<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>sklearn.metrics._classification &mdash; mindsdb_evaluator 0.0.12 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/custom.css" />

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >

          
          
          <a href="../../../index.html">
            
              <img src="../../../_static/mindsdblogo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.0.12
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../accuracy.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Accuracy</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../calibration.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Calibration</span></code></a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: white" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">mindsdb_evaluator</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">sklearn.metrics._classification</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for sklearn.metrics._classification</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Metrics to assess performance on classification task given class prediction.</span>

<span class="sd">Functions named as ``*_score`` return a scalar value to maximize: the higher</span>
<span class="sd">the better.</span>

<span class="sd">Function named as ``*_error`` or ``*_loss`` return a scalar value to minimize:</span>
<span class="sd">the lower the better.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># Authors: Alexandre Gramfort &lt;alexandre.gramfort@inria.fr&gt;</span>
<span class="c1">#          Mathieu Blondel &lt;mathieu@mblondel.org&gt;</span>
<span class="c1">#          Olivier Grisel &lt;olivier.grisel@ensta.org&gt;</span>
<span class="c1">#          Arnaud Joly &lt;a.joly@ulg.ac.be&gt;</span>
<span class="c1">#          Jochen Wersdorfer &lt;jochen@wersdoerfer.de&gt;</span>
<span class="c1">#          Lars Buitinck</span>
<span class="c1">#          Joel Nothman &lt;joel.nothman@gmail.com&gt;</span>
<span class="c1">#          Noel Dawe &lt;noel@dawe.me&gt;</span>
<span class="c1">#          Jatin Shah &lt;jatindshah@gmail.com&gt;</span>
<span class="c1">#          Saurabh Jha &lt;saurabh.jhaa@gmail.com&gt;</span>
<span class="c1">#          Bernardo Stein &lt;bernardovstein@gmail.com&gt;</span>
<span class="c1">#          Shangwu Yao &lt;shangwuyao@gmail.com&gt;</span>
<span class="c1">#          Michal Karbownik &lt;michakarbownik@gmail.com&gt;</span>
<span class="c1"># License: BSD 3 clause</span>


<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">numbers</span> <span class="kn">import</span> <span class="n">Integral</span><span class="p">,</span> <span class="n">Real</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">coo_matrix</span><span class="p">,</span> <span class="n">csr_matrix</span>
<span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">xlogy</span>

<span class="kn">from</span> <span class="nn">..exceptions</span> <span class="kn">import</span> <span class="n">UndefinedMetricWarning</span>
<span class="kn">from</span> <span class="nn">..preprocessing</span> <span class="kn">import</span> <span class="n">LabelBinarizer</span><span class="p">,</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">..utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">assert_all_finite</span><span class="p">,</span>
    <span class="n">check_array</span><span class="p">,</span>
    <span class="n">check_consistent_length</span><span class="p">,</span>
    <span class="n">column_or_1d</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">..utils._array_api</span> <span class="kn">import</span> <span class="n">_union1d</span><span class="p">,</span> <span class="n">_weighted_sum</span><span class="p">,</span> <span class="n">get_namespace</span>
<span class="kn">from</span> <span class="nn">..utils._param_validation</span> <span class="kn">import</span> <span class="n">Interval</span><span class="p">,</span> <span class="n">Options</span><span class="p">,</span> <span class="n">StrOptions</span><span class="p">,</span> <span class="n">validate_params</span>
<span class="kn">from</span> <span class="nn">..utils.extmath</span> <span class="kn">import</span> <span class="n">_nanaverage</span>
<span class="kn">from</span> <span class="nn">..utils.multiclass</span> <span class="kn">import</span> <span class="n">type_of_target</span><span class="p">,</span> <span class="n">unique_labels</span>
<span class="kn">from</span> <span class="nn">..utils.sparsefuncs</span> <span class="kn">import</span> <span class="n">count_nonzero</span>
<span class="kn">from</span> <span class="nn">..utils.validation</span> <span class="kn">import</span> <span class="n">_check_pos_label_consistency</span><span class="p">,</span> <span class="n">_num_samples</span>


<span class="k">def</span> <span class="nf">_check_zero_division</span><span class="p">(</span><span class="n">zero_division</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">zero_division</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">zero_division</span> <span class="o">==</span> <span class="s2">&quot;warn&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">zero_division</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">))</span> <span class="ow">and</span> <span class="n">zero_division</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="n">zero_division</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># np.isnan(zero_division)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>


<span class="k">def</span> <span class="nf">_check_targets</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check that y_true and y_pred belong to the same classification task.</span>

<span class="sd">    This converts multiclass or binary types to a common shape, and raises a</span>
<span class="sd">    ValueError for a mix of multilabel and multiclass targets, a mix of</span>
<span class="sd">    multilabel formats, for the presence of continuous-valued or multioutput</span>
<span class="sd">    targets, or for targets of different lengths.</span>

<span class="sd">    Column vectors are squeezed to 1d, while multilabel formats are returned</span>
<span class="sd">    as CSR sparse label indicators.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : array-like</span>

<span class="sd">    y_pred : array-like</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    type_true : one of {&#39;multilabel-indicator&#39;, &#39;multiclass&#39;, &#39;binary&#39;}</span>
<span class="sd">        The type of the true target data, as output by</span>
<span class="sd">        ``utils.multiclass.type_of_target``.</span>

<span class="sd">    y_true : array or indicator matrix</span>

<span class="sd">    y_pred : array or indicator matrix</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">check_consistent_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">type_true</span> <span class="o">=</span> <span class="n">type_of_target</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;y_true&quot;</span><span class="p">)</span>
    <span class="n">type_pred</span> <span class="o">=</span> <span class="n">type_of_target</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;y_pred&quot;</span><span class="p">)</span>

    <span class="n">y_type</span> <span class="o">=</span> <span class="p">{</span><span class="n">type_true</span><span class="p">,</span> <span class="n">type_pred</span><span class="p">}</span>
    <span class="k">if</span> <span class="n">y_type</span> <span class="o">==</span> <span class="p">{</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">}:</span>
        <span class="n">y_type</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;multiclass&quot;</span><span class="p">}</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_type</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Classification metrics can&#39;t handle a mix of </span><span class="si">{0}</span><span class="s2"> and </span><span class="si">{1}</span><span class="s2"> targets&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">type_true</span><span class="p">,</span> <span class="n">type_pred</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="c1"># We can&#39;t have more than one value on y_type =&gt; The set is no more needed</span>
    <span class="n">y_type</span> <span class="o">=</span> <span class="n">y_type</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>

    <span class="c1"># No metrics support &quot;multiclass-multioutput&quot; format</span>
    <span class="k">if</span> <span class="n">y_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">,</span> <span class="s2">&quot;multilabel-indicator&quot;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{0}</span><span class="s2"> is not supported&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_type</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">y_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">]:</span>
        <span class="n">xp</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_namespace</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
        <span class="n">y_true</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">y_type</span> <span class="o">==</span> <span class="s2">&quot;binary&quot;</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">unique_values</span> <span class="o">=</span> <span class="n">_union1d</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">xp</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">TypeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="c1"># We expect y_true and y_pred to be of the same data type.</span>
                <span class="c1"># If `y_true` was provided to the classifier as strings,</span>
                <span class="c1"># `y_pred` given by the classifier will also be encoded with</span>
                <span class="c1"># strings. So we raise a meaningful error</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="s2">&quot;Labels in y_true and y_pred should be of the same type. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Got y_true=</span><span class="si">{</span><span class="n">xp</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span><span class="si">}</span><span class="s2"> and &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;y_pred=</span><span class="si">{</span><span class="n">xp</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span><span class="si">}</span><span class="s2">. Make sure that the &quot;</span>
                    <span class="s2">&quot;predictions provided by the classifier coincides with &quot;</span>
                    <span class="s2">&quot;the true labels.&quot;</span>
                <span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>
            <span class="k">if</span> <span class="n">unique_values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">y_type</span> <span class="o">=</span> <span class="s2">&quot;multiclass&quot;</span>

    <span class="k">if</span> <span class="n">y_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;multilabel&quot;</span><span class="p">):</span>
        <span class="n">y_true</span> <span class="o">=</span> <span class="n">csr_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">csr_matrix</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
        <span class="n">y_type</span> <span class="o">=</span> <span class="s2">&quot;multilabel-indicator&quot;</span>

    <span class="k">return</span> <span class="n">y_type</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span>


<div class="viewcode-block" id="accuracy_score"><a class="viewcode-back" href="../../../accuracy.html#accuracy.accuracy_score">[docs]</a><span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_pred&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;normalize&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;boolean&quot;</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Accuracy classification score.</span>

<span class="sd">    In multilabel classification, this function computes subset accuracy:</span>
<span class="sd">    the set of labels predicted for a sample must *exactly* match the</span>
<span class="sd">    corresponding set of labels in y_true.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;accuracy_score&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : 1d array-like, or label indicator array / sparse matrix</span>
<span class="sd">        Ground truth (correct) labels.</span>

<span class="sd">    y_pred : 1d array-like, or label indicator array / sparse matrix</span>
<span class="sd">        Predicted labels, as returned by a classifier.</span>

<span class="sd">    normalize : bool, default=True</span>
<span class="sd">        If ``False``, return the number of correctly classified samples.</span>
<span class="sd">        Otherwise, return the fraction of correctly classified samples.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : float</span>
<span class="sd">        If ``normalize == True``, return the fraction of correctly</span>
<span class="sd">        classified samples (float), else returns the number of correctly</span>
<span class="sd">        classified samples (int).</span>

<span class="sd">        The best performance is 1 with ``normalize == True`` and the number</span>
<span class="sd">        of samples with ``normalize == False``.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    balanced_accuracy_score : Compute the balanced accuracy to deal with</span>
<span class="sd">        imbalanced datasets.</span>
<span class="sd">    jaccard_score : Compute the Jaccard similarity coefficient score.</span>
<span class="sd">    hamming_loss : Compute the average Hamming loss or Hamming distance between</span>
<span class="sd">        two sets of samples.</span>
<span class="sd">    zero_one_loss : Compute the Zero-one classification loss. By default, the</span>
<span class="sd">        function will return the percentage of imperfectly predicted subsets.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    In binary classification, this function is equal to the `jaccard_score`</span>
<span class="sd">    function.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import accuracy_score</span>
<span class="sd">    &gt;&gt;&gt; y_pred = [0, 2, 1, 3]</span>
<span class="sd">    &gt;&gt;&gt; y_true = [0, 1, 2, 3]</span>
<span class="sd">    &gt;&gt;&gt; accuracy_score(y_true, y_pred)</span>
<span class="sd">    0.5</span>
<span class="sd">    &gt;&gt;&gt; accuracy_score(y_true, y_pred, normalize=False)</span>
<span class="sd">    2.0</span>

<span class="sd">    In the multilabel case with binary label indicators:</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; accuracy_score(np.array([[0, 1], [1, 1]]), np.ones((2, 2)))</span>
<span class="sd">    0.5</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Compute accuracy for each possible representation</span>
    <span class="n">y_type</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">_check_targets</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">check_consistent_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">y_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;multilabel&quot;</span><span class="p">):</span>
        <span class="n">differing_labels</span> <span class="o">=</span> <span class="n">count_nonzero</span><span class="p">(</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">differing_labels</span> <span class="o">==</span> <span class="mi">0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">y_true</span> <span class="o">==</span> <span class="n">y_pred</span>

    <span class="k">return</span> <span class="n">_weighted_sum</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="n">normalize</span><span class="p">)</span></div>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_pred&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;normalize&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;true&quot;</span><span class="p">,</span> <span class="s2">&quot;pred&quot;</span><span class="p">,</span> <span class="s2">&quot;all&quot;</span><span class="p">}),</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">confusion_matrix</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">None</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute confusion matrix to evaluate the accuracy of a classification.</span>

<span class="sd">    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`</span>
<span class="sd">    is equal to the number of observations known to be in group :math:`i` and</span>
<span class="sd">    predicted to be in group :math:`j`.</span>

<span class="sd">    Thus in binary classification, the count of true negatives is</span>
<span class="sd">    :math:`C_{0,0}`, false negatives is :math:`C_{1,0}`, true positives is</span>
<span class="sd">    :math:`C_{1,1}` and false positives is :math:`C_{0,1}`.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;confusion_matrix&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : array-like of shape (n_samples,)</span>
<span class="sd">        Ground truth (correct) target values.</span>

<span class="sd">    y_pred : array-like of shape (n_samples,)</span>
<span class="sd">        Estimated targets as returned by a classifier.</span>

<span class="sd">    labels : array-like of shape (n_classes), default=None</span>
<span class="sd">        List of labels to index the matrix. This may be used to reorder</span>
<span class="sd">        or select a subset of labels.</span>
<span class="sd">        If ``None`` is given, those that appear at least once</span>
<span class="sd">        in ``y_true`` or ``y_pred`` are used in sorted order.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">        .. versionadded:: 0.18</span>

<span class="sd">    normalize : {&#39;true&#39;, &#39;pred&#39;, &#39;all&#39;}, default=None</span>
<span class="sd">        Normalizes confusion matrix over the true (rows), predicted (columns)</span>
<span class="sd">        conditions or all the population. If None, confusion matrix will not be</span>
<span class="sd">        normalized.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    C : ndarray of shape (n_classes, n_classes)</span>
<span class="sd">        Confusion matrix whose i-th row and j-th</span>
<span class="sd">        column entry indicates the number of</span>
<span class="sd">        samples with true label being i-th class</span>
<span class="sd">        and predicted label being j-th class.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    ConfusionMatrixDisplay.from_estimator : Plot the confusion matrix</span>
<span class="sd">        given an estimator, the data, and the label.</span>
<span class="sd">    ConfusionMatrixDisplay.from_predictions : Plot the confusion matrix</span>
<span class="sd">        given the true and predicted labels.</span>
<span class="sd">    ConfusionMatrixDisplay : Confusion Matrix visualization.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] `Wikipedia entry for the Confusion matrix</span>
<span class="sd">           &lt;https://en.wikipedia.org/wiki/Confusion_matrix&gt;`_</span>
<span class="sd">           (Wikipedia and other references may use a different</span>
<span class="sd">           convention for axes).</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import confusion_matrix</span>
<span class="sd">    &gt;&gt;&gt; y_true = [2, 0, 2, 2, 0, 1]</span>
<span class="sd">    &gt;&gt;&gt; y_pred = [0, 0, 2, 2, 0, 2]</span>
<span class="sd">    &gt;&gt;&gt; confusion_matrix(y_true, y_pred)</span>
<span class="sd">    array([[2, 0, 0],</span>
<span class="sd">           [0, 0, 1],</span>
<span class="sd">           [1, 0, 2]])</span>

<span class="sd">    &gt;&gt;&gt; y_true = [&quot;cat&quot;, &quot;ant&quot;, &quot;cat&quot;, &quot;cat&quot;, &quot;ant&quot;, &quot;bird&quot;]</span>
<span class="sd">    &gt;&gt;&gt; y_pred = [&quot;ant&quot;, &quot;ant&quot;, &quot;cat&quot;, &quot;cat&quot;, &quot;ant&quot;, &quot;cat&quot;]</span>
<span class="sd">    &gt;&gt;&gt; confusion_matrix(y_true, y_pred, labels=[&quot;ant&quot;, &quot;bird&quot;, &quot;cat&quot;])</span>
<span class="sd">    array([[2, 0, 0],</span>
<span class="sd">           [0, 0, 1],</span>
<span class="sd">           [1, 0, 2]])</span>

<span class="sd">    In the binary case, we can extract true positives, etc. as follows:</span>

<span class="sd">    &gt;&gt;&gt; tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()</span>
<span class="sd">    &gt;&gt;&gt; (tn, fp, fn, tp)</span>
<span class="sd">    (0, 2, 1, 1)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_type</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">_check_targets</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">y_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> is not supported&quot;</span> <span class="o">%</span> <span class="n">y_type</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">unique_labels</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">n_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span>
        <span class="k">if</span> <span class="n">n_labels</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;&#39;labels&#39; should contains at least one label.&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">y_true</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_labels</span><span class="p">,</span> <span class="n">n_labels</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">intersect1d</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;At least one label specified must be in y_true&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">y_true</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">)</span>

    <span class="n">check_consistent_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>

    <span class="n">n_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span>
    <span class="c1"># If labels are not consecutive integers starting from zero, then</span>
    <span class="c1"># y_true and y_pred must be converted into index form</span>
    <span class="n">need_index_conversion</span> <span class="o">=</span> <span class="ow">not</span> <span class="p">(</span>
        <span class="n">labels</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;i&quot;</span><span class="p">,</span> <span class="s2">&quot;u&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">}</span>
        <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_labels</span><span class="p">))</span>
        <span class="ow">and</span> <span class="n">y_true</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="mi">0</span>
        <span class="ow">and</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="mi">0</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">need_index_conversion</span><span class="p">:</span>
        <span class="n">label_to_ind</span> <span class="o">=</span> <span class="p">{</span><span class="n">y</span><span class="p">:</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">labels</span><span class="p">)}</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">label_to_ind</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_labels</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">y_pred</span><span class="p">])</span>
        <span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">label_to_ind</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_labels</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">y_true</span><span class="p">])</span>

    <span class="c1"># intersect y_pred, y_true with labels, eliminate items not in labels</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">&lt;</span> <span class="n">n_labels</span><span class="p">,</span> <span class="n">y_true</span> <span class="o">&lt;</span> <span class="n">n_labels</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">ind</span><span class="p">):</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>
        <span class="n">y_true</span> <span class="o">=</span> <span class="n">y_true</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>
        <span class="c1"># also eliminate weights of eliminated items</span>
        <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">sample_weight</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>

    <span class="c1"># Choose the accumulator dtype to always have high precision</span>
    <span class="k">if</span> <span class="n">sample_weight</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;i&quot;</span><span class="p">,</span> <span class="s2">&quot;u&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">}:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span>

    <span class="n">cm</span> <span class="o">=</span> <span class="n">coo_matrix</span><span class="p">(</span>
        <span class="p">(</span><span class="n">sample_weight</span><span class="p">,</span> <span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)),</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_labels</span><span class="p">,</span> <span class="n">n_labels</span><span class="p">),</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
    <span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">errstate</span><span class="p">(</span><span class="nb">all</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">normalize</span> <span class="o">==</span> <span class="s2">&quot;true&quot;</span><span class="p">:</span>
            <span class="n">cm</span> <span class="o">=</span> <span class="n">cm</span> <span class="o">/</span> <span class="n">cm</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">normalize</span> <span class="o">==</span> <span class="s2">&quot;pred&quot;</span><span class="p">:</span>
            <span class="n">cm</span> <span class="o">=</span> <span class="n">cm</span> <span class="o">/</span> <span class="n">cm</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">normalize</span> <span class="o">==</span> <span class="s2">&quot;all&quot;</span><span class="p">:</span>
            <span class="n">cm</span> <span class="o">=</span> <span class="n">cm</span> <span class="o">/</span> <span class="n">cm</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">cm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">cm</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">cm</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="s2">&quot;A single label was found in &#39;y_true&#39; and &#39;y_pred&#39;. For the confusion &quot;</span>
                <span class="s2">&quot;matrix to have the correct shape, use the &#39;labels&#39; parameter to pass &quot;</span>
                <span class="s2">&quot;all known labels.&quot;</span>
            <span class="p">),</span>
            <span class="ne">UserWarning</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">cm</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_pred&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;samplewise&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;boolean&quot;</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">multilabel_confusion_matrix</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">samplewise</span><span class="o">=</span><span class="kc">False</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute a confusion matrix for each class or sample.</span>

<span class="sd">    .. versionadded:: 0.21</span>

<span class="sd">    Compute class-wise (default) or sample-wise (samplewise=True) multilabel</span>
<span class="sd">    confusion matrix to evaluate the accuracy of a classification, and output</span>
<span class="sd">    confusion matrices for each class or sample.</span>

<span class="sd">    In multilabel confusion matrix :math:`MCM`, the count of true negatives</span>
<span class="sd">    is :math:`MCM_{:,0,0}`, false negatives is :math:`MCM_{:,1,0}`,</span>
<span class="sd">    true positives is :math:`MCM_{:,1,1}` and false positives is</span>
<span class="sd">    :math:`MCM_{:,0,1}`.</span>

<span class="sd">    Multiclass data will be treated as if binarized under a one-vs-rest</span>
<span class="sd">    transformation. Returned confusion matrices will be in the order of</span>
<span class="sd">    sorted unique labels in the union of (y_true, y_pred).</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;multilabel_confusion_matrix&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : {array-like, sparse matrix} of shape (n_samples, n_outputs) or \</span>
<span class="sd">            (n_samples,)</span>
<span class="sd">        Ground truth (correct) target values.</span>

<span class="sd">    y_pred : {array-like, sparse matrix} of shape (n_samples, n_outputs) or \</span>
<span class="sd">            (n_samples,)</span>
<span class="sd">        Estimated targets as returned by a classifier.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">    labels : array-like of shape (n_classes,), default=None</span>
<span class="sd">        A list of classes or column indices to select some (or to force</span>
<span class="sd">        inclusion of classes absent from the data).</span>

<span class="sd">    samplewise : bool, default=False</span>
<span class="sd">        In the multilabel case, this calculates a confusion matrix per sample.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    multi_confusion : ndarray of shape (n_outputs, 2, 2)</span>
<span class="sd">        A 2x2 confusion matrix corresponding to each output in the input.</span>
<span class="sd">        When calculating class-wise multi_confusion (default), then</span>
<span class="sd">        n_outputs = n_labels; when calculating sample-wise multi_confusion</span>
<span class="sd">        (samplewise=True), n_outputs = n_samples. If ``labels`` is defined,</span>
<span class="sd">        the results will be returned in the order specified in ``labels``,</span>
<span class="sd">        otherwise the results will be returned in sorted order by default.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    confusion_matrix : Compute confusion matrix to evaluate the accuracy of a</span>
<span class="sd">        classifier.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The `multilabel_confusion_matrix` calculates class-wise or sample-wise</span>
<span class="sd">    multilabel confusion matrices, and in multiclass tasks, labels are</span>
<span class="sd">    binarized under a one-vs-rest way; while</span>
<span class="sd">    :func:`~sklearn.metrics.confusion_matrix` calculates one confusion matrix</span>
<span class="sd">    for confusion between every two classes.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Multilabel-indicator case:</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import multilabel_confusion_matrix</span>
<span class="sd">    &gt;&gt;&gt; y_true = np.array([[1, 0, 1],</span>
<span class="sd">    ...                    [0, 1, 0]])</span>
<span class="sd">    &gt;&gt;&gt; y_pred = np.array([[1, 0, 0],</span>
<span class="sd">    ...                    [0, 1, 1]])</span>
<span class="sd">    &gt;&gt;&gt; multilabel_confusion_matrix(y_true, y_pred)</span>
<span class="sd">    array([[[1, 0],</span>
<span class="sd">            [0, 1]],</span>
<span class="sd">    &lt;BLANKLINE&gt;</span>
<span class="sd">           [[1, 0],</span>
<span class="sd">            [0, 1]],</span>
<span class="sd">    &lt;BLANKLINE&gt;</span>
<span class="sd">           [[0, 1],</span>
<span class="sd">            [1, 0]]])</span>

<span class="sd">    Multiclass case:</span>

<span class="sd">    &gt;&gt;&gt; y_true = [&quot;cat&quot;, &quot;ant&quot;, &quot;cat&quot;, &quot;cat&quot;, &quot;ant&quot;, &quot;bird&quot;]</span>
<span class="sd">    &gt;&gt;&gt; y_pred = [&quot;ant&quot;, &quot;ant&quot;, &quot;cat&quot;, &quot;cat&quot;, &quot;ant&quot;, &quot;cat&quot;]</span>
<span class="sd">    &gt;&gt;&gt; multilabel_confusion_matrix(y_true, y_pred,</span>
<span class="sd">    ...                             labels=[&quot;ant&quot;, &quot;bird&quot;, &quot;cat&quot;])</span>
<span class="sd">    array([[[3, 1],</span>
<span class="sd">            [0, 2]],</span>
<span class="sd">    &lt;BLANKLINE&gt;</span>
<span class="sd">           [[5, 0],</span>
<span class="sd">            [1, 0]],</span>
<span class="sd">    &lt;BLANKLINE&gt;</span>
<span class="sd">           [[2, 1],</span>
<span class="sd">            [1, 2]]])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_type</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">_check_targets</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">)</span>
    <span class="n">check_consistent_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">y_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">,</span> <span class="s2">&quot;multilabel-indicator&quot;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> is not supported&quot;</span> <span class="o">%</span> <span class="n">y_type</span><span class="p">)</span>

    <span class="n">present_labels</span> <span class="o">=</span> <span class="n">unique_labels</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">present_labels</span>
        <span class="n">n_labels</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">n_labels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
            <span class="p">[</span><span class="n">labels</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">setdiff1d</span><span class="p">(</span><span class="n">present_labels</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">assume_unique</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">y_true</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">samplewise</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Samplewise metrics are not available outside of &quot;</span>
                <span class="s2">&quot;multilabel classification.&quot;</span>
            <span class="p">)</span>

        <span class="n">le</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
        <span class="n">le</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">y_true</span> <span class="o">=</span> <span class="n">le</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">le</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
        <span class="n">sorted_labels</span> <span class="o">=</span> <span class="n">le</span><span class="o">.</span><span class="n">classes_</span>

        <span class="c1"># labels are now from 0 to len(labels) - 1 -&gt; use bincount</span>
        <span class="n">tp</span> <span class="o">=</span> <span class="n">y_true</span> <span class="o">==</span> <span class="n">y_pred</span>
        <span class="n">tp_bins</span> <span class="o">=</span> <span class="n">y_true</span><span class="p">[</span><span class="n">tp</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tp_bins_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">)[</span><span class="n">tp</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tp_bins_weights</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tp_bins</span><span class="p">):</span>
            <span class="n">tp_sum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span>
                <span class="n">tp_bins</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">tp_bins_weights</span><span class="p">,</span> <span class="n">minlength</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Pathological case</span>
            <span class="n">true_sum</span> <span class="o">=</span> <span class="n">pred_sum</span> <span class="o">=</span> <span class="n">tp_sum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_pred</span><span class="p">):</span>
            <span class="n">pred_sum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">minlength</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_true</span><span class="p">):</span>
            <span class="n">true_sum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">minlength</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>

        <span class="c1"># Retain only selected labels</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">sorted_labels</span><span class="p">,</span> <span class="n">labels</span><span class="p">[:</span><span class="n">n_labels</span><span class="p">])</span>
        <span class="n">tp_sum</span> <span class="o">=</span> <span class="n">tp_sum</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
        <span class="n">true_sum</span> <span class="o">=</span> <span class="n">true_sum</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
        <span class="n">pred_sum</span> <span class="o">=</span> <span class="n">pred_sum</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">sum_axis</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">samplewise</span> <span class="k">else</span> <span class="mi">0</span>

        <span class="c1"># All labels are index integers for multilabel.</span>
        <span class="c1"># Select labels:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">present_labels</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">present_labels</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;All labels must be in [0, n labels) for &quot;</span>
                    <span class="s2">&quot;multilabel targets. &quot;</span>
                    <span class="s2">&quot;Got </span><span class="si">%d</span><span class="s2"> &gt; </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">labels</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">present_labels</span><span class="p">))</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;All labels must be in [0, n labels) for &quot;</span>
                    <span class="s2">&quot;multilabel targets. &quot;</span>
                    <span class="s2">&quot;Got </span><span class="si">%d</span><span class="s2"> &lt; 0&quot;</span>
                    <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="n">n_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">y_true</span> <span class="o">=</span> <span class="n">y_true</span><span class="p">[:,</span> <span class="n">labels</span><span class="p">[:</span><span class="n">n_labels</span><span class="p">]]</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="n">labels</span><span class="p">[:</span><span class="n">n_labels</span><span class="p">]]</span>

        <span class="c1"># calculate weighted counts</span>
        <span class="n">true_and_pred</span> <span class="o">=</span> <span class="n">y_true</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
        <span class="n">tp_sum</span> <span class="o">=</span> <span class="n">count_nonzero</span><span class="p">(</span>
            <span class="n">true_and_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">sum_axis</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span>
        <span class="p">)</span>
        <span class="n">pred_sum</span> <span class="o">=</span> <span class="n">count_nonzero</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">sum_axis</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
        <span class="n">true_sum</span> <span class="o">=</span> <span class="n">count_nonzero</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">sum_axis</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>

    <span class="n">fp</span> <span class="o">=</span> <span class="n">pred_sum</span> <span class="o">-</span> <span class="n">tp_sum</span>
    <span class="n">fn</span> <span class="o">=</span> <span class="n">true_sum</span> <span class="o">-</span> <span class="n">tp_sum</span>
    <span class="n">tp</span> <span class="o">=</span> <span class="n">tp_sum</span>

    <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">samplewise</span><span class="p">:</span>
        <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">)</span>
        <span class="n">tp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">tp</span><span class="p">)</span>
        <span class="n">fp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">fp</span><span class="p">)</span>
        <span class="n">fn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
        <span class="n">tn</span> <span class="o">=</span> <span class="n">sample_weight</span> <span class="o">*</span> <span class="n">y_true</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">tp</span> <span class="o">-</span> <span class="n">fp</span> <span class="o">-</span> <span class="n">fn</span>
    <span class="k">elif</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">tn</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">)</span> <span class="o">-</span> <span class="n">tp</span> <span class="o">-</span> <span class="n">fp</span> <span class="o">-</span> <span class="n">fn</span>
    <span class="k">elif</span> <span class="n">samplewise</span><span class="p">:</span>
        <span class="n">tn</span> <span class="o">=</span> <span class="n">y_true</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">tp</span> <span class="o">-</span> <span class="n">fp</span> <span class="o">-</span> <span class="n">fn</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">tn</span> <span class="o">=</span> <span class="n">y_true</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">tp</span> <span class="o">-</span> <span class="n">fp</span> <span class="o">-</span> <span class="n">fn</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">tp</span><span class="p">])</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y1&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y2&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;weights&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="s2">&quot;quadratic&quot;</span><span class="p">}),</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">cohen_kappa_score</span><span class="p">(</span><span class="n">y1</span><span class="p">,</span> <span class="n">y2</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute Cohen&#39;s kappa: a statistic that measures inter-annotator agreement.</span>

<span class="sd">    This function computes Cohen&#39;s kappa [1]_, a score that expresses the level</span>
<span class="sd">    of agreement between two annotators on a classification problem. It is</span>
<span class="sd">    defined as</span>

<span class="sd">    .. math::</span>
<span class="sd">        \kappa = (p_o - p_e) / (1 - p_e)</span>

<span class="sd">    where :math:`p_o` is the empirical probability of agreement on the label</span>
<span class="sd">    assigned to any sample (the observed agreement ratio), and :math:`p_e` is</span>
<span class="sd">    the expected agreement when both annotators assign labels randomly.</span>
<span class="sd">    :math:`p_e` is estimated using a per-annotator empirical prior over the</span>
<span class="sd">    class labels [2]_.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;cohen_kappa&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y1 : array-like of shape (n_samples,)</span>
<span class="sd">        Labels assigned by the first annotator.</span>

<span class="sd">    y2 : array-like of shape (n_samples,)</span>
<span class="sd">        Labels assigned by the second annotator. The kappa statistic is</span>
<span class="sd">        symmetric, so swapping ``y1`` and ``y2`` doesn&#39;t change the value.</span>

<span class="sd">    labels : array-like of shape (n_classes,), default=None</span>
<span class="sd">        List of labels to index the matrix. This may be used to select a</span>
<span class="sd">        subset of labels. If `None`, all labels that appear at least once in</span>
<span class="sd">        ``y1`` or ``y2`` are used.</span>

<span class="sd">    weights : {&#39;linear&#39;, &#39;quadratic&#39;}, default=None</span>
<span class="sd">        Weighting type to calculate the score. `None` means no weighted;</span>
<span class="sd">        &quot;linear&quot; means linear weighted; &quot;quadratic&quot; means quadratic weighted.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    kappa : float</span>
<span class="sd">        The kappa statistic, which is a number between -1 and 1. The maximum</span>
<span class="sd">        value means complete agreement; zero or lower means chance agreement.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] :doi:`J. Cohen (1960). &quot;A coefficient of agreement for nominal scales&quot;.</span>
<span class="sd">           Educational and Psychological Measurement 20(1):37-46.</span>
<span class="sd">           &lt;10.1177/001316446002000104&gt;`</span>
<span class="sd">    .. [2] `R. Artstein and M. Poesio (2008). &quot;Inter-coder agreement for</span>
<span class="sd">           computational linguistics&quot;. Computational Linguistics 34(4):555-596</span>
<span class="sd">           &lt;https://www.mitpressjournals.org/doi/pdf/10.1162/coli.07-034-R2&gt;`_.</span>
<span class="sd">    .. [3] `Wikipedia entry for the Cohen&#39;s kappa</span>
<span class="sd">            &lt;https://en.wikipedia.org/wiki/Cohen%27s_kappa&gt;`_.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import cohen_kappa_score</span>
<span class="sd">    &gt;&gt;&gt; y1 = [&quot;negative&quot;, &quot;positive&quot;, &quot;negative&quot;, &quot;neutral&quot;, &quot;positive&quot;]</span>
<span class="sd">    &gt;&gt;&gt; y2 = [&quot;negative&quot;, &quot;positive&quot;, &quot;negative&quot;, &quot;neutral&quot;, &quot;negative&quot;]</span>
<span class="sd">    &gt;&gt;&gt; cohen_kappa_score(y1, y2)</span>
<span class="sd">    0.6875</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">confusion</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y1</span><span class="p">,</span> <span class="n">y2</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
    <span class="n">n_classes</span> <span class="o">=</span> <span class="n">confusion</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">sum0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">confusion</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">sum1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">confusion</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">expected</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">sum0</span><span class="p">,</span> <span class="n">sum1</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">sum0</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">w_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">w_mat</span><span class="o">.</span><span class="n">flat</span><span class="p">[::</span> <span class="n">n_classes</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># &quot;linear&quot; or &quot;quadratic&quot;</span>
        <span class="n">w_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">w_mat</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_classes</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">weights</span> <span class="o">==</span> <span class="s2">&quot;linear&quot;</span><span class="p">:</span>
            <span class="n">w_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">w_mat</span> <span class="o">-</span> <span class="n">w_mat</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">w_mat</span> <span class="o">=</span> <span class="p">(</span><span class="n">w_mat</span> <span class="o">-</span> <span class="n">w_mat</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>

    <span class="n">k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w_mat</span> <span class="o">*</span> <span class="n">confusion</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w_mat</span> <span class="o">*</span> <span class="n">expected</span><span class="p">)</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">k</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_pred&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;pos_label&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Real</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;average&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;samples&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="s2">&quot;binary&quot;</span><span class="p">}),</span>
            <span class="kc">None</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;zero_division&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="n">Options</span><span class="p">(</span><span class="n">Real</span><span class="p">,</span> <span class="p">{</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">}),</span>
            <span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;warn&quot;</span><span class="p">}),</span>
        <span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">jaccard_score</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">average</span><span class="o">=</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">zero_division</span><span class="o">=</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Jaccard similarity coefficient score.</span>

<span class="sd">    The Jaccard index [1], or Jaccard similarity coefficient, defined as</span>
<span class="sd">    the size of the intersection divided by the size of the union of two label</span>
<span class="sd">    sets, is used to compare set of predicted labels for a sample to the</span>
<span class="sd">    corresponding set of labels in ``y_true``.</span>

<span class="sd">    Support beyond term:`binary` targets is achieved by treating :term:`multiclass`</span>
<span class="sd">    and :term:`multilabel` data as a collection of binary problems, one for each</span>
<span class="sd">    label. For the :term:`binary` case, setting `average=&#39;binary&#39;` will return the</span>
<span class="sd">    Jaccard similarity coefficient for `pos_label`. If `average` is not `&#39;binary&#39;`,</span>
<span class="sd">    `pos_label` is ignored and scores for both classes are computed, then averaged or</span>
<span class="sd">    both returned (when `average=None`). Similarly, for :term:`multiclass` and</span>
<span class="sd">    :term:`multilabel` targets, scores for all `labels` are either returned or</span>
<span class="sd">    averaged depending on the `average` parameter. Use `labels` specify the set of</span>
<span class="sd">    labels to calculate the score for.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;jaccard_similarity_score&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : 1d array-like, or label indicator array / sparse matrix</span>
<span class="sd">        Ground truth (correct) labels.</span>

<span class="sd">    y_pred : 1d array-like, or label indicator array / sparse matrix</span>
<span class="sd">        Predicted labels, as returned by a classifier.</span>

<span class="sd">    labels : array-like of shape (n_classes,), default=None</span>
<span class="sd">        The set of labels to include when `average != &#39;binary&#39;`, and their</span>
<span class="sd">        order if `average is None`. Labels present in the data can be</span>
<span class="sd">        excluded, for example in multiclass classification to exclude a &quot;negative</span>
<span class="sd">        class&quot;. Labels not present in the data can be included and will be</span>
<span class="sd">        &quot;assigned&quot; 0 samples. For multilabel targets, labels are column indices.</span>
<span class="sd">        By default, all labels in `y_true` and `y_pred` are used in sorted order.</span>

<span class="sd">    pos_label : int, float, bool or str, default=1</span>
<span class="sd">        The class to report if `average=&#39;binary&#39;` and the data is binary,</span>
<span class="sd">        otherwise this parameter is ignored.</span>
<span class="sd">        For multiclass or multilabel targets, set `labels=[pos_label]` and</span>
<span class="sd">        `average != &#39;binary&#39;` to report metrics for one label only.</span>

<span class="sd">    average : {&#39;micro&#39;, &#39;macro&#39;, &#39;samples&#39;, &#39;weighted&#39;, \</span>
<span class="sd">            &#39;binary&#39;} or None, default=&#39;binary&#39;</span>
<span class="sd">        If ``None``, the scores for each class are returned. Otherwise, this</span>
<span class="sd">        determines the type of averaging performed on the data:</span>

<span class="sd">        ``&#39;binary&#39;``:</span>
<span class="sd">            Only report results for the class specified by ``pos_label``.</span>
<span class="sd">            This is applicable only if targets (``y_{true,pred}``) are binary.</span>
<span class="sd">        ``&#39;micro&#39;``:</span>
<span class="sd">            Calculate metrics globally by counting the total true positives,</span>
<span class="sd">            false negatives and false positives.</span>
<span class="sd">        ``&#39;macro&#39;``:</span>
<span class="sd">            Calculate metrics for each label, and find their unweighted</span>
<span class="sd">            mean.  This does not take label imbalance into account.</span>
<span class="sd">        ``&#39;weighted&#39;``:</span>
<span class="sd">            Calculate metrics for each label, and find their average, weighted</span>
<span class="sd">            by support (the number of true instances for each label). This</span>
<span class="sd">            alters &#39;macro&#39; to account for label imbalance.</span>
<span class="sd">        ``&#39;samples&#39;``:</span>
<span class="sd">            Calculate metrics for each instance, and find their average (only</span>
<span class="sd">            meaningful for multilabel classification).</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">    zero_division : &quot;warn&quot;, {0.0, 1.0}, default=&quot;warn&quot;</span>
<span class="sd">        Sets the value to return when there is a zero division, i.e. when there</span>
<span class="sd">        there are no negative values in predictions and labels. If set to</span>
<span class="sd">        &quot;warn&quot;, this acts like 0, but a warning is also raised.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : float or ndarray of shape (n_unique_labels,), dtype=np.float64</span>
<span class="sd">        The Jaccard score. When `average` is not `None`, a single scalar is</span>
<span class="sd">        returned.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    accuracy_score : Function for calculating the accuracy score.</span>
<span class="sd">    f1_score : Function for calculating the F1 score.</span>
<span class="sd">    multilabel_confusion_matrix : Function for computing a confusion matrix\</span>
<span class="sd">                                  for each class or sample.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    :func:`jaccard_score` may be a poor metric if there are no</span>
<span class="sd">    positives for some samples or classes. Jaccard is undefined if there are</span>
<span class="sd">    no true or predicted labels, and our implementation will return a score</span>
<span class="sd">    of 0 with a warning.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] `Wikipedia entry for the Jaccard index</span>
<span class="sd">           &lt;https://en.wikipedia.org/wiki/Jaccard_index&gt;`_.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import jaccard_score</span>
<span class="sd">    &gt;&gt;&gt; y_true = np.array([[0, 1, 1],</span>
<span class="sd">    ...                    [1, 1, 0]])</span>
<span class="sd">    &gt;&gt;&gt; y_pred = np.array([[1, 1, 1],</span>
<span class="sd">    ...                    [1, 0, 0]])</span>

<span class="sd">    In the binary case:</span>

<span class="sd">    &gt;&gt;&gt; jaccard_score(y_true[0], y_pred[0])</span>
<span class="sd">    0.6666...</span>

<span class="sd">    In the 2D comparison case (e.g. image similarity):</span>

<span class="sd">    &gt;&gt;&gt; jaccard_score(y_true, y_pred, average=&quot;micro&quot;)</span>
<span class="sd">    0.6</span>

<span class="sd">    In the multilabel case:</span>

<span class="sd">    &gt;&gt;&gt; jaccard_score(y_true, y_pred, average=&#39;samples&#39;)</span>
<span class="sd">    0.5833...</span>
<span class="sd">    &gt;&gt;&gt; jaccard_score(y_true, y_pred, average=&#39;macro&#39;)</span>
<span class="sd">    0.6666...</span>
<span class="sd">    &gt;&gt;&gt; jaccard_score(y_true, y_pred, average=None)</span>
<span class="sd">    array([0.5, 0.5, 1. ])</span>

<span class="sd">    In the multiclass case:</span>

<span class="sd">    &gt;&gt;&gt; y_pred = [0, 2, 1, 2]</span>
<span class="sd">    &gt;&gt;&gt; y_true = [0, 1, 2, 2]</span>
<span class="sd">    &gt;&gt;&gt; jaccard_score(y_true, y_pred, average=None)</span>
<span class="sd">    array([1. , 0. , 0.33...])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">_check_set_wise_labels</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">pos_label</span><span class="p">)</span>
    <span class="n">samplewise</span> <span class="o">=</span> <span class="n">average</span> <span class="o">==</span> <span class="s2">&quot;samples&quot;</span>
    <span class="n">MCM</span> <span class="o">=</span> <span class="n">multilabel_confusion_matrix</span><span class="p">(</span>
        <span class="n">y_true</span><span class="p">,</span>
        <span class="n">y_pred</span><span class="p">,</span>
        <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
        <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
        <span class="n">samplewise</span><span class="o">=</span><span class="n">samplewise</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">numerator</span> <span class="o">=</span> <span class="n">MCM</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">denominator</span> <span class="o">=</span> <span class="n">MCM</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">MCM</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">MCM</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">average</span> <span class="o">==</span> <span class="s2">&quot;micro&quot;</span><span class="p">:</span>
        <span class="n">numerator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">numerator</span><span class="o">.</span><span class="n">sum</span><span class="p">()])</span>
        <span class="n">denominator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">denominator</span><span class="o">.</span><span class="n">sum</span><span class="p">()])</span>

    <span class="n">jaccard</span> <span class="o">=</span> <span class="n">_prf_divide</span><span class="p">(</span>
        <span class="n">numerator</span><span class="p">,</span>
        <span class="n">denominator</span><span class="p">,</span>
        <span class="s2">&quot;jaccard&quot;</span><span class="p">,</span>
        <span class="s2">&quot;true or predicted&quot;</span><span class="p">,</span>
        <span class="n">average</span><span class="p">,</span>
        <span class="p">(</span><span class="s2">&quot;jaccard&quot;</span><span class="p">,),</span>
        <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">average</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">jaccard</span>
    <span class="k">if</span> <span class="n">average</span> <span class="o">==</span> <span class="s2">&quot;weighted&quot;</span><span class="p">:</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">MCM</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">MCM</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">weights</span><span class="p">):</span>
            <span class="c1"># numerator is 0, and warning should have already been issued</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">elif</span> <span class="n">average</span> <span class="o">==</span> <span class="s2">&quot;samples&quot;</span> <span class="ow">and</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">sample_weight</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">jaccard</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_pred&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">matthews_corrcoef</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the Matthews correlation coefficient (MCC).</span>

<span class="sd">    The Matthews correlation coefficient is used in machine learning as a</span>
<span class="sd">    measure of the quality of binary and multiclass classifications. It takes</span>
<span class="sd">    into account true and false positives and negatives and is generally</span>
<span class="sd">    regarded as a balanced measure which can be used even if the classes are of</span>
<span class="sd">    very different sizes. The MCC is in essence a correlation coefficient value</span>
<span class="sd">    between -1 and +1. A coefficient of +1 represents a perfect prediction, 0</span>
<span class="sd">    an average random prediction and -1 an inverse prediction.  The statistic</span>
<span class="sd">    is also known as the phi coefficient. [source: Wikipedia]</span>

<span class="sd">    Binary and multiclass labels are supported.  Only in the binary case does</span>
<span class="sd">    this relate to information about true and false positives and negatives.</span>
<span class="sd">    See references below.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;matthews_corrcoef&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : array-like of shape (n_samples,)</span>
<span class="sd">        Ground truth (correct) target values.</span>

<span class="sd">    y_pred : array-like of shape (n_samples,)</span>
<span class="sd">        Estimated targets as returned by a classifier.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">        .. versionadded:: 0.18</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    mcc : float</span>
<span class="sd">        The Matthews correlation coefficient (+1 represents a perfect</span>
<span class="sd">        prediction, 0 an average random prediction and -1 and inverse</span>
<span class="sd">        prediction).</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] :doi:`Baldi, Brunak, Chauvin, Andersen and Nielsen, (2000). Assessing the</span>
<span class="sd">       accuracy of prediction algorithms for classification: an overview.</span>
<span class="sd">       &lt;10.1093/bioinformatics/16.5.412&gt;`</span>

<span class="sd">    .. [2] `Wikipedia entry for the Matthews Correlation Coefficient</span>
<span class="sd">       &lt;https://en.wikipedia.org/wiki/Matthews_correlation_coefficient&gt;`_.</span>

<span class="sd">    .. [3] `Gorodkin, (2004). Comparing two K-category assignments by a</span>
<span class="sd">        K-category correlation coefficient</span>
<span class="sd">        &lt;https://www.sciencedirect.com/science/article/pii/S1476927104000799&gt;`_.</span>

<span class="sd">    .. [4] `Jurman, Riccadonna, Furlanello, (2012). A Comparison of MCC and CEN</span>
<span class="sd">        Error Measures in MultiClass Prediction</span>
<span class="sd">        &lt;https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0041882&gt;`_.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import matthews_corrcoef</span>
<span class="sd">    &gt;&gt;&gt; y_true = [+1, +1, +1, -1]</span>
<span class="sd">    &gt;&gt;&gt; y_pred = [+1, -1, +1, +1]</span>
<span class="sd">    &gt;&gt;&gt; matthews_corrcoef(y_true, y_pred)</span>
<span class="sd">    -0.33...</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_type</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">_check_targets</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">check_consistent_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">y_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">}:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> is not supported&quot;</span> <span class="o">%</span> <span class="n">y_type</span><span class="p">)</span>

    <span class="n">lb</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
    <span class="n">lb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">]))</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">lb</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">lb</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>

    <span class="n">C</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
    <span class="n">t_sum</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">p_sum</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">n_correct</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="n">p_sum</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">cov_ytyp</span> <span class="o">=</span> <span class="n">n_correct</span> <span class="o">*</span> <span class="n">n_samples</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">t_sum</span><span class="p">,</span> <span class="n">p_sum</span><span class="p">)</span>
    <span class="n">cov_ypyp</span> <span class="o">=</span> <span class="n">n_samples</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">p_sum</span><span class="p">,</span> <span class="n">p_sum</span><span class="p">)</span>
    <span class="n">cov_ytyt</span> <span class="o">=</span> <span class="n">n_samples</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">t_sum</span><span class="p">,</span> <span class="n">t_sum</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">cov_ypyp</span> <span class="o">*</span> <span class="n">cov_ytyt</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">cov_ytyp</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">cov_ytyt</span> <span class="o">*</span> <span class="n">cov_ypyp</span><span class="p">)</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_pred&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;normalize&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;boolean&quot;</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">zero_one_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Zero-one classification loss.</span>

<span class="sd">    If normalize is ``True``, return the fraction of misclassifications</span>
<span class="sd">    (float), else it returns the number of misclassifications (int). The best</span>
<span class="sd">    performance is 0.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;zero_one_loss&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : 1d array-like, or label indicator array / sparse matrix</span>
<span class="sd">        Ground truth (correct) labels.</span>

<span class="sd">    y_pred : 1d array-like, or label indicator array / sparse matrix</span>
<span class="sd">        Predicted labels, as returned by a classifier.</span>

<span class="sd">    normalize : bool, default=True</span>
<span class="sd">        If ``False``, return the number of misclassifications.</span>
<span class="sd">        Otherwise, return the fraction of misclassifications.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    loss : float or int,</span>
<span class="sd">        If ``normalize == True``, return the fraction of misclassifications</span>
<span class="sd">        (float), else it returns the number of misclassifications (int).</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    accuracy_score : Compute the accuracy score. By default, the function will</span>
<span class="sd">        return the fraction of correct predictions divided by the total number</span>
<span class="sd">        of predictions.</span>
<span class="sd">    hamming_loss : Compute the average Hamming loss or Hamming distance between</span>
<span class="sd">        two sets of samples.</span>
<span class="sd">    jaccard_score : Compute the Jaccard similarity coefficient score.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    In multilabel classification, the zero_one_loss function corresponds to</span>
<span class="sd">    the subset zero-one loss: for each sample, the entire set of labels must be</span>
<span class="sd">    correctly predicted, otherwise the loss for that sample is equal to one.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import zero_one_loss</span>
<span class="sd">    &gt;&gt;&gt; y_pred = [1, 2, 3, 4]</span>
<span class="sd">    &gt;&gt;&gt; y_true = [2, 2, 3, 4]</span>
<span class="sd">    &gt;&gt;&gt; zero_one_loss(y_true, y_pred)</span>
<span class="sd">    0.25</span>
<span class="sd">    &gt;&gt;&gt; zero_one_loss(y_true, y_pred, normalize=False)</span>
<span class="sd">    1.0</span>

<span class="sd">    In the multilabel case with binary label indicators:</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; zero_one_loss(np.array([[0, 1], [1, 1]]), np.ones((2, 2)))</span>
<span class="sd">    0.5</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">xp</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_namespace</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span>
        <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">score</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">n_samples</span> <span class="o">=</span> <span class="n">xp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">n_samples</span> <span class="o">=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">n_samples</span> <span class="o">-</span> <span class="n">score</span>


<div class="viewcode-block" id="f1_score"><a class="viewcode-back" href="../../../accuracy.html#accuracy.f1_score">[docs]</a><span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_pred&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;pos_label&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Real</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;average&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;samples&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="s2">&quot;binary&quot;</span><span class="p">}),</span>
            <span class="kc">None</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;zero_division&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="n">Options</span><span class="p">(</span><span class="n">Real</span><span class="p">,</span> <span class="p">{</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">}),</span>
            <span class="s2">&quot;nan&quot;</span><span class="p">,</span>
            <span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;warn&quot;</span><span class="p">}),</span>
        <span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">f1_score</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">average</span><span class="o">=</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">zero_division</span><span class="o">=</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the F1 score, also known as balanced F-score or F-measure.</span>

<span class="sd">    The F1 score can be interpreted as a harmonic mean of the precision and</span>
<span class="sd">    recall, where an F1 score reaches its best value at 1 and worst score at 0.</span>
<span class="sd">    The relative contribution of precision and recall to the F1 score are</span>
<span class="sd">    equal. The formula for the F1 score is:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \\text{F1} = \\frac{2 * \\text{TP}}{2 * \\text{TP} + \\text{FP} + \\text{FN}}</span>

<span class="sd">    Where :math:`\\text{TP}` is the number of true positives, :math:`\\text{FN}` is the</span>
<span class="sd">    number of false negatives, and :math:`\\text{FP}` is the number of false positives.</span>
<span class="sd">    F1 is by default</span>
<span class="sd">    calculated as 0.0 when there are no true positives, false negatives, or</span>
<span class="sd">    false positives.</span>

<span class="sd">    Support beyond :term:`binary` targets is achieved by treating :term:`multiclass`</span>
<span class="sd">    and :term:`multilabel` data as a collection of binary problems, one for each</span>
<span class="sd">    label. For the :term:`binary` case, setting `average=&#39;binary&#39;` will return</span>
<span class="sd">    F1 score for `pos_label`. If `average` is not `&#39;binary&#39;`, `pos_label` is ignored</span>
<span class="sd">    and F1 score for both classes are computed, then averaged or both returned (when</span>
<span class="sd">    `average=None`). Similarly, for :term:`multiclass` and :term:`multilabel` targets,</span>
<span class="sd">    F1 score for all `labels` are either returned or averaged depending on the</span>
<span class="sd">    `average` parameter. Use `labels` specify the set of labels to calculate F1 score</span>
<span class="sd">    for.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;precision_recall_f_measure_metrics&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : 1d array-like, or label indicator array / sparse matrix</span>
<span class="sd">        Ground truth (correct) target values.</span>

<span class="sd">    y_pred : 1d array-like, or label indicator array / sparse matrix</span>
<span class="sd">        Estimated targets as returned by a classifier.</span>

<span class="sd">    labels : array-like, default=None</span>
<span class="sd">        The set of labels to include when `average != &#39;binary&#39;`, and their</span>
<span class="sd">        order if `average is None`. Labels present in the data can be</span>
<span class="sd">        excluded, for example in multiclass classification to exclude a &quot;negative</span>
<span class="sd">        class&quot;. Labels not present in the data can be included and will be</span>
<span class="sd">        &quot;assigned&quot; 0 samples. For multilabel targets, labels are column indices.</span>
<span class="sd">        By default, all labels in `y_true` and `y_pred` are used in sorted order.</span>

<span class="sd">        .. versionchanged:: 0.17</span>
<span class="sd">           Parameter `labels` improved for multiclass problem.</span>

<span class="sd">    pos_label : int, float, bool or str, default=1</span>
<span class="sd">        The class to report if `average=&#39;binary&#39;` and the data is binary,</span>
<span class="sd">        otherwise this parameter is ignored.</span>
<span class="sd">        For multiclass or multilabel targets, set `labels=[pos_label]` and</span>
<span class="sd">        `average != &#39;binary&#39;` to report metrics for one label only.</span>

<span class="sd">    average : {&#39;micro&#39;, &#39;macro&#39;, &#39;samples&#39;, &#39;weighted&#39;, &#39;binary&#39;} or None, \</span>
<span class="sd">            default=&#39;binary&#39;</span>
<span class="sd">        This parameter is required for multiclass/multilabel targets.</span>
<span class="sd">        If ``None``, the scores for each class are returned. Otherwise, this</span>
<span class="sd">        determines the type of averaging performed on the data:</span>

<span class="sd">        ``&#39;binary&#39;``:</span>
<span class="sd">            Only report results for the class specified by ``pos_label``.</span>
<span class="sd">            This is applicable only if targets (``y_{true,pred}``) are binary.</span>
<span class="sd">        ``&#39;micro&#39;``:</span>
<span class="sd">            Calculate metrics globally by counting the total true positives,</span>
<span class="sd">            false negatives and false positives.</span>
<span class="sd">        ``&#39;macro&#39;``:</span>
<span class="sd">            Calculate metrics for each label, and find their unweighted</span>
<span class="sd">            mean.  This does not take label imbalance into account.</span>
<span class="sd">        ``&#39;weighted&#39;``:</span>
<span class="sd">            Calculate metrics for each label, and find their average weighted</span>
<span class="sd">            by support (the number of true instances for each label). This</span>
<span class="sd">            alters &#39;macro&#39; to account for label imbalance; it can result in an</span>
<span class="sd">            F-score that is not between precision and recall.</span>
<span class="sd">        ``&#39;samples&#39;``:</span>
<span class="sd">            Calculate metrics for each instance, and find their average (only</span>
<span class="sd">            meaningful for multilabel classification where this differs from</span>
<span class="sd">            :func:`accuracy_score`).</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">    zero_division : {&quot;warn&quot;, 0.0, 1.0, np.nan}, default=&quot;warn&quot;</span>
<span class="sd">        Sets the value to return when there is a zero division, i.e. when all</span>
<span class="sd">        predictions and labels are negative.</span>

<span class="sd">        Notes:</span>
<span class="sd">        - If set to &quot;warn&quot;, this acts like 0, but a warning is also raised.</span>
<span class="sd">        - If set to `np.nan`, such values will be excluded from the average.</span>

<span class="sd">        .. versionadded:: 1.3</span>
<span class="sd">           `np.nan` option was added.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    f1_score : float or array of float, shape = [n_unique_labels]</span>
<span class="sd">        F1 score of the positive class in binary classification or weighted</span>
<span class="sd">        average of the F1 scores of each class for the multiclass task.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    fbeta_score : Compute the F-beta score.</span>
<span class="sd">    precision_recall_fscore_support : Compute the precision, recall, F-score,</span>
<span class="sd">        and support.</span>
<span class="sd">    jaccard_score : Compute the Jaccard similarity coefficient score.</span>
<span class="sd">    multilabel_confusion_matrix : Compute a confusion matrix for each class or</span>
<span class="sd">        sample.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    When ``true positive + false positive + false negative == 0`` (i.e. a class</span>
<span class="sd">    is completely absent from both ``y_true`` or ``y_pred``), f-score is</span>
<span class="sd">    undefined. In such cases, by default f-score will be set to 0.0, and</span>
<span class="sd">    ``UndefinedMetricWarning`` will be raised. This behavior can be modified by</span>
<span class="sd">    setting the ``zero_division`` parameter.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] `Wikipedia entry for the F1-score</span>
<span class="sd">           &lt;https://en.wikipedia.org/wiki/F1_score&gt;`_.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import f1_score</span>
<span class="sd">    &gt;&gt;&gt; y_true = [0, 1, 2, 0, 1, 2]</span>
<span class="sd">    &gt;&gt;&gt; y_pred = [0, 2, 1, 0, 0, 1]</span>
<span class="sd">    &gt;&gt;&gt; f1_score(y_true, y_pred, average=&#39;macro&#39;)</span>
<span class="sd">    0.26...</span>
<span class="sd">    &gt;&gt;&gt; f1_score(y_true, y_pred, average=&#39;micro&#39;)</span>
<span class="sd">    0.33...</span>
<span class="sd">    &gt;&gt;&gt; f1_score(y_true, y_pred, average=&#39;weighted&#39;)</span>
<span class="sd">    0.26...</span>
<span class="sd">    &gt;&gt;&gt; f1_score(y_true, y_pred, average=None)</span>
<span class="sd">    array([0.8, 0. , 0. ])</span>

<span class="sd">    &gt;&gt;&gt; # binary classification</span>
<span class="sd">    &gt;&gt;&gt; y_true_empty = [0, 0, 0, 0, 0, 0]</span>
<span class="sd">    &gt;&gt;&gt; y_pred_empty = [0, 0, 0, 0, 0, 0]</span>
<span class="sd">    &gt;&gt;&gt; f1_score(y_true_empty, y_pred_empty)</span>
<span class="sd">    0.0...</span>
<span class="sd">    &gt;&gt;&gt; f1_score(y_true_empty, y_pred_empty, zero_division=1.0)</span>
<span class="sd">    1.0...</span>
<span class="sd">    &gt;&gt;&gt; f1_score(y_true_empty, y_pred_empty, zero_division=np.nan)</span>
<span class="sd">    nan...</span>

<span class="sd">    &gt;&gt;&gt; # multilabel classification</span>
<span class="sd">    &gt;&gt;&gt; y_true = [[0, 0, 0], [1, 1, 1], [0, 1, 1]]</span>
<span class="sd">    &gt;&gt;&gt; y_pred = [[0, 0, 0], [1, 1, 1], [1, 1, 0]]</span>
<span class="sd">    &gt;&gt;&gt; f1_score(y_true, y_pred, average=None)</span>
<span class="sd">    array([0.66666667, 1.        , 0.66666667])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">fbeta_score</span><span class="p">(</span>
        <span class="n">y_true</span><span class="p">,</span>
        <span class="n">y_pred</span><span class="p">,</span>
        <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
        <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">,</span>
        <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>
        <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
    <span class="p">)</span></div>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_pred&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;beta&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">Real</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">)],</span>
        <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;pos_label&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Real</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;average&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;samples&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="s2">&quot;binary&quot;</span><span class="p">}),</span>
            <span class="kc">None</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;zero_division&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="n">Options</span><span class="p">(</span><span class="n">Real</span><span class="p">,</span> <span class="p">{</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">}),</span>
            <span class="s2">&quot;nan&quot;</span><span class="p">,</span>
            <span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;warn&quot;</span><span class="p">}),</span>
        <span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">fbeta_score</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">beta</span><span class="p">,</span>
    <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">average</span><span class="o">=</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">zero_division</span><span class="o">=</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the F-beta score.</span>

<span class="sd">    The F-beta score is the weighted harmonic mean of precision and recall,</span>
<span class="sd">    reaching its optimal value at 1 and its worst value at 0.</span>

<span class="sd">    The `beta` parameter represents the ratio of recall importance to</span>
<span class="sd">    precision importance. `beta &gt; 1` gives more weight to recall, while</span>
<span class="sd">    `beta &lt; 1` favors precision. For example, `beta = 2` makes recall twice</span>
<span class="sd">    as important as precision, while `beta = 0.5` does the opposite.</span>
<span class="sd">    Asymptotically, `beta -&gt; +inf` considers only recall, and `beta -&gt; 0`</span>
<span class="sd">    only precision.</span>

<span class="sd">    The formula for F-beta score is:</span>

<span class="sd">    .. math::</span>

<span class="sd">       F_\\beta = \\frac{(1 + \\beta^2) \\text{tp}}</span>
<span class="sd">                        {(1 + \\beta^2) \\text{tp} + \\text{fp} + \\beta^2 \\text{fn}}</span>

<span class="sd">    Where :math:`\\text{tp}` is the number of true positives, :math:`\\text{fp}` is the</span>
<span class="sd">    number of false positives, and :math:`\\text{fn}` is the number of false negatives.</span>

<span class="sd">    Support beyond term:`binary` targets is achieved by treating :term:`multiclass`</span>
<span class="sd">    and :term:`multilabel` data as a collection of binary problems, one for each</span>
<span class="sd">    label. For the :term:`binary` case, setting `average=&#39;binary&#39;` will return</span>
<span class="sd">    F-beta score for `pos_label`. If `average` is not `&#39;binary&#39;`, `pos_label` is</span>
<span class="sd">    ignored and F-beta score for both classes are computed, then averaged or both</span>
<span class="sd">    returned (when `average=None`). Similarly, for :term:`multiclass` and</span>
<span class="sd">    :term:`multilabel` targets, F-beta score for all `labels` are either returned or</span>
<span class="sd">    averaged depending on the `average` parameter. Use `labels` specify the set of</span>
<span class="sd">    labels to calculate F-beta score for.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;precision_recall_f_measure_metrics&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : 1d array-like, or label indicator array / sparse matrix</span>
<span class="sd">        Ground truth (correct) target values.</span>

<span class="sd">    y_pred : 1d array-like, or label indicator array / sparse matrix</span>
<span class="sd">        Estimated targets as returned by a classifier.</span>

<span class="sd">    beta : float</span>
<span class="sd">        Determines the weight of recall in the combined score.</span>

<span class="sd">    labels : array-like, default=None</span>
<span class="sd">        The set of labels to include when `average != &#39;binary&#39;`, and their</span>
<span class="sd">        order if `average is None`. Labels present in the data can be</span>
<span class="sd">        excluded, for example in multiclass classification to exclude a &quot;negative</span>
<span class="sd">        class&quot;. Labels not present in the data can be included and will be</span>
<span class="sd">        &quot;assigned&quot; 0 samples. For multilabel targets, labels are column indices.</span>
<span class="sd">        By default, all labels in `y_true` and `y_pred` are used in sorted order.</span>

<span class="sd">        .. versionchanged:: 0.17</span>
<span class="sd">           Parameter `labels` improved for multiclass problem.</span>

<span class="sd">    pos_label : int, float, bool or str, default=1</span>
<span class="sd">        The class to report if `average=&#39;binary&#39;` and the data is binary,</span>
<span class="sd">        otherwise this parameter is ignored.</span>
<span class="sd">        For multiclass or multilabel targets, set `labels=[pos_label]` and</span>
<span class="sd">        `average != &#39;binary&#39;` to report metrics for one label only.</span>

<span class="sd">    average : {&#39;micro&#39;, &#39;macro&#39;, &#39;samples&#39;, &#39;weighted&#39;, &#39;binary&#39;} or None, \</span>
<span class="sd">            default=&#39;binary&#39;</span>
<span class="sd">        This parameter is required for multiclass/multilabel targets.</span>
<span class="sd">        If ``None``, the scores for each class are returned. Otherwise, this</span>
<span class="sd">        determines the type of averaging performed on the data:</span>

<span class="sd">        ``&#39;binary&#39;``:</span>
<span class="sd">            Only report results for the class specified by ``pos_label``.</span>
<span class="sd">            This is applicable only if targets (``y_{true,pred}``) are binary.</span>
<span class="sd">        ``&#39;micro&#39;``:</span>
<span class="sd">            Calculate metrics globally by counting the total true positives,</span>
<span class="sd">            false negatives and false positives.</span>
<span class="sd">        ``&#39;macro&#39;``:</span>
<span class="sd">            Calculate metrics for each label, and find their unweighted</span>
<span class="sd">            mean.  This does not take label imbalance into account.</span>
<span class="sd">        ``&#39;weighted&#39;``:</span>
<span class="sd">            Calculate metrics for each label, and find their average weighted</span>
<span class="sd">            by support (the number of true instances for each label). This</span>
<span class="sd">            alters &#39;macro&#39; to account for label imbalance; it can result in an</span>
<span class="sd">            F-score that is not between precision and recall.</span>
<span class="sd">        ``&#39;samples&#39;``:</span>
<span class="sd">            Calculate metrics for each instance, and find their average (only</span>
<span class="sd">            meaningful for multilabel classification where this differs from</span>
<span class="sd">            :func:`accuracy_score`).</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">    zero_division : {&quot;warn&quot;, 0.0, 1.0, np.nan}, default=&quot;warn&quot;</span>
<span class="sd">        Sets the value to return when there is a zero division, i.e. when all</span>
<span class="sd">        predictions and labels are negative.</span>

<span class="sd">        Notes:</span>
<span class="sd">        - If set to &quot;warn&quot;, this acts like 0, but a warning is also raised.</span>
<span class="sd">        - If set to `np.nan`, such values will be excluded from the average.</span>

<span class="sd">        .. versionadded:: 1.3</span>
<span class="sd">           `np.nan` option was added.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    fbeta_score : float (if average is not None) or array of float, shape =\</span>
<span class="sd">        [n_unique_labels]</span>
<span class="sd">        F-beta score of the positive class in binary classification or weighted</span>
<span class="sd">        average of the F-beta score of each class for the multiclass task.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    precision_recall_fscore_support : Compute the precision, recall, F-score,</span>
<span class="sd">        and support.</span>
<span class="sd">    multilabel_confusion_matrix : Compute a confusion matrix for each class or</span>
<span class="sd">        sample.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    When ``true positive + false positive + false negative == 0``, f-score</span>
<span class="sd">    returns 0.0 and raises ``UndefinedMetricWarning``. This behavior can be</span>
<span class="sd">    modified by setting ``zero_division``.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] R. Baeza-Yates and B. Ribeiro-Neto (2011).</span>
<span class="sd">           Modern Information Retrieval. Addison Wesley, pp. 327-328.</span>

<span class="sd">    .. [2] `Wikipedia entry for the F1-score</span>
<span class="sd">           &lt;https://en.wikipedia.org/wiki/F1_score&gt;`_.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import fbeta_score</span>
<span class="sd">    &gt;&gt;&gt; y_true = [0, 1, 2, 0, 1, 2]</span>
<span class="sd">    &gt;&gt;&gt; y_pred = [0, 2, 1, 0, 0, 1]</span>
<span class="sd">    &gt;&gt;&gt; fbeta_score(y_true, y_pred, average=&#39;macro&#39;, beta=0.5)</span>
<span class="sd">    0.23...</span>
<span class="sd">    &gt;&gt;&gt; fbeta_score(y_true, y_pred, average=&#39;micro&#39;, beta=0.5)</span>
<span class="sd">    0.33...</span>
<span class="sd">    &gt;&gt;&gt; fbeta_score(y_true, y_pred, average=&#39;weighted&#39;, beta=0.5)</span>
<span class="sd">    0.23...</span>
<span class="sd">    &gt;&gt;&gt; fbeta_score(y_true, y_pred, average=None, beta=0.5)</span>
<span class="sd">    array([0.71..., 0.        , 0.        ])</span>
<span class="sd">    &gt;&gt;&gt; y_pred_empty = [0, 0, 0, 0, 0, 0]</span>
<span class="sd">    &gt;&gt;&gt; fbeta_score(y_true, y_pred_empty,</span>
<span class="sd">    ...             average=&quot;macro&quot;, zero_division=np.nan, beta=0.5)</span>
<span class="sd">    0.12...</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">precision_recall_fscore_support</span><span class="p">(</span>
        <span class="n">y_true</span><span class="p">,</span>
        <span class="n">y_pred</span><span class="p">,</span>
        <span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">,</span>
        <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
        <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">,</span>
        <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>
        <span class="n">warn_for</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;f-score&quot;</span><span class="p">,),</span>
        <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">f</span>


<span class="k">def</span> <span class="nf">_prf_divide</span><span class="p">(</span>
    <span class="n">numerator</span><span class="p">,</span> <span class="n">denominator</span><span class="p">,</span> <span class="n">metric</span><span class="p">,</span> <span class="n">modifier</span><span class="p">,</span> <span class="n">average</span><span class="p">,</span> <span class="n">warn_for</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="s2">&quot;warn&quot;</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Performs division and handles divide-by-zero.</span>

<span class="sd">    On zero-division, sets the corresponding result elements equal to</span>
<span class="sd">    0, 1 or np.nan (according to ``zero_division``). Plus, if</span>
<span class="sd">    ``zero_division != &quot;warn&quot;`` raises a warning.</span>

<span class="sd">    The metric, modifier and average arguments are used only for determining</span>
<span class="sd">    an appropriate warning.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">denominator</span> <span class="o">==</span> <span class="mf">0.0</span>
    <span class="n">denominator</span> <span class="o">=</span> <span class="n">denominator</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">denominator</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># avoid infs/nans</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">numerator</span> <span class="o">/</span> <span class="n">denominator</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">mask</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="c1"># set those with 0 denominator to `zero_division`, and 0 when &quot;warn&quot;</span>
    <span class="n">zero_division_value</span> <span class="o">=</span> <span class="n">_check_zero_division</span><span class="p">(</span><span class="n">zero_division</span><span class="p">)</span>
    <span class="n">result</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">zero_division_value</span>

    <span class="c1"># we assume the user will be removing warnings if zero_division is set</span>
    <span class="c1"># to something different than &quot;warn&quot;. If we are computing only f-score</span>
    <span class="c1"># the warning will be raised only if precision and recall are ill-defined</span>
    <span class="k">if</span> <span class="n">zero_division</span> <span class="o">!=</span> <span class="s2">&quot;warn&quot;</span> <span class="ow">or</span> <span class="n">metric</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">warn_for</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="c1"># build appropriate warning</span>
    <span class="k">if</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">warn_for</span><span class="p">:</span>
        <span class="n">_warn_prf</span><span class="p">(</span><span class="n">average</span><span class="p">,</span> <span class="n">modifier</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">metric</span><span class="o">.</span><span class="n">capitalize</span><span class="p">()</span><span class="si">}</span><span class="s2"> is&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span> <span class="nf">_warn_prf</span><span class="p">(</span><span class="n">average</span><span class="p">,</span> <span class="n">modifier</span><span class="p">,</span> <span class="n">msg_start</span><span class="p">,</span> <span class="n">result_size</span><span class="p">):</span>
    <span class="n">axis0</span><span class="p">,</span> <span class="n">axis1</span> <span class="o">=</span> <span class="s2">&quot;sample&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span>
    <span class="k">if</span> <span class="n">average</span> <span class="o">==</span> <span class="s2">&quot;samples&quot;</span><span class="p">:</span>
        <span class="n">axis0</span><span class="p">,</span> <span class="n">axis1</span> <span class="o">=</span> <span class="n">axis1</span><span class="p">,</span> <span class="n">axis0</span>
    <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
        <span class="s2">&quot;</span><span class="si">{0}</span><span class="s2"> ill-defined and being set to 0.0 {{0}} &quot;</span>
        <span class="s2">&quot;no </span><span class="si">{1}</span><span class="s2"> </span><span class="si">{2}</span><span class="s2">s. Use `zero_division` parameter to control&quot;</span>
        <span class="s2">&quot; this behavior.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">msg_start</span><span class="p">,</span> <span class="n">modifier</span><span class="p">,</span> <span class="n">axis0</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">result_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="n">msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;due to&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="n">msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;in </span><span class="si">{0}</span><span class="s2">s with&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">axis1</span><span class="p">))</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="n">UndefinedMetricWarning</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_check_set_wise_labels</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">pos_label</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Validation associated with set-wise metrics.</span>

<span class="sd">    Returns identified labels.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">average_options</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="s2">&quot;samples&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">average</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">average_options</span> <span class="ow">and</span> <span class="n">average</span> <span class="o">!=</span> <span class="s2">&quot;binary&quot;</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;average has to be one of &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">average_options</span><span class="p">))</span>

    <span class="n">y_type</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">_check_targets</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="c1"># Convert to Python primitive type to avoid NumPy type / Python str</span>
    <span class="c1"># comparison. See https://github.com/numpy/numpy/issues/6784</span>
    <span class="n">present_labels</span> <span class="o">=</span> <span class="n">unique_labels</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">average</span> <span class="o">==</span> <span class="s2">&quot;binary&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">y_type</span> <span class="o">==</span> <span class="s2">&quot;binary&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">pos_label</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">present_labels</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">present_labels</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;pos_label=</span><span class="si">{</span><span class="n">pos_label</span><span class="si">}</span><span class="s2"> is not a valid label. It &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;should be one of </span><span class="si">{</span><span class="n">present_labels</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">pos_label</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">average_options</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">average_options</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">y_type</span> <span class="o">==</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">:</span>
                <span class="n">average_options</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&quot;samples&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Target is </span><span class="si">%s</span><span class="s2"> but average=&#39;binary&#39;. Please &quot;</span>
                <span class="s2">&quot;choose another average setting, one of </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">y_type</span><span class="p">,</span> <span class="n">average_options</span><span class="p">)</span>
            <span class="p">)</span>
    <span class="k">elif</span> <span class="n">pos_label</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;Note that pos_label (set to </span><span class="si">%r</span><span class="s2">) is ignored when &quot;</span>
            <span class="s2">&quot;average != &#39;binary&#39; (got </span><span class="si">%r</span><span class="s2">). You may use &quot;</span>
            <span class="s2">&quot;labels=[pos_label] to specify a single positive class.&quot;</span>
            <span class="o">%</span> <span class="p">(</span><span class="n">pos_label</span><span class="p">,</span> <span class="n">average</span><span class="p">),</span>
            <span class="ne">UserWarning</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">labels</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_pred&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;beta&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">Real</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">)],</span>
        <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;pos_label&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Real</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;average&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;samples&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="s2">&quot;binary&quot;</span><span class="p">}),</span>
            <span class="kc">None</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="s2">&quot;warn_for&quot;</span><span class="p">:</span> <span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">,</span> <span class="nb">set</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;zero_division&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="n">Options</span><span class="p">(</span><span class="n">Real</span><span class="p">,</span> <span class="p">{</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">}),</span>
            <span class="s2">&quot;nan&quot;</span><span class="p">,</span>
            <span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;warn&quot;</span><span class="p">}),</span>
        <span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">precision_recall_fscore_support</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
    <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">warn_for</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;precision&quot;</span><span class="p">,</span> <span class="s2">&quot;recall&quot;</span><span class="p">,</span> <span class="s2">&quot;f-score&quot;</span><span class="p">),</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">zero_division</span><span class="o">=</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute precision, recall, F-measure and support for each class.</span>

<span class="sd">    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of</span>
<span class="sd">    true positives and ``fp`` the number of false positives. The precision is</span>
<span class="sd">    intuitively the ability of the classifier not to label a negative sample as</span>
<span class="sd">    positive.</span>

<span class="sd">    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of</span>
<span class="sd">    true positives and ``fn`` the number of false negatives. The recall is</span>
<span class="sd">    intuitively the ability of the classifier to find all the positive samples.</span>

<span class="sd">    The F-beta score can be interpreted as a weighted harmonic mean of</span>
<span class="sd">    the precision and recall, where an F-beta score reaches its best</span>
<span class="sd">    value at 1 and worst score at 0.</span>

<span class="sd">    The F-beta score weights recall more than precision by a factor of</span>
<span class="sd">    ``beta``. ``beta == 1.0`` means recall and precision are equally important.</span>

<span class="sd">    The support is the number of occurrences of each class in ``y_true``.</span>

<span class="sd">    Support beyond term:`binary` targets is achieved by treating :term:`multiclass`</span>
<span class="sd">    and :term:`multilabel` data as a collection of binary problems, one for each</span>
<span class="sd">    label. For the :term:`binary` case, setting `average=&#39;binary&#39;` will return</span>
<span class="sd">    metrics for `pos_label`. If `average` is not `&#39;binary&#39;`, `pos_label` is ignored</span>
<span class="sd">    and metrics for both classes are computed, then averaged or both returned (when</span>
<span class="sd">    `average=None`). Similarly, for :term:`multiclass` and :term:`multilabel` targets,</span>
<span class="sd">    metrics for all `labels` are either returned or averaged depending on the `average`</span>
<span class="sd">    parameter. Use `labels` specify the set of labels to calculate metrics for.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;precision_recall_f_measure_metrics&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : 1d array-like, or label indicator array / sparse matrix</span>
<span class="sd">        Ground truth (correct) target values.</span>

<span class="sd">    y_pred : 1d array-like, or label indicator array / sparse matrix</span>
<span class="sd">        Estimated targets as returned by a classifier.</span>

<span class="sd">    beta : float, default=1.0</span>
<span class="sd">        The strength of recall versus precision in the F-score.</span>

<span class="sd">    labels : array-like, default=None</span>
<span class="sd">        The set of labels to include when `average != &#39;binary&#39;`, and their</span>
<span class="sd">        order if `average is None`. Labels present in the data can be</span>
<span class="sd">        excluded, for example in multiclass classification to exclude a &quot;negative</span>
<span class="sd">        class&quot;. Labels not present in the data can be included and will be</span>
<span class="sd">        &quot;assigned&quot; 0 samples. For multilabel targets, labels are column indices.</span>
<span class="sd">        By default, all labels in `y_true` and `y_pred` are used in sorted order.</span>

<span class="sd">    pos_label : int, float, bool or str, default=1</span>
<span class="sd">        The class to report if `average=&#39;binary&#39;` and the data is binary,</span>
<span class="sd">        otherwise this parameter is ignored.</span>
<span class="sd">        For multiclass or multilabel targets, set `labels=[pos_label]` and</span>
<span class="sd">        `average != &#39;binary&#39;` to report metrics for one label only.</span>

<span class="sd">    average : {&#39;binary&#39;, &#39;micro&#39;, &#39;macro&#39;, &#39;samples&#39;, &#39;weighted&#39;}, \</span>
<span class="sd">            default=None</span>
<span class="sd">        If ``None``, the metrics for each class are returned. Otherwise, this</span>
<span class="sd">        determines the type of averaging performed on the data:</span>

<span class="sd">        ``&#39;binary&#39;``:</span>
<span class="sd">            Only report results for the class specified by ``pos_label``.</span>
<span class="sd">            This is applicable only if targets (``y_{true,pred}``) are binary.</span>
<span class="sd">        ``&#39;micro&#39;``:</span>
<span class="sd">            Calculate metrics globally by counting the total true positives,</span>
<span class="sd">            false negatives and false positives.</span>
<span class="sd">        ``&#39;macro&#39;``:</span>
<span class="sd">            Calculate metrics for each label, and find their unweighted</span>
<span class="sd">            mean.  This does not take label imbalance into account.</span>
<span class="sd">        ``&#39;weighted&#39;``:</span>
<span class="sd">            Calculate metrics for each label, and find their average weighted</span>
<span class="sd">            by support (the number of true instances for each label). This</span>
<span class="sd">            alters &#39;macro&#39; to account for label imbalance; it can result in an</span>
<span class="sd">            F-score that is not between precision and recall.</span>
<span class="sd">        ``&#39;samples&#39;``:</span>
<span class="sd">            Calculate metrics for each instance, and find their average (only</span>
<span class="sd">            meaningful for multilabel classification where this differs from</span>
<span class="sd">            :func:`accuracy_score`).</span>

<span class="sd">    warn_for : list, tuple or set, for internal use</span>
<span class="sd">        This determines which warnings will be made in the case that this</span>
<span class="sd">        function is being used to return only one of its metrics.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">    zero_division : {&quot;warn&quot;, 0.0, 1.0, np.nan}, default=&quot;warn&quot;</span>
<span class="sd">        Sets the value to return when there is a zero division:</span>
<span class="sd">           - recall: when there are no positive labels</span>
<span class="sd">           - precision: when there are no positive predictions</span>
<span class="sd">           - f-score: both</span>

<span class="sd">        Notes:</span>
<span class="sd">        - If set to &quot;warn&quot;, this acts like 0, but a warning is also raised.</span>
<span class="sd">        - If set to `np.nan`, such values will be excluded from the average.</span>

<span class="sd">        .. versionadded:: 1.3</span>
<span class="sd">           `np.nan` option was added.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    precision : float (if average is not None) or array of float, shape =\</span>
<span class="sd">        [n_unique_labels]</span>
<span class="sd">        Precision score.</span>

<span class="sd">    recall : float (if average is not None) or array of float, shape =\</span>
<span class="sd">        [n_unique_labels]</span>
<span class="sd">        Recall score.</span>

<span class="sd">    fbeta_score : float (if average is not None) or array of float, shape =\</span>
<span class="sd">        [n_unique_labels]</span>
<span class="sd">        F-beta score.</span>

<span class="sd">    support : None (if average is not None) or array of int, shape =\</span>
<span class="sd">        [n_unique_labels]</span>
<span class="sd">        The number of occurrences of each label in ``y_true``.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    When ``true positive + false positive == 0``, precision is undefined.</span>
<span class="sd">    When ``true positive + false negative == 0``, recall is undefined. When</span>
<span class="sd">    ``true positive + false negative + false positive == 0``, f-score is</span>
<span class="sd">    undefined. In such cases, by default the metric will be set to 0, and</span>
<span class="sd">    ``UndefinedMetricWarning`` will be raised. This behavior can be modified</span>
<span class="sd">    with ``zero_division``.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] `Wikipedia entry for the Precision and recall</span>
<span class="sd">           &lt;https://en.wikipedia.org/wiki/Precision_and_recall&gt;`_.</span>

<span class="sd">    .. [2] `Wikipedia entry for the F1-score</span>
<span class="sd">           &lt;https://en.wikipedia.org/wiki/F1_score&gt;`_.</span>

<span class="sd">    .. [3] `Discriminative Methods for Multi-labeled Classification Advances</span>
<span class="sd">           in Knowledge Discovery and Data Mining (2004), pp. 22-30 by Shantanu</span>
<span class="sd">           Godbole, Sunita Sarawagi</span>
<span class="sd">           &lt;http://www.godbole.net/shantanu/pubs/multilabelsvm-pakdd04.pdf&gt;`_.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import precision_recall_fscore_support</span>
<span class="sd">    &gt;&gt;&gt; y_true = np.array([&#39;cat&#39;, &#39;dog&#39;, &#39;pig&#39;, &#39;cat&#39;, &#39;dog&#39;, &#39;pig&#39;])</span>
<span class="sd">    &gt;&gt;&gt; y_pred = np.array([&#39;cat&#39;, &#39;pig&#39;, &#39;dog&#39;, &#39;cat&#39;, &#39;cat&#39;, &#39;dog&#39;])</span>
<span class="sd">    &gt;&gt;&gt; precision_recall_fscore_support(y_true, y_pred, average=&#39;macro&#39;)</span>
<span class="sd">    (0.22..., 0.33..., 0.26..., None)</span>
<span class="sd">    &gt;&gt;&gt; precision_recall_fscore_support(y_true, y_pred, average=&#39;micro&#39;)</span>
<span class="sd">    (0.33..., 0.33..., 0.33..., None)</span>
<span class="sd">    &gt;&gt;&gt; precision_recall_fscore_support(y_true, y_pred, average=&#39;weighted&#39;)</span>
<span class="sd">    (0.22..., 0.33..., 0.26..., None)</span>

<span class="sd">    It is possible to compute per-label precisions, recalls, F1-scores and</span>
<span class="sd">    supports instead of averaging:</span>

<span class="sd">    &gt;&gt;&gt; precision_recall_fscore_support(y_true, y_pred, average=None,</span>
<span class="sd">    ... labels=[&#39;pig&#39;, &#39;dog&#39;, &#39;cat&#39;])</span>
<span class="sd">    (array([0.        , 0.        , 0.66...]),</span>
<span class="sd">     array([0., 0., 1.]), array([0. , 0. , 0.8]),</span>
<span class="sd">     array([2, 2, 2]))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_check_zero_division</span><span class="p">(</span><span class="n">zero_division</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">_check_set_wise_labels</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">pos_label</span><span class="p">)</span>

    <span class="c1"># Calculate tp_sum, pred_sum, true_sum ###</span>
    <span class="n">samplewise</span> <span class="o">=</span> <span class="n">average</span> <span class="o">==</span> <span class="s2">&quot;samples&quot;</span>
    <span class="n">MCM</span> <span class="o">=</span> <span class="n">multilabel_confusion_matrix</span><span class="p">(</span>
        <span class="n">y_true</span><span class="p">,</span>
        <span class="n">y_pred</span><span class="p">,</span>
        <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
        <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
        <span class="n">samplewise</span><span class="o">=</span><span class="n">samplewise</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">tp_sum</span> <span class="o">=</span> <span class="n">MCM</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">pred_sum</span> <span class="o">=</span> <span class="n">tp_sum</span> <span class="o">+</span> <span class="n">MCM</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">true_sum</span> <span class="o">=</span> <span class="n">tp_sum</span> <span class="o">+</span> <span class="n">MCM</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">average</span> <span class="o">==</span> <span class="s2">&quot;micro&quot;</span><span class="p">:</span>
        <span class="n">tp_sum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">tp_sum</span><span class="o">.</span><span class="n">sum</span><span class="p">()])</span>
        <span class="n">pred_sum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">pred_sum</span><span class="o">.</span><span class="n">sum</span><span class="p">()])</span>
        <span class="n">true_sum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">true_sum</span><span class="o">.</span><span class="n">sum</span><span class="p">()])</span>

    <span class="c1"># Finally, we have all our sufficient statistics. Divide! #</span>
    <span class="n">beta2</span> <span class="o">=</span> <span class="n">beta</span><span class="o">**</span><span class="mi">2</span>

    <span class="c1"># Divide, and on zero-division, set scores and/or warn according to</span>
    <span class="c1"># zero_division:</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="n">_prf_divide</span><span class="p">(</span>
        <span class="n">tp_sum</span><span class="p">,</span> <span class="n">pred_sum</span><span class="p">,</span> <span class="s2">&quot;precision&quot;</span><span class="p">,</span> <span class="s2">&quot;predicted&quot;</span><span class="p">,</span> <span class="n">average</span><span class="p">,</span> <span class="n">warn_for</span><span class="p">,</span> <span class="n">zero_division</span>
    <span class="p">)</span>
    <span class="n">recall</span> <span class="o">=</span> <span class="n">_prf_divide</span><span class="p">(</span>
        <span class="n">tp_sum</span><span class="p">,</span> <span class="n">true_sum</span><span class="p">,</span> <span class="s2">&quot;recall&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">,</span> <span class="n">average</span><span class="p">,</span> <span class="n">warn_for</span><span class="p">,</span> <span class="n">zero_division</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isposinf</span><span class="p">(</span><span class="n">beta</span><span class="p">):</span>
        <span class="n">f_score</span> <span class="o">=</span> <span class="n">recall</span>
    <span class="k">elif</span> <span class="n">beta</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">f_score</span> <span class="o">=</span> <span class="n">precision</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># The score is defined as:</span>
        <span class="c1"># score = (1 + beta**2) * precision * recall / (beta**2 * precision + recall)</span>
        <span class="c1"># Therefore, we can express the score in terms of confusion matrix entries as:</span>
        <span class="c1"># score = (1 + beta**2) * tp / ((1 + beta**2) * tp + beta**2 * fn + fp)</span>
        <span class="n">denom</span> <span class="o">=</span> <span class="n">beta2</span> <span class="o">*</span> <span class="n">true_sum</span> <span class="o">+</span> <span class="n">pred_sum</span>
        <span class="n">f_score</span> <span class="o">=</span> <span class="n">_prf_divide</span><span class="p">(</span>
            <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">beta2</span><span class="p">)</span> <span class="o">*</span> <span class="n">tp_sum</span><span class="p">,</span>
            <span class="n">denom</span><span class="p">,</span>
            <span class="s2">&quot;f-score&quot;</span><span class="p">,</span>
            <span class="s2">&quot;true nor predicted&quot;</span><span class="p">,</span>
            <span class="n">average</span><span class="p">,</span>
            <span class="n">warn_for</span><span class="p">,</span>
            <span class="n">zero_division</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># Average the results</span>
    <span class="k">if</span> <span class="n">average</span> <span class="o">==</span> <span class="s2">&quot;weighted&quot;</span><span class="p">:</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">true_sum</span>
    <span class="k">elif</span> <span class="n">average</span> <span class="o">==</span> <span class="s2">&quot;samples&quot;</span><span class="p">:</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">sample_weight</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">average</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">average</span> <span class="o">!=</span> <span class="s2">&quot;binary&quot;</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">_nanaverage</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
        <span class="n">recall</span> <span class="o">=</span> <span class="n">_nanaverage</span><span class="p">(</span><span class="n">recall</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
        <span class="n">f_score</span> <span class="o">=</span> <span class="n">_nanaverage</span><span class="p">(</span><span class="n">f_score</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
        <span class="n">true_sum</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># return no support</span>

    <span class="k">return</span> <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">f_score</span><span class="p">,</span> <span class="n">true_sum</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_pred&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;raise_warning&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;boolean&quot;</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">class_likelihood_ratios</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">raise_warning</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute binary classification positive and negative likelihood ratios.</span>

<span class="sd">    The positive likelihood ratio is `LR+ = sensitivity / (1 - specificity)`</span>
<span class="sd">    where the sensitivity or recall is the ratio `tp / (tp + fn)` and the</span>
<span class="sd">    specificity is `tn / (tn + fp)`. The negative likelihood ratio is `LR- = (1</span>
<span class="sd">    - sensitivity) / specificity`. Here `tp` is the number of true positives,</span>
<span class="sd">    `fp` the number of false positives, `tn` is the number of true negatives and</span>
<span class="sd">    `fn` the number of false negatives. Both class likelihood ratios can be used</span>
<span class="sd">    to obtain post-test probabilities given a pre-test probability.</span>

<span class="sd">    `LR+` ranges from 1 to infinity. A `LR+` of 1 indicates that the probability</span>
<span class="sd">    of predicting the positive class is the same for samples belonging to either</span>
<span class="sd">    class; therefore, the test is useless. The greater `LR+` is, the more a</span>
<span class="sd">    positive prediction is likely to be a true positive when compared with the</span>
<span class="sd">    pre-test probability. A value of `LR+` lower than 1 is invalid as it would</span>
<span class="sd">    indicate that the odds of a sample being a true positive decrease with</span>
<span class="sd">    respect to the pre-test odds.</span>

<span class="sd">    `LR-` ranges from 0 to 1. The closer it is to 0, the lower the probability</span>
<span class="sd">    of a given sample to be a false negative. A `LR-` of 1 means the test is</span>
<span class="sd">    useless because the odds of having the condition did not change after the</span>
<span class="sd">    test. A value of `LR-` greater than 1 invalidates the classifier as it</span>
<span class="sd">    indicates an increase in the odds of a sample belonging to the positive</span>
<span class="sd">    class after being classified as negative. This is the case when the</span>
<span class="sd">    classifier systematically predicts the opposite of the true label.</span>

<span class="sd">    A typical application in medicine is to identify the positive/negative class</span>
<span class="sd">    to the presence/absence of a disease, respectively; the classifier being a</span>
<span class="sd">    diagnostic test; the pre-test probability of an individual having the</span>
<span class="sd">    disease can be the prevalence of such disease (proportion of a particular</span>
<span class="sd">    population found to be affected by a medical condition); and the post-test</span>
<span class="sd">    probabilities would be the probability that the condition is truly present</span>
<span class="sd">    given a positive test result.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;class_likelihood_ratios&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : 1d array-like, or label indicator array / sparse matrix</span>
<span class="sd">        Ground truth (correct) target values.</span>

<span class="sd">    y_pred : 1d array-like, or label indicator array / sparse matrix</span>
<span class="sd">        Estimated targets as returned by a classifier.</span>

<span class="sd">    labels : array-like, default=None</span>
<span class="sd">        List of labels to index the matrix. This may be used to select the</span>
<span class="sd">        positive and negative classes with the ordering `labels=[negative_class,</span>
<span class="sd">        positive_class]`. If `None` is given, those that appear at least once in</span>
<span class="sd">        `y_true` or `y_pred` are used in sorted order.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">    raise_warning : bool, default=True</span>
<span class="sd">        Whether or not a case-specific warning message is raised when there is a</span>
<span class="sd">        zero division. Even if the error is not raised, the function will return</span>
<span class="sd">        nan in such cases.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    (positive_likelihood_ratio, negative_likelihood_ratio) : tuple</span>
<span class="sd">        A tuple of two float, the first containing the Positive likelihood ratio</span>
<span class="sd">        and the second the Negative likelihood ratio.</span>

<span class="sd">    Warns</span>
<span class="sd">    -----</span>
<span class="sd">    When `false positive == 0`, the positive likelihood ratio is undefined.</span>
<span class="sd">    When `true negative == 0`, the negative likelihood ratio is undefined.</span>
<span class="sd">    When `true positive + false negative == 0` both ratios are undefined.</span>
<span class="sd">    In such cases, `UserWarning` will be raised if raise_warning=True.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] `Wikipedia entry for the Likelihood ratios in diagnostic testing</span>
<span class="sd">           &lt;https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing&gt;`_.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import class_likelihood_ratios</span>
<span class="sd">    &gt;&gt;&gt; class_likelihood_ratios([0, 1, 0, 1, 0], [1, 1, 0, 0, 0])</span>
<span class="sd">    (1.5, 0.75)</span>
<span class="sd">    &gt;&gt;&gt; y_true = np.array([&quot;non-cat&quot;, &quot;cat&quot;, &quot;non-cat&quot;, &quot;cat&quot;, &quot;non-cat&quot;])</span>
<span class="sd">    &gt;&gt;&gt; y_pred = np.array([&quot;cat&quot;, &quot;cat&quot;, &quot;non-cat&quot;, &quot;non-cat&quot;, &quot;non-cat&quot;])</span>
<span class="sd">    &gt;&gt;&gt; class_likelihood_ratios(y_true, y_pred)</span>
<span class="sd">    (1.33..., 0.66...)</span>
<span class="sd">    &gt;&gt;&gt; y_true = np.array([&quot;non-zebra&quot;, &quot;zebra&quot;, &quot;non-zebra&quot;, &quot;zebra&quot;, &quot;non-zebra&quot;])</span>
<span class="sd">    &gt;&gt;&gt; y_pred = np.array([&quot;zebra&quot;, &quot;zebra&quot;, &quot;non-zebra&quot;, &quot;non-zebra&quot;, &quot;non-zebra&quot;])</span>
<span class="sd">    &gt;&gt;&gt; class_likelihood_ratios(y_true, y_pred)</span>
<span class="sd">    (1.5, 0.75)</span>

<span class="sd">    To avoid ambiguities, use the notation `labels=[negative_class,</span>
<span class="sd">    positive_class]`</span>

<span class="sd">    &gt;&gt;&gt; y_true = np.array([&quot;non-cat&quot;, &quot;cat&quot;, &quot;non-cat&quot;, &quot;cat&quot;, &quot;non-cat&quot;])</span>
<span class="sd">    &gt;&gt;&gt; y_pred = np.array([&quot;cat&quot;, &quot;cat&quot;, &quot;non-cat&quot;, &quot;non-cat&quot;, &quot;non-cat&quot;])</span>
<span class="sd">    &gt;&gt;&gt; class_likelihood_ratios(y_true, y_pred, labels=[&quot;non-cat&quot;, &quot;cat&quot;])</span>
<span class="sd">    (1.5, 0.75)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">y_type</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">_check_targets</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">y_type</span> <span class="o">!=</span> <span class="s2">&quot;binary&quot;</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;class_likelihood_ratios only supports binary classification &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;problems, got targets of type: </span><span class="si">{</span><span class="n">y_type</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span>
        <span class="n">y_true</span><span class="p">,</span>
        <span class="n">y_pred</span><span class="p">,</span>
        <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
        <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Case when `y_test` contains a single class and `y_test == y_pred`.</span>
    <span class="c1"># This may happen when cross-validating imbalanced data and should</span>
    <span class="c1"># not be interpreted as a perfect score.</span>
    <span class="k">if</span> <span class="n">cm</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;samples of only one class were seen during testing &quot;</span>
        <span class="k">if</span> <span class="n">raise_warning</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="ne">UserWarning</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">positive_likelihood_ratio</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="n">negative_likelihood_ratio</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">tp</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        <span class="n">support_pos</span> <span class="o">=</span> <span class="n">tp</span> <span class="o">+</span> <span class="n">fn</span>
        <span class="n">support_neg</span> <span class="o">=</span> <span class="n">tn</span> <span class="o">+</span> <span class="n">fp</span>
        <span class="n">pos_num</span> <span class="o">=</span> <span class="n">tp</span> <span class="o">*</span> <span class="n">support_neg</span>
        <span class="n">pos_denom</span> <span class="o">=</span> <span class="n">fp</span> <span class="o">*</span> <span class="n">support_pos</span>
        <span class="n">neg_num</span> <span class="o">=</span> <span class="n">fn</span> <span class="o">*</span> <span class="n">support_neg</span>
        <span class="n">neg_denom</span> <span class="o">=</span> <span class="n">tn</span> <span class="o">*</span> <span class="n">support_pos</span>

        <span class="c1"># If zero division warn and set scores to nan, else divide</span>
        <span class="k">if</span> <span class="n">support_pos</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;no samples of the positive class were present in the testing set &quot;</span>
            <span class="k">if</span> <span class="n">raise_warning</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="ne">UserWarning</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">positive_likelihood_ratio</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
            <span class="n">negative_likelihood_ratio</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">if</span> <span class="n">fp</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">tp</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;no samples predicted for the positive class&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;positive_likelihood_ratio ill-defined and being set to nan &quot;</span>
            <span class="k">if</span> <span class="n">raise_warning</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="ne">UserWarning</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">positive_likelihood_ratio</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">positive_likelihood_ratio</span> <span class="o">=</span> <span class="n">pos_num</span> <span class="o">/</span> <span class="n">pos_denom</span>
        <span class="k">if</span> <span class="n">tn</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;negative_likelihood_ratio ill-defined and being set to nan &quot;</span>
            <span class="k">if</span> <span class="n">raise_warning</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="ne">UserWarning</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">negative_likelihood_ratio</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">negative_likelihood_ratio</span> <span class="o">=</span> <span class="n">neg_num</span> <span class="o">/</span> <span class="n">neg_denom</span>

    <span class="k">return</span> <span class="n">positive_likelihood_ratio</span><span class="p">,</span> <span class="n">negative_likelihood_ratio</span>


<div class="viewcode-block" id="precision_score"><a class="viewcode-back" href="../../../accuracy.html#accuracy.precision_score">[docs]</a><span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_pred&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;pos_label&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Real</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;average&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;samples&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="s2">&quot;binary&quot;</span><span class="p">}),</span>
            <span class="kc">None</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;zero_division&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="n">Options</span><span class="p">(</span><span class="n">Real</span><span class="p">,</span> <span class="p">{</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">}),</span>
            <span class="s2">&quot;nan&quot;</span><span class="p">,</span>
            <span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;warn&quot;</span><span class="p">}),</span>
        <span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">precision_score</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">average</span><span class="o">=</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">zero_division</span><span class="o">=</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the precision.</span>

<span class="sd">    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of</span>
<span class="sd">    true positives and ``fp`` the number of false positives. The precision is</span>
<span class="sd">    intuitively the ability of the classifier not to label as positive a sample</span>
<span class="sd">    that is negative.</span>

<span class="sd">    The best value is 1 and the worst value is 0.</span>

<span class="sd">    Support beyond term:`binary` targets is achieved by treating :term:`multiclass`</span>
<span class="sd">    and :term:`multilabel` data as a collection of binary problems, one for each</span>
<span class="sd">    label. For the :term:`binary` case, setting `average=&#39;binary&#39;` will return</span>
<span class="sd">    precision for `pos_label`. If `average` is not `&#39;binary&#39;`, `pos_label` is ignored</span>
<span class="sd">    and precision for both classes are computed, then averaged or both returned (when</span>
<span class="sd">    `average=None`). Similarly, for :term:`multiclass` and :term:`multilabel` targets,</span>
<span class="sd">    precision for all `labels` are either returned or averaged depending on the</span>
<span class="sd">    `average` parameter. Use `labels` specify the set of labels to calculate precision</span>
<span class="sd">    for.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;precision_recall_f_measure_metrics&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : 1d array-like, or label indicator array / sparse matrix</span>
<span class="sd">        Ground truth (correct) target values.</span>

<span class="sd">    y_pred : 1d array-like, or label indicator array / sparse matrix</span>
<span class="sd">        Estimated targets as returned by a classifier.</span>

<span class="sd">    labels : array-like, default=None</span>
<span class="sd">        The set of labels to include when `average != &#39;binary&#39;`, and their</span>
<span class="sd">        order if `average is None`. Labels present in the data can be</span>
<span class="sd">        excluded, for example in multiclass classification to exclude a &quot;negative</span>
<span class="sd">        class&quot;. Labels not present in the data can be included and will be</span>
<span class="sd">        &quot;assigned&quot; 0 samples. For multilabel targets, labels are column indices.</span>
<span class="sd">        By default, all labels in `y_true` and `y_pred` are used in sorted order.</span>

<span class="sd">        .. versionchanged:: 0.17</span>
<span class="sd">           Parameter `labels` improved for multiclass problem.</span>

<span class="sd">    pos_label : int, float, bool or str, default=1</span>
<span class="sd">        The class to report if `average=&#39;binary&#39;` and the data is binary,</span>
<span class="sd">        otherwise this parameter is ignored.</span>
<span class="sd">        For multiclass or multilabel targets, set `labels=[pos_label]` and</span>
<span class="sd">        `average != &#39;binary&#39;` to report metrics for one label only.</span>

<span class="sd">    average : {&#39;micro&#39;, &#39;macro&#39;, &#39;samples&#39;, &#39;weighted&#39;, &#39;binary&#39;} or None, \</span>
<span class="sd">            default=&#39;binary&#39;</span>
<span class="sd">        This parameter is required for multiclass/multilabel targets.</span>
<span class="sd">        If ``None``, the scores for each class are returned. Otherwise, this</span>
<span class="sd">        determines the type of averaging performed on the data:</span>

<span class="sd">        ``&#39;binary&#39;``:</span>
<span class="sd">            Only report results for the class specified by ``pos_label``.</span>
<span class="sd">            This is applicable only if targets (``y_{true,pred}``) are binary.</span>
<span class="sd">        ``&#39;micro&#39;``:</span>
<span class="sd">            Calculate metrics globally by counting the total true positives,</span>
<span class="sd">            false negatives and false positives.</span>
<span class="sd">        ``&#39;macro&#39;``:</span>
<span class="sd">            Calculate metrics for each label, and find their unweighted</span>
<span class="sd">            mean.  This does not take label imbalance into account.</span>
<span class="sd">        ``&#39;weighted&#39;``:</span>
<span class="sd">            Calculate metrics for each label, and find their average weighted</span>
<span class="sd">            by support (the number of true instances for each label). This</span>
<span class="sd">            alters &#39;macro&#39; to account for label imbalance; it can result in an</span>
<span class="sd">            F-score that is not between precision and recall.</span>
<span class="sd">        ``&#39;samples&#39;``:</span>
<span class="sd">            Calculate metrics for each instance, and find their average (only</span>
<span class="sd">            meaningful for multilabel classification where this differs from</span>
<span class="sd">            :func:`accuracy_score`).</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">    zero_division : {&quot;warn&quot;, 0.0, 1.0, np.nan}, default=&quot;warn&quot;</span>
<span class="sd">        Sets the value to return when there is a zero division.</span>

<span class="sd">        Notes:</span>
<span class="sd">        - If set to &quot;warn&quot;, this acts like 0, but a warning is also raised.</span>
<span class="sd">        - If set to `np.nan`, such values will be excluded from the average.</span>

<span class="sd">        .. versionadded:: 1.3</span>
<span class="sd">           `np.nan` option was added.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    precision : float (if average is not None) or array of float of shape \</span>
<span class="sd">                (n_unique_labels,)</span>
<span class="sd">        Precision of the positive class in binary classification or weighted</span>
<span class="sd">        average of the precision of each class for the multiclass task.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    precision_recall_fscore_support : Compute precision, recall, F-measure and</span>
<span class="sd">        support for each class.</span>
<span class="sd">    recall_score :  Compute the ratio ``tp / (tp + fn)`` where ``tp`` is the</span>
<span class="sd">        number of true positives and ``fn`` the number of false negatives.</span>
<span class="sd">    PrecisionRecallDisplay.from_estimator : Plot precision-recall curve given</span>
<span class="sd">        an estimator and some data.</span>
<span class="sd">    PrecisionRecallDisplay.from_predictions : Plot precision-recall curve given</span>
<span class="sd">        binary class predictions.</span>
<span class="sd">    multilabel_confusion_matrix : Compute a confusion matrix for each class or</span>
<span class="sd">        sample.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    When ``true positive + false positive == 0``, precision returns 0 and</span>
<span class="sd">    raises ``UndefinedMetricWarning``. This behavior can be</span>
<span class="sd">    modified with ``zero_division``.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import precision_score</span>
<span class="sd">    &gt;&gt;&gt; y_true = [0, 1, 2, 0, 1, 2]</span>
<span class="sd">    &gt;&gt;&gt; y_pred = [0, 2, 1, 0, 0, 1]</span>
<span class="sd">    &gt;&gt;&gt; precision_score(y_true, y_pred, average=&#39;macro&#39;)</span>
<span class="sd">    0.22...</span>
<span class="sd">    &gt;&gt;&gt; precision_score(y_true, y_pred, average=&#39;micro&#39;)</span>
<span class="sd">    0.33...</span>
<span class="sd">    &gt;&gt;&gt; precision_score(y_true, y_pred, average=&#39;weighted&#39;)</span>
<span class="sd">    0.22...</span>
<span class="sd">    &gt;&gt;&gt; precision_score(y_true, y_pred, average=None)</span>
<span class="sd">    array([0.66..., 0.        , 0.        ])</span>
<span class="sd">    &gt;&gt;&gt; y_pred = [0, 0, 0, 0, 0, 0]</span>
<span class="sd">    &gt;&gt;&gt; precision_score(y_true, y_pred, average=None)</span>
<span class="sd">    array([0.33..., 0.        , 0.        ])</span>
<span class="sd">    &gt;&gt;&gt; precision_score(y_true, y_pred, average=None, zero_division=1)</span>
<span class="sd">    array([0.33..., 1.        , 1.        ])</span>
<span class="sd">    &gt;&gt;&gt; precision_score(y_true, y_pred, average=None, zero_division=np.nan)</span>
<span class="sd">    array([0.33...,        nan,        nan])</span>

<span class="sd">    &gt;&gt;&gt; # multilabel classification</span>
<span class="sd">    &gt;&gt;&gt; y_true = [[0, 0, 0], [1, 1, 1], [0, 1, 1]]</span>
<span class="sd">    &gt;&gt;&gt; y_pred = [[0, 0, 0], [1, 1, 1], [1, 1, 0]]</span>
<span class="sd">    &gt;&gt;&gt; precision_score(y_true, y_pred, average=None)</span>
<span class="sd">    array([0.5, 1. , 1. ])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">precision_recall_fscore_support</span><span class="p">(</span>
        <span class="n">y_true</span><span class="p">,</span>
        <span class="n">y_pred</span><span class="p">,</span>
        <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
        <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">,</span>
        <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>
        <span class="n">warn_for</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;precision&quot;</span><span class="p">,),</span>
        <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>


<div class="viewcode-block" id="recall_score"><a class="viewcode-back" href="../../../accuracy.html#accuracy.recall_score">[docs]</a><span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_pred&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;pos_label&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Real</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;average&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;samples&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="s2">&quot;binary&quot;</span><span class="p">}),</span>
            <span class="kc">None</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;zero_division&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="n">Options</span><span class="p">(</span><span class="n">Real</span><span class="p">,</span> <span class="p">{</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">}),</span>
            <span class="s2">&quot;nan&quot;</span><span class="p">,</span>
            <span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;warn&quot;</span><span class="p">}),</span>
        <span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">recall_score</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">average</span><span class="o">=</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">zero_division</span><span class="o">=</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the recall.</span>

<span class="sd">    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of</span>
<span class="sd">    true positives and ``fn`` the number of false negatives. The recall is</span>
<span class="sd">    intuitively the ability of the classifier to find all the positive samples.</span>

<span class="sd">    The best value is 1 and the worst value is 0.</span>

<span class="sd">    Support beyond term:`binary` targets is achieved by treating :term:`multiclass`</span>
<span class="sd">    and :term:`multilabel` data as a collection of binary problems, one for each</span>
<span class="sd">    label. For the :term:`binary` case, setting `average=&#39;binary&#39;` will return</span>
<span class="sd">    recall for `pos_label`. If `average` is not `&#39;binary&#39;`, `pos_label` is ignored</span>
<span class="sd">    and recall for both classes are computed then averaged or both returned (when</span>
<span class="sd">    `average=None`). Similarly, for :term:`multiclass` and :term:`multilabel` targets,</span>
<span class="sd">    recall for all `labels` are either returned or averaged depending on the `average`</span>
<span class="sd">    parameter. Use `labels` specify the set of labels to calculate recall for.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;precision_recall_f_measure_metrics&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : 1d array-like, or label indicator array / sparse matrix</span>
<span class="sd">        Ground truth (correct) target values.</span>

<span class="sd">    y_pred : 1d array-like, or label indicator array / sparse matrix</span>
<span class="sd">        Estimated targets as returned by a classifier.</span>

<span class="sd">    labels : array-like, default=None</span>
<span class="sd">        The set of labels to include when `average != &#39;binary&#39;`, and their</span>
<span class="sd">        order if `average is None`. Labels present in the data can be</span>
<span class="sd">        excluded, for example in multiclass classification to exclude a &quot;negative</span>
<span class="sd">        class&quot;. Labels not present in the data can be included and will be</span>
<span class="sd">        &quot;assigned&quot; 0 samples. For multilabel targets, labels are column indices.</span>
<span class="sd">        By default, all labels in `y_true` and `y_pred` are used in sorted order.</span>

<span class="sd">        .. versionchanged:: 0.17</span>
<span class="sd">           Parameter `labels` improved for multiclass problem.</span>

<span class="sd">    pos_label : int, float, bool or str, default=1</span>
<span class="sd">        The class to report if `average=&#39;binary&#39;` and the data is binary,</span>
<span class="sd">        otherwise this parameter is ignored.</span>
<span class="sd">        For multiclass or multilabel targets, set `labels=[pos_label]` and</span>
<span class="sd">        `average != &#39;binary&#39;` to report metrics for one label only.</span>

<span class="sd">    average : {&#39;micro&#39;, &#39;macro&#39;, &#39;samples&#39;, &#39;weighted&#39;, &#39;binary&#39;} or None, \</span>
<span class="sd">            default=&#39;binary&#39;</span>
<span class="sd">        This parameter is required for multiclass/multilabel targets.</span>
<span class="sd">        If ``None``, the scores for each class are returned. Otherwise, this</span>
<span class="sd">        determines the type of averaging performed on the data:</span>

<span class="sd">        ``&#39;binary&#39;``:</span>
<span class="sd">            Only report results for the class specified by ``pos_label``.</span>
<span class="sd">            This is applicable only if targets (``y_{true,pred}``) are binary.</span>
<span class="sd">        ``&#39;micro&#39;``:</span>
<span class="sd">            Calculate metrics globally by counting the total true positives,</span>
<span class="sd">            false negatives and false positives.</span>
<span class="sd">        ``&#39;macro&#39;``:</span>
<span class="sd">            Calculate metrics for each label, and find their unweighted</span>
<span class="sd">            mean.  This does not take label imbalance into account.</span>
<span class="sd">        ``&#39;weighted&#39;``:</span>
<span class="sd">            Calculate metrics for each label, and find their average weighted</span>
<span class="sd">            by support (the number of true instances for each label). This</span>
<span class="sd">            alters &#39;macro&#39; to account for label imbalance; it can result in an</span>
<span class="sd">            F-score that is not between precision and recall. Weighted recall</span>
<span class="sd">            is equal to accuracy.</span>
<span class="sd">        ``&#39;samples&#39;``:</span>
<span class="sd">            Calculate metrics for each instance, and find their average (only</span>
<span class="sd">            meaningful for multilabel classification where this differs from</span>
<span class="sd">            :func:`accuracy_score`).</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">    zero_division : {&quot;warn&quot;, 0.0, 1.0, np.nan}, default=&quot;warn&quot;</span>
<span class="sd">        Sets the value to return when there is a zero division.</span>

<span class="sd">        Notes:</span>
<span class="sd">        - If set to &quot;warn&quot;, this acts like 0, but a warning is also raised.</span>
<span class="sd">        - If set to `np.nan`, such values will be excluded from the average.</span>

<span class="sd">        .. versionadded:: 1.3</span>
<span class="sd">           `np.nan` option was added.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    recall : float (if average is not None) or array of float of shape \</span>
<span class="sd">             (n_unique_labels,)</span>
<span class="sd">        Recall of the positive class in binary classification or weighted</span>
<span class="sd">        average of the recall of each class for the multiclass task.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    precision_recall_fscore_support : Compute precision, recall, F-measure and</span>
<span class="sd">        support for each class.</span>
<span class="sd">    precision_score : Compute the ratio ``tp / (tp + fp)`` where ``tp`` is the</span>
<span class="sd">        number of true positives and ``fp`` the number of false positives.</span>
<span class="sd">    balanced_accuracy_score : Compute balanced accuracy to deal with imbalanced</span>
<span class="sd">        datasets.</span>
<span class="sd">    multilabel_confusion_matrix : Compute a confusion matrix for each class or</span>
<span class="sd">        sample.</span>
<span class="sd">    PrecisionRecallDisplay.from_estimator : Plot precision-recall curve given</span>
<span class="sd">        an estimator and some data.</span>
<span class="sd">    PrecisionRecallDisplay.from_predictions : Plot precision-recall curve given</span>
<span class="sd">        binary class predictions.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    When ``true positive + false negative == 0``, recall returns 0 and raises</span>
<span class="sd">    ``UndefinedMetricWarning``. This behavior can be modified with</span>
<span class="sd">    ``zero_division``.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import recall_score</span>
<span class="sd">    &gt;&gt;&gt; y_true = [0, 1, 2, 0, 1, 2]</span>
<span class="sd">    &gt;&gt;&gt; y_pred = [0, 2, 1, 0, 0, 1]</span>
<span class="sd">    &gt;&gt;&gt; recall_score(y_true, y_pred, average=&#39;macro&#39;)</span>
<span class="sd">    0.33...</span>
<span class="sd">    &gt;&gt;&gt; recall_score(y_true, y_pred, average=&#39;micro&#39;)</span>
<span class="sd">    0.33...</span>
<span class="sd">    &gt;&gt;&gt; recall_score(y_true, y_pred, average=&#39;weighted&#39;)</span>
<span class="sd">    0.33...</span>
<span class="sd">    &gt;&gt;&gt; recall_score(y_true, y_pred, average=None)</span>
<span class="sd">    array([1., 0., 0.])</span>
<span class="sd">    &gt;&gt;&gt; y_true = [0, 0, 0, 0, 0, 0]</span>
<span class="sd">    &gt;&gt;&gt; recall_score(y_true, y_pred, average=None)</span>
<span class="sd">    array([0.5, 0. , 0. ])</span>
<span class="sd">    &gt;&gt;&gt; recall_score(y_true, y_pred, average=None, zero_division=1)</span>
<span class="sd">    array([0.5, 1. , 1. ])</span>
<span class="sd">    &gt;&gt;&gt; recall_score(y_true, y_pred, average=None, zero_division=np.nan)</span>
<span class="sd">    array([0.5, nan, nan])</span>

<span class="sd">    &gt;&gt;&gt; # multilabel classification</span>
<span class="sd">    &gt;&gt;&gt; y_true = [[0, 0, 0], [1, 1, 1], [0, 1, 1]]</span>
<span class="sd">    &gt;&gt;&gt; y_pred = [[0, 0, 0], [1, 1, 1], [1, 1, 0]]</span>
<span class="sd">    &gt;&gt;&gt; recall_score(y_true, y_pred, average=None)</span>
<span class="sd">    array([1. , 1. , 0.5])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">precision_recall_fscore_support</span><span class="p">(</span>
        <span class="n">y_true</span><span class="p">,</span>
        <span class="n">y_pred</span><span class="p">,</span>
        <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
        <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">,</span>
        <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>
        <span class="n">warn_for</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;recall&quot;</span><span class="p">,),</span>
        <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">r</span></div>


<div class="viewcode-block" id="balanced_accuracy_score"><a class="viewcode-back" href="../../../accuracy.html#accuracy.balanced_accuracy_score">[docs]</a><span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_pred&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;adjusted&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;boolean&quot;</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">balanced_accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">adjusted</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the balanced accuracy.</span>

<span class="sd">    The balanced accuracy in binary and multiclass classification problems to</span>
<span class="sd">    deal with imbalanced datasets. It is defined as the average of recall</span>
<span class="sd">    obtained on each class.</span>

<span class="sd">    The best value is 1 and the worst value is 0 when ``adjusted=False``.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;balanced_accuracy_score&gt;`.</span>

<span class="sd">    .. versionadded:: 0.20</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : array-like of shape (n_samples,)</span>
<span class="sd">        Ground truth (correct) target values.</span>

<span class="sd">    y_pred : array-like of shape (n_samples,)</span>
<span class="sd">        Estimated targets as returned by a classifier.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">    adjusted : bool, default=False</span>
<span class="sd">        When true, the result is adjusted for chance, so that random</span>
<span class="sd">        performance would score 0, while keeping perfect performance at a score</span>
<span class="sd">        of 1.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    balanced_accuracy : float</span>
<span class="sd">        Balanced accuracy score.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    average_precision_score : Compute average precision (AP) from prediction</span>
<span class="sd">        scores.</span>
<span class="sd">    precision_score : Compute the precision score.</span>
<span class="sd">    recall_score : Compute the recall score.</span>
<span class="sd">    roc_auc_score : Compute Area Under the Receiver Operating Characteristic</span>
<span class="sd">        Curve (ROC AUC) from prediction scores.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Some literature promotes alternative definitions of balanced accuracy. Our</span>
<span class="sd">    definition is equivalent to :func:`accuracy_score` with class-balanced</span>
<span class="sd">    sample weights, and shares desirable properties with the binary case.</span>
<span class="sd">    See the :ref:`User Guide &lt;balanced_accuracy_score&gt;`.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Brodersen, K.H.; Ong, C.S.; Stephan, K.E.; Buhmann, J.M. (2010).</span>
<span class="sd">           The balanced accuracy and its posterior distribution.</span>
<span class="sd">           Proceedings of the 20th International Conference on Pattern</span>
<span class="sd">           Recognition, 3121-24.</span>
<span class="sd">    .. [2] John. D. Kelleher, Brian Mac Namee, Aoife D&#39;Arcy, (2015).</span>
<span class="sd">           `Fundamentals of Machine Learning for Predictive Data Analytics:</span>
<span class="sd">           Algorithms, Worked Examples, and Case Studies</span>
<span class="sd">           &lt;https://mitpress.mit.edu/books/fundamentals-machine-learning-predictive-data-analytics&gt;`_.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import balanced_accuracy_score</span>
<span class="sd">    &gt;&gt;&gt; y_true = [0, 1, 0, 0, 1, 0]</span>
<span class="sd">    &gt;&gt;&gt; y_pred = [0, 1, 0, 0, 0, 1]</span>
<span class="sd">    &gt;&gt;&gt; balanced_accuracy_score(y_true, y_pred)</span>
<span class="sd">    0.625</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">C</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">errstate</span><span class="p">(</span><span class="n">divide</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">invalid</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">):</span>
        <span class="n">per_class</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">C</span><span class="p">)</span> <span class="o">/</span> <span class="n">C</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">per_class</span><span class="p">)):</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;y_pred contains classes not in y_true&quot;</span><span class="p">)</span>
        <span class="n">per_class</span> <span class="o">=</span> <span class="n">per_class</span><span class="p">[</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">per_class</span><span class="p">)]</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">per_class</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">adjusted</span><span class="p">:</span>
        <span class="n">n_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">per_class</span><span class="p">)</span>
        <span class="n">chance</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">n_classes</span>
        <span class="n">score</span> <span class="o">-=</span> <span class="n">chance</span>
        <span class="n">score</span> <span class="o">/=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">chance</span>
    <span class="k">return</span> <span class="n">score</span></div>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_pred&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;target_names&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;digits&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">Integral</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)],</span>
        <span class="s2">&quot;output_dict&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;boolean&quot;</span><span class="p">],</span>
        <span class="s2">&quot;zero_division&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="n">Options</span><span class="p">(</span><span class="n">Real</span><span class="p">,</span> <span class="p">{</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">}),</span>
            <span class="s2">&quot;nan&quot;</span><span class="p">,</span>
            <span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;warn&quot;</span><span class="p">}),</span>
        <span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">classification_report</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">target_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">digits</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">output_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">zero_division</span><span class="o">=</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Build a text report showing the main classification metrics.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;classification_report&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : 1d array-like, or label indicator array / sparse matrix</span>
<span class="sd">        Ground truth (correct) target values.</span>

<span class="sd">    y_pred : 1d array-like, or label indicator array / sparse matrix</span>
<span class="sd">        Estimated targets as returned by a classifier.</span>

<span class="sd">    labels : array-like of shape (n_labels,), default=None</span>
<span class="sd">        Optional list of label indices to include in the report.</span>

<span class="sd">    target_names : array-like of shape (n_labels,), default=None</span>
<span class="sd">        Optional display names matching the labels (same order).</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">    digits : int, default=2</span>
<span class="sd">        Number of digits for formatting output floating point values.</span>
<span class="sd">        When ``output_dict`` is ``True``, this will be ignored and the</span>
<span class="sd">        returned values will not be rounded.</span>

<span class="sd">    output_dict : bool, default=False</span>
<span class="sd">        If True, return output as dict.</span>

<span class="sd">        .. versionadded:: 0.20</span>

<span class="sd">    zero_division : {&quot;warn&quot;, 0.0, 1.0, np.nan}, default=&quot;warn&quot;</span>
<span class="sd">        Sets the value to return when there is a zero division. If set to</span>
<span class="sd">        &quot;warn&quot;, this acts as 0, but warnings are also raised.</span>

<span class="sd">        .. versionadded:: 1.3</span>
<span class="sd">           `np.nan` option was added.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    report : str or dict</span>
<span class="sd">        Text summary of the precision, recall, F1 score for each class.</span>
<span class="sd">        Dictionary returned if output_dict is True. Dictionary has the</span>
<span class="sd">        following structure::</span>

<span class="sd">            {&#39;label 1&#39;: {&#39;precision&#39;:0.5,</span>
<span class="sd">                         &#39;recall&#39;:1.0,</span>
<span class="sd">                         &#39;f1-score&#39;:0.67,</span>
<span class="sd">                         &#39;support&#39;:1},</span>
<span class="sd">             &#39;label 2&#39;: { ... },</span>
<span class="sd">              ...</span>
<span class="sd">            }</span>

<span class="sd">        The reported averages include macro average (averaging the unweighted</span>
<span class="sd">        mean per label), weighted average (averaging the support-weighted mean</span>
<span class="sd">        per label), and sample average (only for multilabel classification).</span>
<span class="sd">        Micro average (averaging the total true positives, false negatives and</span>
<span class="sd">        false positives) is only shown for multi-label or multi-class</span>
<span class="sd">        with a subset of classes, because it corresponds to accuracy</span>
<span class="sd">        otherwise and would be the same for all metrics.</span>
<span class="sd">        See also :func:`precision_recall_fscore_support` for more details</span>
<span class="sd">        on averages.</span>

<span class="sd">        Note that in binary classification, recall of the positive class</span>
<span class="sd">        is also known as &quot;sensitivity&quot;; recall of the negative class is</span>
<span class="sd">        &quot;specificity&quot;.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    precision_recall_fscore_support: Compute precision, recall, F-measure and</span>
<span class="sd">        support for each class.</span>
<span class="sd">    confusion_matrix: Compute confusion matrix to evaluate the accuracy of a</span>
<span class="sd">        classification.</span>
<span class="sd">    multilabel_confusion_matrix: Compute a confusion matrix for each class or sample.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import classification_report</span>
<span class="sd">    &gt;&gt;&gt; y_true = [0, 1, 2, 2, 2]</span>
<span class="sd">    &gt;&gt;&gt; y_pred = [0, 0, 2, 2, 1]</span>
<span class="sd">    &gt;&gt;&gt; target_names = [&#39;class 0&#39;, &#39;class 1&#39;, &#39;class 2&#39;]</span>
<span class="sd">    &gt;&gt;&gt; print(classification_report(y_true, y_pred, target_names=target_names))</span>
<span class="sd">                  precision    recall  f1-score   support</span>
<span class="sd">    &lt;BLANKLINE&gt;</span>
<span class="sd">         class 0       0.50      1.00      0.67         1</span>
<span class="sd">         class 1       0.00      0.00      0.00         1</span>
<span class="sd">         class 2       1.00      0.67      0.80         3</span>
<span class="sd">    &lt;BLANKLINE&gt;</span>
<span class="sd">        accuracy                           0.60         5</span>
<span class="sd">       macro avg       0.50      0.56      0.49         5</span>
<span class="sd">    weighted avg       0.70      0.60      0.61         5</span>
<span class="sd">    &lt;BLANKLINE&gt;</span>
<span class="sd">    &gt;&gt;&gt; y_pred = [1, 1, 0]</span>
<span class="sd">    &gt;&gt;&gt; y_true = [1, 1, 1]</span>
<span class="sd">    &gt;&gt;&gt; print(classification_report(y_true, y_pred, labels=[1, 2, 3]))</span>
<span class="sd">                  precision    recall  f1-score   support</span>
<span class="sd">    &lt;BLANKLINE&gt;</span>
<span class="sd">               1       1.00      0.67      0.80         3</span>
<span class="sd">               2       0.00      0.00      0.00         0</span>
<span class="sd">               3       0.00      0.00      0.00         0</span>
<span class="sd">    &lt;BLANKLINE&gt;</span>
<span class="sd">       micro avg       1.00      0.67      0.80         3</span>
<span class="sd">       macro avg       0.33      0.22      0.27         3</span>
<span class="sd">    weighted avg       1.00      0.67      0.80         3</span>
<span class="sd">    &lt;BLANKLINE&gt;</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">y_type</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">_check_targets</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">unique_labels</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
        <span class="n">labels_given</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">labels_given</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># labelled micro average</span>
    <span class="n">micro_is_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_type</span> <span class="o">==</span> <span class="s2">&quot;multiclass&quot;</span> <span class="ow">or</span> <span class="n">y_type</span> <span class="o">==</span> <span class="s2">&quot;binary&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
        <span class="ow">not</span> <span class="n">labels_given</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span> <span class="o">==</span> <span class="nb">set</span><span class="p">(</span><span class="n">unique_labels</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">target_names</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_names</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">labels_given</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;labels size, </span><span class="si">{0}</span><span class="s2">, does not match size of target_names, </span><span class="si">{1}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_names</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Number of classes, </span><span class="si">{0}</span><span class="s2">, does not match size of &quot;</span>
                <span class="s2">&quot;target_names, </span><span class="si">{1}</span><span class="s2">. Try specifying the labels &quot;</span>
                <span class="s2">&quot;parameter&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_names</span><span class="p">))</span>
            <span class="p">)</span>
    <span class="k">if</span> <span class="n">target_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">target_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">l</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">]</span>

    <span class="n">headers</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;precision&quot;</span><span class="p">,</span> <span class="s2">&quot;recall&quot;</span><span class="p">,</span> <span class="s2">&quot;f1-score&quot;</span><span class="p">,</span> <span class="s2">&quot;support&quot;</span><span class="p">]</span>
    <span class="c1"># compute per-class results without averaging</span>
    <span class="n">p</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">f1</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">precision_recall_fscore_support</span><span class="p">(</span>
        <span class="n">y_true</span><span class="p">,</span>
        <span class="n">y_pred</span><span class="p">,</span>
        <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
        <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">target_names</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">f1</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">y_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;multilabel&quot;</span><span class="p">):</span>
        <span class="n">average_options</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="s2">&quot;samples&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">average_options</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">output_dict</span><span class="p">:</span>
        <span class="n">report_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">label</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="n">label</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">rows</span><span class="p">}</span>
        <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">scores</span> <span class="ow">in</span> <span class="n">report_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">report_dict</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">headers</span><span class="p">,</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">]))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">longest_last_line_heading</span> <span class="o">=</span> <span class="s2">&quot;weighted avg&quot;</span>
        <span class="n">name_width</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cn</span><span class="p">)</span> <span class="k">for</span> <span class="n">cn</span> <span class="ow">in</span> <span class="n">target_names</span><span class="p">)</span>
        <span class="n">width</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">name_width</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">longest_last_line_heading</span><span class="p">),</span> <span class="n">digits</span><span class="p">)</span>
        <span class="n">head_fmt</span> <span class="o">=</span> <span class="s2">&quot;{:&gt;</span><span class="si">{width}</span><span class="s2">s} &quot;</span> <span class="o">+</span> <span class="s2">&quot; </span><span class="si">{:&gt;9}</span><span class="s2">&quot;</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">headers</span><span class="p">)</span>
        <span class="n">report</span> <span class="o">=</span> <span class="n">head_fmt</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="o">*</span><span class="n">headers</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="n">width</span><span class="p">)</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span>
        <span class="n">row_fmt</span> <span class="o">=</span> <span class="s2">&quot;{:&gt;</span><span class="si">{width}</span><span class="s2">s} &quot;</span> <span class="o">+</span> <span class="s2">&quot; {:&gt;9.</span><span class="si">{digits}</span><span class="s2">f}&quot;</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">+</span> <span class="s2">&quot; </span><span class="si">{:&gt;9}</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">rows</span><span class="p">:</span>
            <span class="n">report</span> <span class="o">+=</span> <span class="n">row_fmt</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">row</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="n">width</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="n">digits</span><span class="p">)</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>

    <span class="c1"># compute all applicable averages</span>
    <span class="k">for</span> <span class="n">average</span> <span class="ow">in</span> <span class="n">average_options</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">average</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;micro&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">micro_is_accuracy</span><span class="p">:</span>
            <span class="n">line_heading</span> <span class="o">=</span> <span class="s2">&quot;accuracy&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">line_heading</span> <span class="o">=</span> <span class="n">average</span> <span class="o">+</span> <span class="s2">&quot; avg&quot;</span>

        <span class="c1"># compute averages with specified averaging method</span>
        <span class="n">avg_p</span><span class="p">,</span> <span class="n">avg_r</span><span class="p">,</span> <span class="n">avg_f1</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">precision_recall_fscore_support</span><span class="p">(</span>
            <span class="n">y_true</span><span class="p">,</span>
            <span class="n">y_pred</span><span class="p">,</span>
            <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
            <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>
            <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
            <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">avg</span> <span class="o">=</span> <span class="p">[</span><span class="n">avg_p</span><span class="p">,</span> <span class="n">avg_r</span><span class="p">,</span> <span class="n">avg_f1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">s</span><span class="p">)]</span>

        <span class="k">if</span> <span class="n">output_dict</span><span class="p">:</span>
            <span class="n">report_dict</span><span class="p">[</span><span class="n">line_heading</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">headers</span><span class="p">,</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">avg</span><span class="p">]))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">line_heading</span> <span class="o">==</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">:</span>
                <span class="n">row_fmt_accuracy</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="s2">&quot;{:&gt;</span><span class="si">{width}</span><span class="s2">s} &quot;</span>
                    <span class="o">+</span> <span class="s2">&quot; {:&gt;9.</span><span class="si">{digits}</span><span class="s2">}&quot;</span> <span class="o">*</span> <span class="mi">2</span>
                    <span class="o">+</span> <span class="s2">&quot; {:&gt;9.</span><span class="si">{digits}</span><span class="s2">f}&quot;</span>
                    <span class="o">+</span> <span class="s2">&quot; </span><span class="si">{:&gt;9}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="p">)</span>
                <span class="n">report</span> <span class="o">+=</span> <span class="n">row_fmt_accuracy</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">line_heading</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="o">*</span><span class="n">avg</span><span class="p">[</span><span class="mi">2</span><span class="p">:],</span> <span class="n">width</span><span class="o">=</span><span class="n">width</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="n">digits</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">report</span> <span class="o">+=</span> <span class="n">row_fmt</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">line_heading</span><span class="p">,</span> <span class="o">*</span><span class="n">avg</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="n">width</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="n">digits</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">output_dict</span><span class="p">:</span>
        <span class="k">if</span> <span class="s2">&quot;accuracy&quot;</span> <span class="ow">in</span> <span class="n">report_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">report_dict</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">report_dict</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">][</span><span class="s2">&quot;precision&quot;</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">report_dict</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">report</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_pred&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">hamming_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the average Hamming loss.</span>

<span class="sd">    The Hamming loss is the fraction of labels that are incorrectly predicted.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;hamming_loss&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : 1d array-like, or label indicator array / sparse matrix</span>
<span class="sd">        Ground truth (correct) labels.</span>

<span class="sd">    y_pred : 1d array-like, or label indicator array / sparse matrix</span>
<span class="sd">        Predicted labels, as returned by a classifier.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">        .. versionadded:: 0.18</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    loss : float or int</span>
<span class="sd">        Return the average Hamming loss between element of ``y_true`` and</span>
<span class="sd">        ``y_pred``.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    accuracy_score : Compute the accuracy score. By default, the function will</span>
<span class="sd">        return the fraction of correct predictions divided by the total number</span>
<span class="sd">        of predictions.</span>
<span class="sd">    jaccard_score : Compute the Jaccard similarity coefficient score.</span>
<span class="sd">    zero_one_loss : Compute the Zero-one classification loss. By default, the</span>
<span class="sd">        function will return the percentage of imperfectly predicted subsets.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    In multiclass classification, the Hamming loss corresponds to the Hamming</span>
<span class="sd">    distance between ``y_true`` and ``y_pred`` which is equivalent to the</span>
<span class="sd">    subset ``zero_one_loss`` function, when `normalize` parameter is set to</span>
<span class="sd">    True.</span>

<span class="sd">    In multilabel classification, the Hamming loss is different from the</span>
<span class="sd">    subset zero-one loss. The zero-one loss considers the entire set of labels</span>
<span class="sd">    for a given sample incorrect if it does not entirely match the true set of</span>
<span class="sd">    labels. Hamming loss is more forgiving in that it penalizes only the</span>
<span class="sd">    individual labels.</span>

<span class="sd">    The Hamming loss is upperbounded by the subset zero-one loss, when</span>
<span class="sd">    `normalize` parameter is set to True. It is always between 0 and 1,</span>
<span class="sd">    lower being better.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Grigorios Tsoumakas, Ioannis Katakis. Multi-Label Classification:</span>
<span class="sd">           An Overview. International Journal of Data Warehousing &amp; Mining,</span>
<span class="sd">           3(3), 1-13, July-September 2007.</span>

<span class="sd">    .. [2] `Wikipedia entry on the Hamming distance</span>
<span class="sd">           &lt;https://en.wikipedia.org/wiki/Hamming_distance&gt;`_.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import hamming_loss</span>
<span class="sd">    &gt;&gt;&gt; y_pred = [1, 2, 3, 4]</span>
<span class="sd">    &gt;&gt;&gt; y_true = [2, 2, 3, 4]</span>
<span class="sd">    &gt;&gt;&gt; hamming_loss(y_true, y_pred)</span>
<span class="sd">    0.25</span>

<span class="sd">    In the multilabel case with binary label indicators:</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; hamming_loss(np.array([[0, 1], [1, 1]]), np.zeros((2, 2)))</span>
<span class="sd">    0.75</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">y_type</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">_check_targets</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">check_consistent_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">weight_average</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">weight_average</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">y_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;multilabel&quot;</span><span class="p">):</span>
        <span class="n">n_differences</span> <span class="o">=</span> <span class="n">count_nonzero</span><span class="p">(</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">n_differences</span> <span class="o">/</span> <span class="p">(</span><span class="n">y_true</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">y_true</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">weight_average</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">y_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">_weighted_sum</span><span class="p">(</span><span class="n">y_true</span> <span class="o">!=</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{0}</span><span class="s2"> is not supported&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_type</span><span class="p">))</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_pred&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;eps&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;auto&quot;</span><span class="p">}),</span> <span class="n">Interval</span><span class="p">(</span><span class="n">Real</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">)],</span>
        <span class="s2">&quot;normalize&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;boolean&quot;</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">log_loss</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Log loss, aka logistic loss or cross-entropy loss.</span>

<span class="sd">    This is the loss function used in (multinomial) logistic regression</span>
<span class="sd">    and extensions of it such as neural networks, defined as the negative</span>
<span class="sd">    log-likelihood of a logistic model that returns ``y_pred`` probabilities</span>
<span class="sd">    for its training data ``y_true``.</span>
<span class="sd">    The log loss is only defined for two or more labels.</span>
<span class="sd">    For a single sample with true label :math:`y \in \{0,1\}` and</span>
<span class="sd">    a probability estimate :math:`p = \operatorname{Pr}(y = 1)`, the log</span>
<span class="sd">    loss is:</span>

<span class="sd">    .. math::</span>
<span class="sd">        L_{\log}(y, p) = -(y \log (p) + (1 - y) \log (1 - p))</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;log_loss&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : array-like or label indicator matrix</span>
<span class="sd">        Ground truth (correct) labels for n_samples samples.</span>

<span class="sd">    y_pred : array-like of float, shape = (n_samples, n_classes) or (n_samples,)</span>
<span class="sd">        Predicted probabilities, as returned by a classifier&#39;s</span>
<span class="sd">        predict_proba method. If ``y_pred.shape = (n_samples,)``</span>
<span class="sd">        the probabilities provided are assumed to be that of the</span>
<span class="sd">        positive class. The labels in ``y_pred`` are assumed to be</span>
<span class="sd">        ordered alphabetically, as done by</span>
<span class="sd">        :class:`~sklearn.preprocessing.LabelBinarizer`.</span>

<span class="sd">    eps : float or &quot;auto&quot;, default=&quot;auto&quot;</span>
<span class="sd">        Log loss is undefined for p=0 or p=1, so probabilities are</span>
<span class="sd">        clipped to `max(eps, min(1 - eps, p))`. The default will depend on the</span>
<span class="sd">        data type of `y_pred` and is set to `np.finfo(y_pred.dtype).eps`.</span>

<span class="sd">        .. versionadded:: 1.2</span>

<span class="sd">        .. versionchanged:: 1.2</span>
<span class="sd">           The default value changed from `1e-15` to `&quot;auto&quot;` that is</span>
<span class="sd">           equivalent to `np.finfo(y_pred.dtype).eps`.</span>

<span class="sd">        .. deprecated:: 1.3</span>
<span class="sd">           `eps` is deprecated in 1.3 and will be removed in 1.5.</span>

<span class="sd">    normalize : bool, default=True</span>
<span class="sd">        If true, return the mean loss per sample.</span>
<span class="sd">        Otherwise, return the sum of the per-sample losses.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">    labels : array-like, default=None</span>
<span class="sd">        If not provided, labels will be inferred from y_true. If ``labels``</span>
<span class="sd">        is ``None`` and ``y_pred`` has shape (n_samples,) the labels are</span>
<span class="sd">        assumed to be binary and are inferred from ``y_true``.</span>

<span class="sd">        .. versionadded:: 0.18</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    loss : float</span>
<span class="sd">        Log loss, aka logistic loss or cross-entropy loss.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The logarithm used is the natural logarithm (base-e).</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    C.M. Bishop (2006). Pattern Recognition and Machine Learning. Springer,</span>
<span class="sd">    p. 209.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import log_loss</span>
<span class="sd">    &gt;&gt;&gt; log_loss([&quot;spam&quot;, &quot;ham&quot;, &quot;ham&quot;, &quot;spam&quot;],</span>
<span class="sd">    ...          [[.1, .9], [.9, .1], [.8, .2], [.35, .65]])</span>
<span class="sd">    0.21616...</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span>
        <span class="n">y_pred</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float16</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">eps</span> <span class="o">==</span> <span class="s2">&quot;auto&quot;</span><span class="p">:</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">y_pred</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># TODO: Remove user defined eps in 1.5</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="s2">&quot;Setting the eps parameter is deprecated and will &quot;</span>
                <span class="s2">&quot;be removed in 1.5. Instead eps will always have&quot;</span>
                <span class="s2">&quot;a default value of `np.finfo(y_pred.dtype).eps`.&quot;</span>
            <span class="p">),</span>
            <span class="ne">FutureWarning</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">check_consistent_length</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>
    <span class="n">lb</span> <span class="o">=</span> <span class="n">LabelBinarizer</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">lb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">lb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lb</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;y_true contains only one label (</span><span class="si">{0}</span><span class="s2">). Please &quot;</span>
                <span class="s2">&quot;provide the true labels explicitly through the &quot;</span>
                <span class="s2">&quot;labels argument.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lb</span><span class="o">.</span><span class="n">classes_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The labels array needs to contain at least two &quot;</span>
                <span class="s2">&quot;labels for log_loss, &quot;</span>
                <span class="s2">&quot;got </span><span class="si">{0}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lb</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
            <span class="p">)</span>

    <span class="n">transformed_labels</span> <span class="o">=</span> <span class="n">lb</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">transformed_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">transformed_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="mi">1</span> <span class="o">-</span> <span class="n">transformed_labels</span><span class="p">,</span> <span class="n">transformed_labels</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>

    <span class="c1"># Clipping</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">eps</span><span class="p">)</span>

    <span class="c1"># If y_pred is of single dimension, assume y_true to be binary</span>
    <span class="c1"># and then check.</span>
    <span class="k">if</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Check if dimensions are consistent.</span>
    <span class="n">transformed_labels</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">transformed_labels</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lb</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span> <span class="o">!=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;y_true and y_pred contain different number of &quot;</span>
                <span class="s2">&quot;classes </span><span class="si">{0}</span><span class="s2">, </span><span class="si">{1}</span><span class="s2">. Please provide the true &quot;</span>
                <span class="s2">&quot;labels explicitly through the labels argument. &quot;</span>
                <span class="s2">&quot;Classes found in &quot;</span>
                <span class="s2">&quot;y_true: </span><span class="si">{2}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">transformed_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">lb</span><span class="o">.</span><span class="n">classes_</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The number of classes in labels is different &quot;</span>
                <span class="s2">&quot;from that in y_pred. Classes found in &quot;</span>
                <span class="s2">&quot;labels: </span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lb</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
            <span class="p">)</span>

    <span class="c1"># Renormalize</span>
    <span class="n">y_pred_sum</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">y_pred_sum</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-15</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mi">5</span> <span class="o">*</span> <span class="n">eps</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="s2">&quot;The y_pred values do not sum to one. Starting from 1.5 this&quot;</span>
                <span class="s2">&quot;will result in an error.&quot;</span>
            <span class="p">),</span>
            <span class="ne">UserWarning</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">/</span> <span class="n">y_pred_sum</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">xlogy</span><span class="p">(</span><span class="n">transformed_labels</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">_weighted_sum</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="n">normalize</span><span class="p">)</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;pred_decision&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">hinge_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">pred_decision</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Average hinge loss (non-regularized).</span>

<span class="sd">    In binary class case, assuming labels in y_true are encoded with +1 and -1,</span>
<span class="sd">    when a prediction mistake is made, ``margin = y_true * pred_decision`` is</span>
<span class="sd">    always negative (since the signs disagree), implying ``1 - margin`` is</span>
<span class="sd">    always greater than 1.  The cumulated hinge loss is therefore an upper</span>
<span class="sd">    bound of the number of mistakes made by the classifier.</span>

<span class="sd">    In multiclass case, the function expects that either all the labels are</span>
<span class="sd">    included in y_true or an optional labels argument is provided which</span>
<span class="sd">    contains all the labels. The multilabel margin is calculated according</span>
<span class="sd">    to Crammer-Singer&#39;s method. As in the binary case, the cumulated hinge loss</span>
<span class="sd">    is an upper bound of the number of mistakes made by the classifier.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;hinge_loss&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : array-like of shape (n_samples,)</span>
<span class="sd">        True target, consisting of integers of two values. The positive label</span>
<span class="sd">        must be greater than the negative label.</span>

<span class="sd">    pred_decision : array-like of shape (n_samples,) or (n_samples, n_classes)</span>
<span class="sd">        Predicted decisions, as output by decision_function (floats).</span>

<span class="sd">    labels : array-like, default=None</span>
<span class="sd">        Contains all the labels for the problem. Used in multiclass hinge loss.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    loss : float</span>
<span class="sd">        Average hinge loss.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] `Wikipedia entry on the Hinge loss</span>
<span class="sd">           &lt;https://en.wikipedia.org/wiki/Hinge_loss&gt;`_.</span>

<span class="sd">    .. [2] Koby Crammer, Yoram Singer. On the Algorithmic</span>
<span class="sd">           Implementation of Multiclass Kernel-based Vector</span>
<span class="sd">           Machines. Journal of Machine Learning Research 2,</span>
<span class="sd">           (2001), 265-292.</span>

<span class="sd">    .. [3] `L1 AND L2 Regularization for Multiclass Hinge Loss Models</span>
<span class="sd">           by Robert C. Moore, John DeNero</span>
<span class="sd">           &lt;https://storage.googleapis.com/pub-tools-public-publication-data/pdf/37362.pdf&gt;`_.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn import svm</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import hinge_loss</span>
<span class="sd">    &gt;&gt;&gt; X = [[0], [1]]</span>
<span class="sd">    &gt;&gt;&gt; y = [-1, 1]</span>
<span class="sd">    &gt;&gt;&gt; est = svm.LinearSVC(dual=&quot;auto&quot;, random_state=0)</span>
<span class="sd">    &gt;&gt;&gt; est.fit(X, y)</span>
<span class="sd">    LinearSVC(dual=&#39;auto&#39;, random_state=0)</span>
<span class="sd">    &gt;&gt;&gt; pred_decision = est.decision_function([[-2], [3], [0.5]])</span>
<span class="sd">    &gt;&gt;&gt; pred_decision</span>
<span class="sd">    array([-2.18...,  2.36...,  0.09...])</span>
<span class="sd">    &gt;&gt;&gt; hinge_loss([-1, 1, 1], pred_decision)</span>
<span class="sd">    0.30...</span>

<span class="sd">    In the multiclass case:</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[0], [1], [2], [3]])</span>
<span class="sd">    &gt;&gt;&gt; Y = np.array([0, 1, 2, 3])</span>
<span class="sd">    &gt;&gt;&gt; labels = np.array([0, 1, 2, 3])</span>
<span class="sd">    &gt;&gt;&gt; est = svm.LinearSVC(dual=&quot;auto&quot;)</span>
<span class="sd">    &gt;&gt;&gt; est.fit(X, Y)</span>
<span class="sd">    LinearSVC(dual=&#39;auto&#39;)</span>
<span class="sd">    &gt;&gt;&gt; pred_decision = est.decision_function([[-1], [2], [3]])</span>
<span class="sd">    &gt;&gt;&gt; y_true = [0, 2, 3]</span>
<span class="sd">    &gt;&gt;&gt; hinge_loss(y_true, pred_decision, labels=labels)</span>
<span class="sd">    0.56...</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">check_consistent_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">pred_decision</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>
    <span class="n">pred_decision</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">pred_decision</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">y_true_unique</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels</span> <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">y_true</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">y_true_unique</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">pred_decision</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The shape of pred_decision cannot be 1d array&quot;</span>
                <span class="s2">&quot;with a multiclass target. pred_decision shape &quot;</span>
                <span class="s2">&quot;must be (n_samples, n_classes), that is &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;(</span><span class="si">{</span><span class="n">y_true</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">y_true_unique</span><span class="o">.</span><span class="n">size</span><span class="si">}</span><span class="s2">).&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; Got: </span><span class="si">{</span><span class="n">pred_decision</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># pred_decision.ndim &gt; 1 is true</span>
        <span class="k">if</span> <span class="n">y_true_unique</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="n">pred_decision</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Please include all labels in y_true &quot;</span>
                    <span class="s2">&quot;or pass labels as third argument&quot;</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;The shape of pred_decision is not &quot;</span>
                    <span class="s2">&quot;consistent with the number of classes. &quot;</span>
                    <span class="s2">&quot;With a multiclass target, pred_decision &quot;</span>
                    <span class="s2">&quot;shape must be &quot;</span>
                    <span class="s2">&quot;(n_samples, n_classes), that is &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;(</span><span class="si">{</span><span class="n">y_true</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">y_true_unique</span><span class="o">.</span><span class="n">size</span><span class="si">}</span><span class="s2">). &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Got: </span><span class="si">{</span><span class="n">pred_decision</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">y_true_unique</span>
        <span class="n">le</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
        <span class="n">le</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">y_true</span> <span class="o">=</span> <span class="n">le</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">pred_decision</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
        <span class="n">mask</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y_true</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">y_true</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">margin</span> <span class="o">=</span> <span class="n">pred_decision</span><span class="p">[</span><span class="o">~</span><span class="n">mask</span><span class="p">]</span>
        <span class="n">margin</span> <span class="o">-=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">pred_decision</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y_true</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Handles binary class case</span>
        <span class="c1"># this code assumes that positive and negative labels</span>
        <span class="c1"># are encoded as +1 and -1 respectively</span>
        <span class="n">pred_decision</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">pred_decision</span><span class="p">)</span>
        <span class="n">pred_decision</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">pred_decision</span><span class="p">)</span>

        <span class="n">lbin</span> <span class="o">=</span> <span class="n">LabelBinarizer</span><span class="p">(</span><span class="n">neg_label</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">y_true</span> <span class="o">=</span> <span class="n">lbin</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y_true</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">margin</span> <span class="o">=</span> <span class="n">y_true</span> <span class="o">*</span> <span class="n">pred_decision</span>
        <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;pred_decision should be an array of floats.&quot;</span><span class="p">)</span>

    <span class="n">losses</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">margin</span>
    <span class="c1"># The hinge_loss doesn&#39;t penalize good enough predictions.</span>
    <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">losses</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_prob&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;pos_label&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Real</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">brier_score_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_prob</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the Brier score loss.</span>

<span class="sd">    The smaller the Brier score loss, the better, hence the naming with &quot;loss&quot;.</span>
<span class="sd">    The Brier score measures the mean squared difference between the predicted</span>
<span class="sd">    probability and the actual outcome. The Brier score always</span>
<span class="sd">    takes on a value between zero and one, since this is the largest</span>
<span class="sd">    possible difference between a predicted probability (which must be</span>
<span class="sd">    between zero and one) and the actual outcome (which can take on values</span>
<span class="sd">    of only 0 and 1). It can be decomposed as the sum of refinement loss and</span>
<span class="sd">    calibration loss.</span>

<span class="sd">    The Brier score is appropriate for binary and categorical outcomes that</span>
<span class="sd">    can be structured as true or false, but is inappropriate for ordinal</span>
<span class="sd">    variables which can take on three or more values (this is because the</span>
<span class="sd">    Brier score assumes that all possible outcomes are equivalently</span>
<span class="sd">    &quot;distant&quot; from one another). Which label is considered to be the positive</span>
<span class="sd">    label is controlled via the parameter `pos_label`, which defaults to</span>
<span class="sd">    the greater label unless `y_true` is all 0 or all -1, in which case</span>
<span class="sd">    `pos_label` defaults to 1.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;brier_score_loss&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : array-like of shape (n_samples,)</span>
<span class="sd">        True targets.</span>

<span class="sd">    y_prob : array-like of shape (n_samples,)</span>
<span class="sd">        Probabilities of the positive class.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">    pos_label : int, float, bool or str, default=None</span>
<span class="sd">        Label of the positive class. `pos_label` will be inferred in the</span>
<span class="sd">        following manner:</span>

<span class="sd">        * if `y_true` in {-1, 1} or {0, 1}, `pos_label` defaults to 1;</span>
<span class="sd">        * else if `y_true` contains string, an error will be raised and</span>
<span class="sd">          `pos_label` should be explicitly specified;</span>
<span class="sd">        * otherwise, `pos_label` defaults to the greater label,</span>
<span class="sd">          i.e. `np.unique(y_true)[-1]`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : float</span>
<span class="sd">        Brier score loss.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] `Wikipedia entry for the Brier score</span>
<span class="sd">            &lt;https://en.wikipedia.org/wiki/Brier_score&gt;`_.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import brier_score_loss</span>
<span class="sd">    &gt;&gt;&gt; y_true = np.array([0, 1, 1, 0])</span>
<span class="sd">    &gt;&gt;&gt; y_true_categorical = np.array([&quot;spam&quot;, &quot;ham&quot;, &quot;ham&quot;, &quot;spam&quot;])</span>
<span class="sd">    &gt;&gt;&gt; y_prob = np.array([0.1, 0.9, 0.8, 0.3])</span>
<span class="sd">    &gt;&gt;&gt; brier_score_loss(y_true, y_prob)</span>
<span class="sd">    0.037...</span>
<span class="sd">    &gt;&gt;&gt; brier_score_loss(y_true, 1-y_prob, pos_label=0)</span>
<span class="sd">    0.037...</span>
<span class="sd">    &gt;&gt;&gt; brier_score_loss(y_true_categorical, y_prob, pos_label=&quot;ham&quot;)</span>
<span class="sd">    0.037...</span>
<span class="sd">    &gt;&gt;&gt; brier_score_loss(y_true, np.array(y_prob) &gt; 0.5)</span>
<span class="sd">    0.0</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">y_prob</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_prob</span><span class="p">)</span>
    <span class="n">assert_all_finite</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">assert_all_finite</span><span class="p">(</span><span class="n">y_prob</span><span class="p">)</span>
    <span class="n">check_consistent_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_prob</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>

    <span class="n">y_type</span> <span class="o">=</span> <span class="n">type_of_target</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;y_true&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">y_type</span> <span class="o">!=</span> <span class="s2">&quot;binary&quot;</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Only binary classification is supported. The type of the target &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;is </span><span class="si">{</span><span class="n">y_type</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">y_prob</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;y_prob contains values greater than 1.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">y_prob</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;y_prob contains values less than 0.&quot;</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">pos_label</span> <span class="o">=</span> <span class="n">_check_pos_label_consistency</span><span class="p">(</span><span class="n">pos_label</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
        <span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">classes</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;U&quot;</span><span class="p">,</span> <span class="s2">&quot;S&quot;</span><span class="p">):</span>
            <span class="c1"># for backward compatibility, if classes are not string then</span>
            <span class="c1"># `pos_label` will correspond to the greater label</span>
            <span class="n">pos_label</span> <span class="o">=</span> <span class="n">classes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_true</span> <span class="o">==</span> <span class="n">pos_label</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">((</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_prob</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, MindsDB.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>