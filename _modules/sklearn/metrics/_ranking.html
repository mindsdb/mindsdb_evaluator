<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>sklearn.metrics._ranking &mdash; mindsdb_evaluator 0.0.12 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/custom.css" />

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >

          
          
          <a href="../../../index.html">
            
              <img src="../../../_static/mindsdblogo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.0.12
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../accuracy.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Accuracy</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../calibration.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Calibration</span></code></a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: white" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">mindsdb_evaluator</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">sklearn.metrics._ranking</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for sklearn.metrics._ranking</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Metrics to assess performance on classification task given scores.</span>

<span class="sd">Functions named as ``*_score`` return a scalar value to maximize: the higher</span>
<span class="sd">the better.</span>

<span class="sd">Function named as ``*_error`` or ``*_loss`` return a scalar value to minimize:</span>
<span class="sd">the lower the better.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># Authors: Alexandre Gramfort &lt;alexandre.gramfort@inria.fr&gt;</span>
<span class="c1">#          Mathieu Blondel &lt;mathieu@mblondel.org&gt;</span>
<span class="c1">#          Olivier Grisel &lt;olivier.grisel@ensta.org&gt;</span>
<span class="c1">#          Arnaud Joly &lt;a.joly@ulg.ac.be&gt;</span>
<span class="c1">#          Jochen Wersdorfer &lt;jochen@wersdoerfer.de&gt;</span>
<span class="c1">#          Lars Buitinck</span>
<span class="c1">#          Joel Nothman &lt;joel.nothman@gmail.com&gt;</span>
<span class="c1">#          Noel Dawe &lt;noel@dawe.me&gt;</span>
<span class="c1">#          Michal Karbownik &lt;michakarbownik@gmail.com&gt;</span>
<span class="c1"># License: BSD 3 clause</span>


<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">numbers</span> <span class="kn">import</span> <span class="n">Integral</span><span class="p">,</span> <span class="n">Real</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">csr_matrix</span><span class="p">,</span> <span class="n">issparse</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">rankdata</span>

<span class="kn">from</span> <span class="nn">..exceptions</span> <span class="kn">import</span> <span class="n">UndefinedMetricWarning</span>
<span class="kn">from</span> <span class="nn">..preprocessing</span> <span class="kn">import</span> <span class="n">label_binarize</span>
<span class="kn">from</span> <span class="nn">..utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">assert_all_finite</span><span class="p">,</span>
    <span class="n">check_array</span><span class="p">,</span>
    <span class="n">check_consistent_length</span><span class="p">,</span>
    <span class="n">column_or_1d</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">..utils._encode</span> <span class="kn">import</span> <span class="n">_encode</span><span class="p">,</span> <span class="n">_unique</span>
<span class="kn">from</span> <span class="nn">..utils._param_validation</span> <span class="kn">import</span> <span class="n">Interval</span><span class="p">,</span> <span class="n">StrOptions</span><span class="p">,</span> <span class="n">validate_params</span>
<span class="kn">from</span> <span class="nn">..utils.extmath</span> <span class="kn">import</span> <span class="n">stable_cumsum</span>
<span class="kn">from</span> <span class="nn">..utils.fixes</span> <span class="kn">import</span> <span class="n">trapezoid</span>
<span class="kn">from</span> <span class="nn">..utils.multiclass</span> <span class="kn">import</span> <span class="n">type_of_target</span>
<span class="kn">from</span> <span class="nn">..utils.sparsefuncs</span> <span class="kn">import</span> <span class="n">count_nonzero</span>
<span class="kn">from</span> <span class="nn">..utils.validation</span> <span class="kn">import</span> <span class="n">_check_pos_label_consistency</span><span class="p">,</span> <span class="n">_check_sample_weight</span>
<span class="kn">from</span> <span class="nn">._base</span> <span class="kn">import</span> <span class="n">_average_binary_score</span><span class="p">,</span> <span class="n">_average_multiclass_ovo_score</span>


<div class="viewcode-block" id="auc"><a class="viewcode-back" href="../../../accuracy.html#accuracy.auc">[docs]</a><span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">]},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">auc</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute Area Under the Curve (AUC) using the trapezoidal rule.</span>

<span class="sd">    This is a general function, given points on a curve.  For computing the</span>
<span class="sd">    area under the ROC-curve, see :func:`roc_auc_score`.  For an alternative</span>
<span class="sd">    way to summarize a precision-recall curve, see</span>
<span class="sd">    :func:`average_precision_score`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : array-like of shape (n,)</span>
<span class="sd">        X coordinates. These must be either monotonic increasing or monotonic</span>
<span class="sd">        decreasing.</span>
<span class="sd">    y : array-like of shape (n,)</span>
<span class="sd">        Y coordinates.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    auc : float</span>
<span class="sd">        Area Under the Curve.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    roc_auc_score : Compute the area under the ROC curve.</span>
<span class="sd">    average_precision_score : Compute average precision from prediction scores.</span>
<span class="sd">    precision_recall_curve : Compute precision-recall pairs for different</span>
<span class="sd">        probability thresholds.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn import metrics</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 1, 2, 2])</span>
<span class="sd">    &gt;&gt;&gt; pred = np.array([0.1, 0.4, 0.35, 0.8])</span>
<span class="sd">    &gt;&gt;&gt; fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=2)</span>
<span class="sd">    &gt;&gt;&gt; metrics.auc(fpr, tpr)</span>
<span class="sd">    0.75</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">check_consistent_length</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;At least 2 points are needed to compute area under curve, but x.shape = </span><span class="si">%s</span><span class="s2">&quot;</span>
            <span class="o">%</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
        <span class="p">)</span>

    <span class="n">direction</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">dx</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">dx</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">):</span>
            <span class="n">direction</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;x is neither increasing nor decreasing : </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

    <span class="n">area</span> <span class="o">=</span> <span class="n">direction</span> <span class="o">*</span> <span class="n">trapezoid</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">area</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">memmap</span><span class="p">):</span>
        <span class="c1"># Reductions such as .sum used internally in trapezoid do not return a</span>
        <span class="c1"># scalar by default for numpy.memmap instances contrary to</span>
        <span class="c1"># regular numpy.ndarray instances.</span>
        <span class="n">area</span> <span class="o">=</span> <span class="n">area</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">area</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">area</span></div>


<div class="viewcode-block" id="average_precision_score"><a class="viewcode-back" href="../../../accuracy.html#accuracy.average_precision_score">[docs]</a><span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_score&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;average&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;samples&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">}),</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;pos_label&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Real</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;boolean&quot;</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">average_precision_score</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute average precision (AP) from prediction scores.</span>

<span class="sd">    AP summarizes a precision-recall curve as the weighted mean of precisions</span>
<span class="sd">    achieved at each threshold, with the increase in recall from the previous</span>
<span class="sd">    threshold used as the weight:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \\text{AP} = \\sum_n (R_n - R_{n-1}) P_n</span>

<span class="sd">    where :math:`P_n` and :math:`R_n` are the precision and recall at the nth</span>
<span class="sd">    threshold [1]_. This implementation is not interpolated and is different</span>
<span class="sd">    from computing the area under the precision-recall curve with the</span>
<span class="sd">    trapezoidal rule, which uses linear interpolation and can be too</span>
<span class="sd">    optimistic.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;precision_recall_f_measure_metrics&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : array-like of shape (n_samples,) or (n_samples, n_classes)</span>
<span class="sd">        True binary labels or binary label indicators.</span>

<span class="sd">    y_score : array-like of shape (n_samples,) or (n_samples, n_classes)</span>
<span class="sd">        Target scores, can either be probability estimates of the positive</span>
<span class="sd">        class, confidence values, or non-thresholded measure of decisions</span>
<span class="sd">        (as returned by :term:`decision_function` on some classifiers).</span>

<span class="sd">    average : {&#39;micro&#39;, &#39;samples&#39;, &#39;weighted&#39;, &#39;macro&#39;} or None, \</span>
<span class="sd">            default=&#39;macro&#39;</span>
<span class="sd">        If ``None``, the scores for each class are returned. Otherwise,</span>
<span class="sd">        this determines the type of averaging performed on the data:</span>

<span class="sd">        ``&#39;micro&#39;``:</span>
<span class="sd">            Calculate metrics globally by considering each element of the label</span>
<span class="sd">            indicator matrix as a label.</span>
<span class="sd">        ``&#39;macro&#39;``:</span>
<span class="sd">            Calculate metrics for each label, and find their unweighted</span>
<span class="sd">            mean.  This does not take label imbalance into account.</span>
<span class="sd">        ``&#39;weighted&#39;``:</span>
<span class="sd">            Calculate metrics for each label, and find their average, weighted</span>
<span class="sd">            by support (the number of true instances for each label).</span>
<span class="sd">        ``&#39;samples&#39;``:</span>
<span class="sd">            Calculate metrics for each instance, and find their average.</span>

<span class="sd">        Will be ignored when ``y_true`` is binary.</span>

<span class="sd">    pos_label : int, float, bool or str, default=1</span>
<span class="sd">        The label of the positive class. Only applied to binary ``y_true``.</span>
<span class="sd">        For multilabel-indicator ``y_true``, ``pos_label`` is fixed to 1.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    average_precision : float</span>
<span class="sd">        Average precision score.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    roc_auc_score : Compute the area under the ROC curve.</span>
<span class="sd">    precision_recall_curve : Compute precision-recall pairs for different</span>
<span class="sd">        probability thresholds.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    .. versionchanged:: 0.19</span>
<span class="sd">      Instead of linearly interpolating between operating points, precisions</span>
<span class="sd">      are weighted by the change in recall since the last operating point.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] `Wikipedia entry for the Average precision</span>
<span class="sd">           &lt;https://en.wikipedia.org/w/index.php?title=Information_retrieval&amp;</span>
<span class="sd">           oldid=793358396#Average_precision&gt;`_</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import average_precision_score</span>
<span class="sd">    &gt;&gt;&gt; y_true = np.array([0, 0, 1, 1])</span>
<span class="sd">    &gt;&gt;&gt; y_scores = np.array([0.1, 0.4, 0.35, 0.8])</span>
<span class="sd">    &gt;&gt;&gt; average_precision_score(y_true, y_scores)</span>
<span class="sd">    0.83...</span>
<span class="sd">    &gt;&gt;&gt; y_true = np.array([0, 0, 1, 1, 2, 2])</span>
<span class="sd">    &gt;&gt;&gt; y_scores = np.array([</span>
<span class="sd">    ...     [0.7, 0.2, 0.1],</span>
<span class="sd">    ...     [0.4, 0.3, 0.3],</span>
<span class="sd">    ...     [0.1, 0.8, 0.1],</span>
<span class="sd">    ...     [0.2, 0.3, 0.5],</span>
<span class="sd">    ...     [0.4, 0.4, 0.2],</span>
<span class="sd">    ...     [0.1, 0.2, 0.7],</span>
<span class="sd">    ... ])</span>
<span class="sd">    &gt;&gt;&gt; average_precision_score(y_true, y_scores)</span>
<span class="sd">    0.77...</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_binary_uninterpolated_average_precision</span><span class="p">(</span>
        <span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
        <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span>
            <span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span>
        <span class="p">)</span>
        <span class="c1"># Return the step function integral</span>
        <span class="c1"># The following works because the last entry of precision is</span>
        <span class="c1"># guaranteed to be 1, as returned by precision_recall_curve</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">recall</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">precision</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">y_type</span> <span class="o">=</span> <span class="n">type_of_target</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;y_true&quot;</span><span class="p">)</span>

    <span class="c1"># Convert to Python primitive type to avoid NumPy type / Python str</span>
    <span class="c1"># comparison. See https://github.com/numpy/numpy/issues/6784</span>
    <span class="n">present_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">y_type</span> <span class="o">==</span> <span class="s2">&quot;binary&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">present_labels</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">pos_label</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">present_labels</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;pos_label=</span><span class="si">{</span><span class="n">pos_label</span><span class="si">}</span><span class="s2"> is not a valid label. It should be &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;one of </span><span class="si">{</span><span class="n">present_labels</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

    <span class="k">elif</span> <span class="n">y_type</span> <span class="o">==</span> <span class="s2">&quot;multilabel-indicator&quot;</span> <span class="ow">and</span> <span class="n">pos_label</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Parameter pos_label is fixed to 1 for multilabel-indicator y_true. &quot;</span>
            <span class="s2">&quot;Do not set pos_label or set pos_label to 1.&quot;</span>
        <span class="p">)</span>

    <span class="k">elif</span> <span class="n">y_type</span> <span class="o">==</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">pos_label</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Parameter pos_label is fixed to 1 for multiclass y_true. &quot;</span>
                <span class="s2">&quot;Do not set pos_label or set pos_label to 1.&quot;</span>
            <span class="p">)</span>
        <span class="n">y_true</span> <span class="o">=</span> <span class="n">label_binarize</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="n">present_labels</span><span class="p">)</span>

    <span class="n">average_precision</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
        <span class="n">_binary_uninterpolated_average_precision</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">_average_binary_score</span><span class="p">(</span>
        <span class="n">average_precision</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">average</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span>
    <span class="p">)</span></div>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_score&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;pos_label&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Real</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">det_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute error rates for different probability thresholds.</span>

<span class="sd">    .. note::</span>
<span class="sd">       This metric is used for evaluation of ranking and error tradeoffs of</span>
<span class="sd">       a binary classification task.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;det_curve&gt;`.</span>

<span class="sd">    .. versionadded:: 0.24</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : ndarray of shape (n_samples,)</span>
<span class="sd">        True binary labels. If labels are not either {-1, 1} or {0, 1}, then</span>
<span class="sd">        pos_label should be explicitly given.</span>

<span class="sd">    y_score : ndarray of shape of (n_samples,)</span>
<span class="sd">        Target scores, can either be probability estimates of the positive</span>
<span class="sd">        class, confidence values, or non-thresholded measure of decisions</span>
<span class="sd">        (as returned by &quot;decision_function&quot; on some classifiers).</span>

<span class="sd">    pos_label : int, float, bool or str, default=None</span>
<span class="sd">        The label of the positive class.</span>
<span class="sd">        When ``pos_label=None``, if `y_true` is in {-1, 1} or {0, 1},</span>
<span class="sd">        ``pos_label`` is set to 1, otherwise an error will be raised.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    fpr : ndarray of shape (n_thresholds,)</span>
<span class="sd">        False positive rate (FPR) such that element i is the false positive</span>
<span class="sd">        rate of predictions with score &gt;= thresholds[i]. This is occasionally</span>
<span class="sd">        referred to as false acceptance probability or fall-out.</span>

<span class="sd">    fnr : ndarray of shape (n_thresholds,)</span>
<span class="sd">        False negative rate (FNR) such that element i is the false negative</span>
<span class="sd">        rate of predictions with score &gt;= thresholds[i]. This is occasionally</span>
<span class="sd">        referred to as false rejection or miss rate.</span>

<span class="sd">    thresholds : ndarray of shape (n_thresholds,)</span>
<span class="sd">        Decreasing score values.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    DetCurveDisplay.from_estimator : Plot DET curve given an estimator and</span>
<span class="sd">        some data.</span>
<span class="sd">    DetCurveDisplay.from_predictions : Plot DET curve given the true and</span>
<span class="sd">        predicted labels.</span>
<span class="sd">    DetCurveDisplay : DET curve visualization.</span>
<span class="sd">    roc_curve : Compute Receiver operating characteristic (ROC) curve.</span>
<span class="sd">    precision_recall_curve : Compute precision-recall curve.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import det_curve</span>
<span class="sd">    &gt;&gt;&gt; y_true = np.array([0, 0, 1, 1])</span>
<span class="sd">    &gt;&gt;&gt; y_scores = np.array([0.1, 0.4, 0.35, 0.8])</span>
<span class="sd">    &gt;&gt;&gt; fpr, fnr, thresholds = det_curve(y_true, y_scores)</span>
<span class="sd">    &gt;&gt;&gt; fpr</span>
<span class="sd">    array([0.5, 0.5, 0. ])</span>
<span class="sd">    &gt;&gt;&gt; fnr</span>
<span class="sd">    array([0. , 0.5, 0.5])</span>
<span class="sd">    &gt;&gt;&gt; thresholds</span>
<span class="sd">    array([0.35, 0.4 , 0.8 ])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fps</span><span class="p">,</span> <span class="n">tps</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">_binary_clf_curve</span><span class="p">(</span>
        <span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_true</span><span class="p">))</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Only one class present in y_true. Detection error &quot;</span>
            <span class="s2">&quot;tradeoff curve is not defined in that case.&quot;</span>
        <span class="p">)</span>

    <span class="n">fns</span> <span class="o">=</span> <span class="n">tps</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">tps</span>
    <span class="n">p_count</span> <span class="o">=</span> <span class="n">tps</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">n_count</span> <span class="o">=</span> <span class="n">fps</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># start with false positives zero</span>
    <span class="n">first_ind</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">fps</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">fps</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">side</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">fps</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">fps</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">side</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="k">else</span> <span class="kc">None</span>
    <span class="p">)</span>
    <span class="c1"># stop with false negatives zero</span>
    <span class="n">last_ind</span> <span class="o">=</span> <span class="n">tps</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">tps</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">sl</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="n">first_ind</span><span class="p">,</span> <span class="n">last_ind</span><span class="p">)</span>

    <span class="c1"># reverse the output such that list of false positives is decreasing</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">fps</span><span class="p">[</span><span class="n">sl</span><span class="p">][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">n_count</span><span class="p">,</span> <span class="n">fns</span><span class="p">[</span><span class="n">sl</span><span class="p">][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">p_count</span><span class="p">,</span> <span class="n">thresholds</span><span class="p">[</span><span class="n">sl</span><span class="p">][::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">_binary_roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_fpr</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Binary roc auc score.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_true</span><span class="p">))</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Only one class present in y_true. ROC AUC score &quot;</span>
            <span class="s2">&quot;is not defined in that case.&quot;</span>
        <span class="p">)</span>

    <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_fpr</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">max_fpr</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_fpr</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">max_fpr</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Expected max_fpr in range (0, 1], got: </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">max_fpr</span><span class="p">)</span>

    <span class="c1"># Add a single point at max_fpr by linear interpolation</span>
    <span class="n">stop</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">max_fpr</span><span class="p">,</span> <span class="s2">&quot;right&quot;</span><span class="p">)</span>
    <span class="n">x_interp</span> <span class="o">=</span> <span class="p">[</span><span class="n">fpr</span><span class="p">[</span><span class="n">stop</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="n">fpr</span><span class="p">[</span><span class="n">stop</span><span class="p">]]</span>
    <span class="n">y_interp</span> <span class="o">=</span> <span class="p">[</span><span class="n">tpr</span><span class="p">[</span><span class="n">stop</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="n">tpr</span><span class="p">[</span><span class="n">stop</span><span class="p">]]</span>
    <span class="n">tpr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tpr</span><span class="p">[:</span><span class="n">stop</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">interp</span><span class="p">(</span><span class="n">max_fpr</span><span class="p">,</span> <span class="n">x_interp</span><span class="p">,</span> <span class="n">y_interp</span><span class="p">))</span>
    <span class="n">fpr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fpr</span><span class="p">[:</span><span class="n">stop</span><span class="p">],</span> <span class="n">max_fpr</span><span class="p">)</span>
    <span class="n">partial_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

    <span class="c1"># McClish correction: standardize result to be 0.5 if non-discriminant</span>
    <span class="c1"># and 1 if maximal</span>
    <span class="n">min_area</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">max_fpr</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">max_area</span> <span class="o">=</span> <span class="n">max_fpr</span>
    <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">partial_auc</span> <span class="o">-</span> <span class="n">min_area</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">max_area</span> <span class="o">-</span> <span class="n">min_area</span><span class="p">))</span>


<div class="viewcode-block" id="roc_auc_score"><a class="viewcode-back" href="../../../accuracy.html#accuracy.roc_auc_score">[docs]</a><span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_score&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;average&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;samples&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">}),</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;max_fpr&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">Real</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">),</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;multi_class&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;raise&quot;</span><span class="p">,</span> <span class="s2">&quot;ovr&quot;</span><span class="p">,</span> <span class="s2">&quot;ovo&quot;</span><span class="p">})],</span>
        <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">roc_auc_score</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">,</span>
    <span class="n">y_score</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_fpr</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;raise&quot;</span><span class="p">,</span>
    <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) \</span>
<span class="sd">    from prediction scores.</span>

<span class="sd">    Note: this implementation can be used with binary, multiclass and</span>
<span class="sd">    multilabel classification, but some restrictions apply (see Parameters).</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;roc_metrics&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : array-like of shape (n_samples,) or (n_samples, n_classes)</span>
<span class="sd">        True labels or binary label indicators. The binary and multiclass cases</span>
<span class="sd">        expect labels with shape (n_samples,) while the multilabel case expects</span>
<span class="sd">        binary label indicators with shape (n_samples, n_classes).</span>

<span class="sd">    y_score : array-like of shape (n_samples,) or (n_samples, n_classes)</span>
<span class="sd">        Target scores.</span>

<span class="sd">        * In the binary case, it corresponds to an array of shape</span>
<span class="sd">          `(n_samples,)`. Both probability estimates and non-thresholded</span>
<span class="sd">          decision values can be provided. The probability estimates correspond</span>
<span class="sd">          to the **probability of the class with the greater label**,</span>
<span class="sd">          i.e. `estimator.classes_[1]` and thus</span>
<span class="sd">          `estimator.predict_proba(X, y)[:, 1]`. The decision values</span>
<span class="sd">          corresponds to the output of `estimator.decision_function(X, y)`.</span>
<span class="sd">          See more information in the :ref:`User guide &lt;roc_auc_binary&gt;`;</span>
<span class="sd">        * In the multiclass case, it corresponds to an array of shape</span>
<span class="sd">          `(n_samples, n_classes)` of probability estimates provided by the</span>
<span class="sd">          `predict_proba` method. The probability estimates **must**</span>
<span class="sd">          sum to 1 across the possible classes. In addition, the order of the</span>
<span class="sd">          class scores must correspond to the order of ``labels``,</span>
<span class="sd">          if provided, or else to the numerical or lexicographical order of</span>
<span class="sd">          the labels in ``y_true``. See more information in the</span>
<span class="sd">          :ref:`User guide &lt;roc_auc_multiclass&gt;`;</span>
<span class="sd">        * In the multilabel case, it corresponds to an array of shape</span>
<span class="sd">          `(n_samples, n_classes)`. Probability estimates are provided by the</span>
<span class="sd">          `predict_proba` method and the non-thresholded decision values by</span>
<span class="sd">          the `decision_function` method. The probability estimates correspond</span>
<span class="sd">          to the **probability of the class with the greater label for each</span>
<span class="sd">          output** of the classifier. See more information in the</span>
<span class="sd">          :ref:`User guide &lt;roc_auc_multilabel&gt;`.</span>

<span class="sd">    average : {&#39;micro&#39;, &#39;macro&#39;, &#39;samples&#39;, &#39;weighted&#39;} or None, \</span>
<span class="sd">            default=&#39;macro&#39;</span>
<span class="sd">        If ``None``, the scores for each class are returned.</span>
<span class="sd">        Otherwise, this determines the type of averaging performed on the data.</span>
<span class="sd">        Note: multiclass ROC AUC currently only handles the &#39;macro&#39; and</span>
<span class="sd">        &#39;weighted&#39; averages. For multiclass targets, `average=None` is only</span>
<span class="sd">        implemented for `multi_class=&#39;ovr&#39;` and `average=&#39;micro&#39;` is only</span>
<span class="sd">        implemented for `multi_class=&#39;ovr&#39;`.</span>

<span class="sd">        ``&#39;micro&#39;``:</span>
<span class="sd">            Calculate metrics globally by considering each element of the label</span>
<span class="sd">            indicator matrix as a label.</span>
<span class="sd">        ``&#39;macro&#39;``:</span>
<span class="sd">            Calculate metrics for each label, and find their unweighted</span>
<span class="sd">            mean.  This does not take label imbalance into account.</span>
<span class="sd">        ``&#39;weighted&#39;``:</span>
<span class="sd">            Calculate metrics for each label, and find their average, weighted</span>
<span class="sd">            by support (the number of true instances for each label).</span>
<span class="sd">        ``&#39;samples&#39;``:</span>
<span class="sd">            Calculate metrics for each instance, and find their average.</span>

<span class="sd">        Will be ignored when ``y_true`` is binary.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">    max_fpr : float &gt; 0 and &lt;= 1, default=None</span>
<span class="sd">        If not ``None``, the standardized partial AUC [2]_ over the range</span>
<span class="sd">        [0, max_fpr] is returned. For the multiclass case, ``max_fpr``,</span>
<span class="sd">        should be either equal to ``None`` or ``1.0`` as AUC ROC partial</span>
<span class="sd">        computation currently is not supported for multiclass.</span>

<span class="sd">    multi_class : {&#39;raise&#39;, &#39;ovr&#39;, &#39;ovo&#39;}, default=&#39;raise&#39;</span>
<span class="sd">        Only used for multiclass targets. Determines the type of configuration</span>
<span class="sd">        to use. The default value raises an error, so either</span>
<span class="sd">        ``&#39;ovr&#39;`` or ``&#39;ovo&#39;`` must be passed explicitly.</span>

<span class="sd">        ``&#39;ovr&#39;``:</span>
<span class="sd">            Stands for One-vs-rest. Computes the AUC of each class</span>
<span class="sd">            against the rest [3]_ [4]_. This</span>
<span class="sd">            treats the multiclass case in the same way as the multilabel case.</span>
<span class="sd">            Sensitive to class imbalance even when ``average == &#39;macro&#39;``,</span>
<span class="sd">            because class imbalance affects the composition of each of the</span>
<span class="sd">            &#39;rest&#39; groupings.</span>
<span class="sd">        ``&#39;ovo&#39;``:</span>
<span class="sd">            Stands for One-vs-one. Computes the average AUC of all</span>
<span class="sd">            possible pairwise combinations of classes [5]_.</span>
<span class="sd">            Insensitive to class imbalance when</span>
<span class="sd">            ``average == &#39;macro&#39;``.</span>

<span class="sd">    labels : array-like of shape (n_classes,), default=None</span>
<span class="sd">        Only used for multiclass targets. List of labels that index the</span>
<span class="sd">        classes in ``y_score``. If ``None``, the numerical or lexicographical</span>
<span class="sd">        order of the labels in ``y_true`` is used.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    auc : float</span>
<span class="sd">        Area Under the Curve score.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    average_precision_score : Area under the precision-recall curve.</span>
<span class="sd">    roc_curve : Compute Receiver operating characteristic (ROC) curve.</span>
<span class="sd">    RocCurveDisplay.from_estimator : Plot Receiver Operating Characteristic</span>
<span class="sd">        (ROC) curve given an estimator and some data.</span>
<span class="sd">    RocCurveDisplay.from_predictions : Plot Receiver Operating Characteristic</span>
<span class="sd">        (ROC) curve given the true and predicted values.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The Gini Coefficient is a summary measure of the ranking ability of binary</span>
<span class="sd">    classifiers. It is expressed using the area under of the ROC as follows:</span>

<span class="sd">    G = 2 * AUC - 1</span>

<span class="sd">    Where G is the Gini coefficient and AUC is the ROC-AUC score. This normalisation</span>
<span class="sd">    will ensure that random guessing will yield a score of 0 in expectation, and it is</span>
<span class="sd">    upper bounded by 1.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] `Wikipedia entry for the Receiver operating characteristic</span>
<span class="sd">            &lt;https://en.wikipedia.org/wiki/Receiver_operating_characteristic&gt;`_</span>

<span class="sd">    .. [2] `Analyzing a portion of the ROC curve. McClish, 1989</span>
<span class="sd">            &lt;https://www.ncbi.nlm.nih.gov/pubmed/2668680&gt;`_</span>

<span class="sd">    .. [3] Provost, F., Domingos, P. (2000). Well-trained PETs: Improving</span>
<span class="sd">           probability estimation trees (Section 6.2), CeDER Working Paper</span>
<span class="sd">           #IS-00-04, Stern School of Business, New York University.</span>

<span class="sd">    .. [4] `Fawcett, T. (2006). An introduction to ROC analysis. Pattern</span>
<span class="sd">            Recognition Letters, 27(8), 861-874.</span>
<span class="sd">            &lt;https://www.sciencedirect.com/science/article/pii/S016786550500303X&gt;`_</span>

<span class="sd">    .. [5] `Hand, D.J., Till, R.J. (2001). A Simple Generalisation of the Area</span>
<span class="sd">            Under the ROC Curve for Multiple Class Classification Problems.</span>
<span class="sd">            Machine Learning, 45(2), 171-186.</span>
<span class="sd">            &lt;http://link.springer.com/article/10.1023/A:1010920819831&gt;`_</span>
<span class="sd">    .. [6] `Wikipedia entry for the Gini coefficient</span>
<span class="sd">            &lt;https://en.wikipedia.org/wiki/Gini_coefficient&gt;`_</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Binary case:</span>

<span class="sd">    &gt;&gt;&gt; from sklearn.datasets import load_breast_cancer</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.linear_model import LogisticRegression</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import roc_auc_score</span>
<span class="sd">    &gt;&gt;&gt; X, y = load_breast_cancer(return_X_y=True)</span>
<span class="sd">    &gt;&gt;&gt; clf = LogisticRegression(solver=&quot;liblinear&quot;, random_state=0).fit(X, y)</span>
<span class="sd">    &gt;&gt;&gt; roc_auc_score(y, clf.predict_proba(X)[:, 1])</span>
<span class="sd">    0.99...</span>
<span class="sd">    &gt;&gt;&gt; roc_auc_score(y, clf.decision_function(X))</span>
<span class="sd">    0.99...</span>

<span class="sd">    Multiclass case:</span>

<span class="sd">    &gt;&gt;&gt; from sklearn.datasets import load_iris</span>
<span class="sd">    &gt;&gt;&gt; X, y = load_iris(return_X_y=True)</span>
<span class="sd">    &gt;&gt;&gt; clf = LogisticRegression(solver=&quot;liblinear&quot;).fit(X, y)</span>
<span class="sd">    &gt;&gt;&gt; roc_auc_score(y, clf.predict_proba(X), multi_class=&#39;ovr&#39;)</span>
<span class="sd">    0.99...</span>

<span class="sd">    Multilabel case:</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.datasets import make_multilabel_classification</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.multioutput import MultiOutputClassifier</span>
<span class="sd">    &gt;&gt;&gt; X, y = make_multilabel_classification(random_state=0)</span>
<span class="sd">    &gt;&gt;&gt; clf = MultiOutputClassifier(clf).fit(X, y)</span>
<span class="sd">    &gt;&gt;&gt; # get a list of n_output containing probability arrays of shape</span>
<span class="sd">    &gt;&gt;&gt; # (n_samples, n_classes)</span>
<span class="sd">    &gt;&gt;&gt; y_pred = clf.predict_proba(X)</span>
<span class="sd">    &gt;&gt;&gt; # extract the positive columns for each output</span>
<span class="sd">    &gt;&gt;&gt; y_pred = np.transpose([pred[:, 1] for pred in y_pred])</span>
<span class="sd">    &gt;&gt;&gt; roc_auc_score(y, y_pred, average=None)</span>
<span class="sd">    array([0.82..., 0.86..., 0.94..., 0.85... , 0.94...])</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.linear_model import RidgeClassifierCV</span>
<span class="sd">    &gt;&gt;&gt; clf = RidgeClassifierCV().fit(X, y)</span>
<span class="sd">    &gt;&gt;&gt; roc_auc_score(y, clf.decision_function(X), average=None)</span>
<span class="sd">    array([0.81..., 0.84... , 0.93..., 0.87..., 0.94...])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">y_type</span> <span class="o">=</span> <span class="n">type_of_target</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;y_true&quot;</span><span class="p">)</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">y_score</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y_score</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">y_type</span> <span class="o">==</span> <span class="s2">&quot;multiclass&quot;</span> <span class="ow">or</span> <span class="p">(</span>
        <span class="n">y_type</span> <span class="o">==</span> <span class="s2">&quot;binary&quot;</span> <span class="ow">and</span> <span class="n">y_score</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">y_score</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">2</span>
    <span class="p">):</span>
        <span class="c1"># do not support partial ROC computation for multiclass</span>
        <span class="k">if</span> <span class="n">max_fpr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">max_fpr</span> <span class="o">!=</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Partial AUC computation not available in &quot;</span>
                <span class="s2">&quot;multiclass setting, &#39;max_fpr&#39; must be&quot;</span>
                <span class="s2">&quot; set to `None`, received `max_fpr=</span><span class="si">{0}</span><span class="s2">` &quot;</span>
                <span class="s2">&quot;instead&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">max_fpr</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">multi_class</span> <span class="o">==</span> <span class="s2">&quot;raise&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;multi_class must be in (&#39;ovo&#39;, &#39;ovr&#39;)&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_multiclass_roc_auc_score</span><span class="p">(</span>
            <span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">multi_class</span><span class="p">,</span> <span class="n">average</span><span class="p">,</span> <span class="n">sample_weight</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">y_type</span> <span class="o">==</span> <span class="s2">&quot;binary&quot;</span><span class="p">:</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
        <span class="n">y_true</span> <span class="o">=</span> <span class="n">label_binarize</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="n">labels</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">_average_binary_score</span><span class="p">(</span>
            <span class="n">partial</span><span class="p">(</span><span class="n">_binary_roc_auc_score</span><span class="p">,</span> <span class="n">max_fpr</span><span class="o">=</span><span class="n">max_fpr</span><span class="p">),</span>
            <span class="n">y_true</span><span class="p">,</span>
            <span class="n">y_score</span><span class="p">,</span>
            <span class="n">average</span><span class="p">,</span>
            <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># multilabel-indicator</span>
        <span class="k">return</span> <span class="n">_average_binary_score</span><span class="p">(</span>
            <span class="n">partial</span><span class="p">(</span><span class="n">_binary_roc_auc_score</span><span class="p">,</span> <span class="n">max_fpr</span><span class="o">=</span><span class="n">max_fpr</span><span class="p">),</span>
            <span class="n">y_true</span><span class="p">,</span>
            <span class="n">y_score</span><span class="p">,</span>
            <span class="n">average</span><span class="p">,</span>
            <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
        <span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_multiclass_roc_auc_score</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">multi_class</span><span class="p">,</span> <span class="n">average</span><span class="p">,</span> <span class="n">sample_weight</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Multiclass roc auc score.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : array-like of shape (n_samples,)</span>
<span class="sd">        True multiclass labels.</span>

<span class="sd">    y_score : array-like of shape (n_samples, n_classes)</span>
<span class="sd">        Target scores corresponding to probability estimates of a sample</span>
<span class="sd">        belonging to a particular class</span>

<span class="sd">    labels : array-like of shape (n_classes,) or None</span>
<span class="sd">        List of labels to index ``y_score`` used for multiclass. If ``None``,</span>
<span class="sd">        the lexical order of ``y_true`` is used to index ``y_score``.</span>

<span class="sd">    multi_class : {&#39;ovr&#39;, &#39;ovo&#39;}</span>
<span class="sd">        Determines the type of multiclass configuration to use.</span>
<span class="sd">        ``&#39;ovr&#39;``:</span>
<span class="sd">            Calculate metrics for the multiclass case using the one-vs-rest</span>
<span class="sd">            approach.</span>
<span class="sd">        ``&#39;ovo&#39;``:</span>
<span class="sd">            Calculate metrics for the multiclass case using the one-vs-one</span>
<span class="sd">            approach.</span>

<span class="sd">    average : {&#39;micro&#39;, &#39;macro&#39;, &#39;weighted&#39;}</span>
<span class="sd">        Determines the type of averaging performed on the pairwise binary</span>
<span class="sd">        metric scores</span>
<span class="sd">        ``&#39;micro&#39;``:</span>
<span class="sd">            Calculate metrics for the binarized-raveled classes. Only supported</span>
<span class="sd">            for `multi_class=&#39;ovr&#39;`.</span>

<span class="sd">        .. versionadded:: 1.2</span>

<span class="sd">        ``&#39;macro&#39;``:</span>
<span class="sd">            Calculate metrics for each label, and find their unweighted</span>
<span class="sd">            mean. This does not take label imbalance into account. Classes</span>
<span class="sd">            are assumed to be uniformly distributed.</span>
<span class="sd">        ``&#39;weighted&#39;``:</span>
<span class="sd">            Calculate metrics for each label, taking into account the</span>
<span class="sd">            prevalence of the classes.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,) or None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># validation of the input y_score</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">y_score</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Target scores need to be probabilities for multiclass &quot;</span>
            <span class="s2">&quot;roc_auc, i.e. they should sum up to 1.0 over classes&quot;</span>
        <span class="p">)</span>

    <span class="c1"># validation for multiclass parameter specifications</span>
    <span class="n">average_options</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">multi_class</span> <span class="o">==</span> <span class="s2">&quot;ovr&quot;</span><span class="p">:</span>
        <span class="n">average_options</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;micro&quot;</span><span class="p">,)</span> <span class="o">+</span> <span class="n">average_options</span>
    <span class="k">if</span> <span class="n">average</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">average_options</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;average must be one of </span><span class="si">{0}</span><span class="s2"> for multiclass problems&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">average_options</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="n">multiclass_options</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;ovo&quot;</span><span class="p">,</span> <span class="s2">&quot;ovr&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">multi_class</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">multiclass_options</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;multi_class=&#39;</span><span class="si">{0}</span><span class="s2">&#39; is not supported &quot;</span>
            <span class="s2">&quot;for multiclass ROC AUC, multi_class must be &quot;</span>
            <span class="s2">&quot;in </span><span class="si">{1}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">multi_class</span><span class="p">,</span> <span class="n">multiclass_options</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">average</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">multi_class</span> <span class="o">==</span> <span class="s2">&quot;ovo&quot;</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;average=None is not implemented for multi_class=&#39;ovo&#39;.&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">classes</span> <span class="o">=</span> <span class="n">_unique</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Parameter &#39;labels&#39; must be unique&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">classes</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Parameter &#39;labels&#39; must be ordered&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">)</span> <span class="o">!=</span> <span class="n">y_score</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Number of given labels, </span><span class="si">{0}</span><span class="s2">, not equal to the number &quot;</span>
                <span class="s2">&quot;of columns in &#39;y_score&#39;, </span><span class="si">{1}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">),</span> <span class="n">y_score</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">setdiff1d</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">classes</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;&#39;y_true&#39; contains labels not in parameter &#39;labels&#39;&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">classes</span> <span class="o">=</span> <span class="n">_unique</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">)</span> <span class="o">!=</span> <span class="n">y_score</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Number of classes in y_true not equal to the number of &quot;</span>
                <span class="s2">&quot;columns in &#39;y_score&#39;&quot;</span>
            <span class="p">)</span>

    <span class="k">if</span> <span class="n">multi_class</span> <span class="o">==</span> <span class="s2">&quot;ovo&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;sample_weight is not supported &quot;</span>
                <span class="s2">&quot;for multiclass one-vs-one ROC AUC, &quot;</span>
                <span class="s2">&quot;&#39;sample_weight&#39; must be None in this case.&quot;</span>
            <span class="p">)</span>
        <span class="n">y_true_encoded</span> <span class="o">=</span> <span class="n">_encode</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">uniques</span><span class="o">=</span><span class="n">classes</span><span class="p">)</span>
        <span class="c1"># Hand &amp; Till (2001) implementation (ovo)</span>
        <span class="k">return</span> <span class="n">_average_multiclass_ovo_score</span><span class="p">(</span>
            <span class="n">_binary_roc_auc_score</span><span class="p">,</span> <span class="n">y_true_encoded</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="n">average</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># ovr is same as multi-label</span>
        <span class="n">y_true_multilabel</span> <span class="o">=</span> <span class="n">label_binarize</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="n">classes</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_average_binary_score</span><span class="p">(</span>
            <span class="n">_binary_roc_auc_score</span><span class="p">,</span>
            <span class="n">y_true_multilabel</span><span class="p">,</span>
            <span class="n">y_score</span><span class="p">,</span>
            <span class="n">average</span><span class="p">,</span>
            <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
        <span class="p">)</span>


<span class="k">def</span> <span class="nf">_binary_clf_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculate true and false positives per binary classification threshold.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : ndarray of shape (n_samples,)</span>
<span class="sd">        True targets of binary classification.</span>

<span class="sd">    y_score : ndarray of shape (n_samples,)</span>
<span class="sd">        Estimated probabilities or output of a decision function.</span>

<span class="sd">    pos_label : int, float, bool or str, default=None</span>
<span class="sd">        The label of the positive class.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    fps : ndarray of shape (n_thresholds,)</span>
<span class="sd">        A count of false positives, at index i being the number of negative</span>
<span class="sd">        samples assigned a score &gt;= thresholds[i]. The total number of</span>
<span class="sd">        negative samples is equal to fps[-1] (thus true negatives are given by</span>
<span class="sd">        fps[-1] - fps).</span>

<span class="sd">    tps : ndarray of shape (n_thresholds,)</span>
<span class="sd">        An increasing count of true positives, at index i being the number</span>
<span class="sd">        of positive samples assigned a score &gt;= thresholds[i]. The total</span>
<span class="sd">        number of positive samples is equal to tps[-1] (thus false negatives</span>
<span class="sd">        are given by tps[-1] - tps).</span>

<span class="sd">    thresholds : ndarray of shape (n_thresholds,)</span>
<span class="sd">        Decreasing score values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Check to make sure y_true is valid</span>
    <span class="n">y_type</span> <span class="o">=</span> <span class="n">type_of_target</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;y_true&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">y_type</span> <span class="o">==</span> <span class="s2">&quot;binary&quot;</span> <span class="ow">or</span> <span class="p">(</span><span class="n">y_type</span> <span class="o">==</span> <span class="s2">&quot;multiclass&quot;</span> <span class="ow">and</span> <span class="n">pos_label</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{0}</span><span class="s2"> format is not supported&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_type</span><span class="p">))</span>

    <span class="n">check_consistent_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">y_score</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span>
    <span class="n">assert_all_finite</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">assert_all_finite</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span>

    <span class="c1"># Filter out zero-weighted samples, as they should not impact the result</span>
    <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">)</span>
        <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">_check_sample_weight</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>
        <span class="n">nonzero_weight_mask</span> <span class="o">=</span> <span class="n">sample_weight</span> <span class="o">!=</span> <span class="mi">0</span>
        <span class="n">y_true</span> <span class="o">=</span> <span class="n">y_true</span><span class="p">[</span><span class="n">nonzero_weight_mask</span><span class="p">]</span>
        <span class="n">y_score</span> <span class="o">=</span> <span class="n">y_score</span><span class="p">[</span><span class="n">nonzero_weight_mask</span><span class="p">]</span>
        <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">sample_weight</span><span class="p">[</span><span class="n">nonzero_weight_mask</span><span class="p">]</span>

    <span class="n">pos_label</span> <span class="o">=</span> <span class="n">_check_pos_label_consistency</span><span class="p">(</span><span class="n">pos_label</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>

    <span class="c1"># make y_true a boolean vector</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">y_true</span> <span class="o">==</span> <span class="n">pos_label</span>

    <span class="c1"># sort scores and corresponding truth values</span>
    <span class="n">desc_score_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">y_score</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;mergesort&quot;</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">y_score</span> <span class="o">=</span> <span class="n">y_score</span><span class="p">[</span><span class="n">desc_score_indices</span><span class="p">]</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">y_true</span><span class="p">[</span><span class="n">desc_score_indices</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">sample_weight</span><span class="p">[</span><span class="n">desc_score_indices</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="mf">1.0</span>

    <span class="c1"># y_score typically has many tied values. Here we extract</span>
    <span class="c1"># the indices associated with the distinct values. We also</span>
    <span class="c1"># concatenate a value for the end of the curve.</span>
    <span class="n">distinct_value_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">y_score</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">threshold_idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="n">distinct_value_indices</span><span class="p">,</span> <span class="n">y_true</span><span class="o">.</span><span class="n">size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>

    <span class="c1"># accumulate the true positives with decreasing threshold</span>
    <span class="n">tps</span> <span class="o">=</span> <span class="n">stable_cumsum</span><span class="p">(</span><span class="n">y_true</span> <span class="o">*</span> <span class="n">weight</span><span class="p">)[</span><span class="n">threshold_idxs</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># express fps as a cumsum to ensure fps is increasing even in</span>
        <span class="c1"># the presence of floating point errors</span>
        <span class="n">fps</span> <span class="o">=</span> <span class="n">stable_cumsum</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y_true</span><span class="p">)</span> <span class="o">*</span> <span class="n">weight</span><span class="p">)[</span><span class="n">threshold_idxs</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">fps</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">threshold_idxs</span> <span class="o">-</span> <span class="n">tps</span>
    <span class="k">return</span> <span class="n">fps</span><span class="p">,</span> <span class="n">tps</span><span class="p">,</span> <span class="n">y_score</span><span class="p">[</span><span class="n">threshold_idxs</span><span class="p">]</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;probas_pred&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;pos_label&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Real</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;drop_intermediate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;boolean&quot;</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">precision_recall_curve</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">,</span> <span class="n">probas_pred</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">drop_intermediate</span><span class="o">=</span><span class="kc">False</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute precision-recall pairs for different probability thresholds.</span>

<span class="sd">    Note: this implementation is restricted to the binary classification task.</span>

<span class="sd">    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of</span>
<span class="sd">    true positives and ``fp`` the number of false positives. The precision is</span>
<span class="sd">    intuitively the ability of the classifier not to label as positive a sample</span>
<span class="sd">    that is negative.</span>

<span class="sd">    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of</span>
<span class="sd">    true positives and ``fn`` the number of false negatives. The recall is</span>
<span class="sd">    intuitively the ability of the classifier to find all the positive samples.</span>

<span class="sd">    The last precision and recall values are 1. and 0. respectively and do not</span>
<span class="sd">    have a corresponding threshold. This ensures that the graph starts on the</span>
<span class="sd">    y axis.</span>

<span class="sd">    The first precision and recall values are precision=class balance and recall=1.0</span>
<span class="sd">    which corresponds to a classifier that always predicts the positive class.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;precision_recall_f_measure_metrics&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : array-like of shape (n_samples,)</span>
<span class="sd">        True binary labels. If labels are not either {-1, 1} or {0, 1}, then</span>
<span class="sd">        pos_label should be explicitly given.</span>

<span class="sd">    probas_pred : array-like of shape (n_samples,)</span>
<span class="sd">        Target scores, can either be probability estimates of the positive</span>
<span class="sd">        class, or non-thresholded measure of decisions (as returned by</span>
<span class="sd">        `decision_function` on some classifiers).</span>

<span class="sd">    pos_label : int, float, bool or str, default=None</span>
<span class="sd">        The label of the positive class.</span>
<span class="sd">        When ``pos_label=None``, if y_true is in {-1, 1} or {0, 1},</span>
<span class="sd">        ``pos_label`` is set to 1, otherwise an error will be raised.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">    drop_intermediate : bool, default=False</span>
<span class="sd">        Whether to drop some suboptimal thresholds which would not appear</span>
<span class="sd">        on a plotted precision-recall curve. This is useful in order to create</span>
<span class="sd">        lighter precision-recall curves.</span>

<span class="sd">        .. versionadded:: 1.3</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    precision : ndarray of shape (n_thresholds + 1,)</span>
<span class="sd">        Precision values such that element i is the precision of</span>
<span class="sd">        predictions with score &gt;= thresholds[i] and the last element is 1.</span>

<span class="sd">    recall : ndarray of shape (n_thresholds + 1,)</span>
<span class="sd">        Decreasing recall values such that element i is the recall of</span>
<span class="sd">        predictions with score &gt;= thresholds[i] and the last element is 0.</span>

<span class="sd">    thresholds : ndarray of shape (n_thresholds,)</span>
<span class="sd">        Increasing thresholds on the decision function used to compute</span>
<span class="sd">        precision and recall where `n_thresholds = len(np.unique(probas_pred))`.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    PrecisionRecallDisplay.from_estimator : Plot Precision Recall Curve given</span>
<span class="sd">        a binary classifier.</span>
<span class="sd">    PrecisionRecallDisplay.from_predictions : Plot Precision Recall Curve</span>
<span class="sd">        using predictions from a binary classifier.</span>
<span class="sd">    average_precision_score : Compute average precision from prediction scores.</span>
<span class="sd">    det_curve: Compute error rates for different probability thresholds.</span>
<span class="sd">    roc_curve : Compute Receiver operating characteristic (ROC) curve.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import precision_recall_curve</span>
<span class="sd">    &gt;&gt;&gt; y_true = np.array([0, 0, 1, 1])</span>
<span class="sd">    &gt;&gt;&gt; y_scores = np.array([0.1, 0.4, 0.35, 0.8])</span>
<span class="sd">    &gt;&gt;&gt; precision, recall, thresholds = precision_recall_curve(</span>
<span class="sd">    ...     y_true, y_scores)</span>
<span class="sd">    &gt;&gt;&gt; precision</span>
<span class="sd">    array([0.5       , 0.66666667, 0.5       , 1.        , 1.        ])</span>
<span class="sd">    &gt;&gt;&gt; recall</span>
<span class="sd">    array([1. , 1. , 0.5, 0.5, 0. ])</span>
<span class="sd">    &gt;&gt;&gt; thresholds</span>
<span class="sd">    array([0.1 , 0.35, 0.4 , 0.8 ])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fps</span><span class="p">,</span> <span class="n">tps</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">_binary_clf_curve</span><span class="p">(</span>
        <span class="n">y_true</span><span class="p">,</span> <span class="n">probas_pred</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">drop_intermediate</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">fps</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="c1"># Drop thresholds corresponding to points where true positives (tps)</span>
        <span class="c1"># do not change from the previous or subsequent point. This will keep</span>
        <span class="c1"># only the first and last point for each tps value. All points</span>
        <span class="c1"># with the same tps value have the same recall and thus x coordinate.</span>
        <span class="c1"># They appear as a vertical line on the plot.</span>
        <span class="n">optimal_idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
                <span class="p">[[</span><span class="kc">True</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_or</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">tps</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">tps</span><span class="p">[</span><span class="mi">1</span><span class="p">:])),</span> <span class="p">[</span><span class="kc">True</span><span class="p">]]</span>
            <span class="p">)</span>
        <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">fps</span> <span class="o">=</span> <span class="n">fps</span><span class="p">[</span><span class="n">optimal_idxs</span><span class="p">]</span>
        <span class="n">tps</span> <span class="o">=</span> <span class="n">tps</span><span class="p">[</span><span class="n">optimal_idxs</span><span class="p">]</span>
        <span class="n">thresholds</span> <span class="o">=</span> <span class="n">thresholds</span><span class="p">[</span><span class="n">optimal_idxs</span><span class="p">]</span>

    <span class="n">ps</span> <span class="o">=</span> <span class="n">tps</span> <span class="o">+</span> <span class="n">fps</span>
    <span class="c1"># Initialize the result array with zeros to make sure that precision[ps == 0]</span>
    <span class="c1"># does not contain uninitialized values.</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">tps</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">tps</span><span class="p">,</span> <span class="n">ps</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">precision</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="p">(</span><span class="n">ps</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">))</span>

    <span class="c1"># When no positive label in y_true, recall is set to 1 for all thresholds</span>
    <span class="c1"># tps[-1] == 0 &lt;=&gt; y_true == all negative labels</span>
    <span class="k">if</span> <span class="n">tps</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;No positive class found in y_true, &quot;</span>
            <span class="s2">&quot;recall is set to one for all thresholds.&quot;</span>
        <span class="p">)</span>
        <span class="n">recall</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">tps</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">recall</span> <span class="o">=</span> <span class="n">tps</span> <span class="o">/</span> <span class="n">tps</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># reverse the outputs so recall is decreasing</span>
    <span class="n">sl</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">precision</span><span class="p">[</span><span class="n">sl</span><span class="p">],</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">recall</span><span class="p">[</span><span class="n">sl</span><span class="p">],</span> <span class="mi">0</span><span class="p">)),</span> <span class="n">thresholds</span><span class="p">[</span><span class="n">sl</span><span class="p">]</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_score&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;pos_label&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Real</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;drop_intermediate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;boolean&quot;</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">roc_curve</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">drop_intermediate</span><span class="o">=</span><span class="kc">True</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute Receiver operating characteristic (ROC).</span>

<span class="sd">    Note: this implementation is restricted to the binary classification task.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;roc_metrics&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : array-like of shape (n_samples,)</span>
<span class="sd">        True binary labels. If labels are not either {-1, 1} or {0, 1}, then</span>
<span class="sd">        pos_label should be explicitly given.</span>

<span class="sd">    y_score : array-like of shape (n_samples,)</span>
<span class="sd">        Target scores, can either be probability estimates of the positive</span>
<span class="sd">        class, confidence values, or non-thresholded measure of decisions</span>
<span class="sd">        (as returned by &quot;decision_function&quot; on some classifiers).</span>

<span class="sd">    pos_label : int, float, bool or str, default=None</span>
<span class="sd">        The label of the positive class.</span>
<span class="sd">        When ``pos_label=None``, if `y_true` is in {-1, 1} or {0, 1},</span>
<span class="sd">        ``pos_label`` is set to 1, otherwise an error will be raised.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">    drop_intermediate : bool, default=True</span>
<span class="sd">        Whether to drop some suboptimal thresholds which would not appear</span>
<span class="sd">        on a plotted ROC curve. This is useful in order to create lighter</span>
<span class="sd">        ROC curves.</span>

<span class="sd">        .. versionadded:: 0.17</span>
<span class="sd">           parameter *drop_intermediate*.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    fpr : ndarray of shape (&gt;2,)</span>
<span class="sd">        Increasing false positive rates such that element i is the false</span>
<span class="sd">        positive rate of predictions with score &gt;= `thresholds[i]`.</span>

<span class="sd">    tpr : ndarray of shape (&gt;2,)</span>
<span class="sd">        Increasing true positive rates such that element `i` is the true</span>
<span class="sd">        positive rate of predictions with score &gt;= `thresholds[i]`.</span>

<span class="sd">    thresholds : ndarray of shape (n_thresholds,)</span>
<span class="sd">        Decreasing thresholds on the decision function used to compute</span>
<span class="sd">        fpr and tpr. `thresholds[0]` represents no instances being predicted</span>
<span class="sd">        and is arbitrarily set to `np.inf`.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    RocCurveDisplay.from_estimator : Plot Receiver Operating Characteristic</span>
<span class="sd">        (ROC) curve given an estimator and some data.</span>
<span class="sd">    RocCurveDisplay.from_predictions : Plot Receiver Operating Characteristic</span>
<span class="sd">        (ROC) curve given the true and predicted values.</span>
<span class="sd">    det_curve: Compute error rates for different probability thresholds.</span>
<span class="sd">    roc_auc_score : Compute the area under the ROC curve.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Since the thresholds are sorted from low to high values, they</span>
<span class="sd">    are reversed upon returning them to ensure they correspond to both ``fpr``</span>
<span class="sd">    and ``tpr``, which are sorted in reversed order during their calculation.</span>

<span class="sd">    An arbitrary threshold is added for the case `tpr=0` and `fpr=0` to</span>
<span class="sd">    ensure that the curve starts at `(0, 0)`. This threshold corresponds to the</span>
<span class="sd">    `np.inf`.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] `Wikipedia entry for the Receiver operating characteristic</span>
<span class="sd">            &lt;https://en.wikipedia.org/wiki/Receiver_operating_characteristic&gt;`_</span>

<span class="sd">    .. [2] Fawcett T. An introduction to ROC analysis[J]. Pattern Recognition</span>
<span class="sd">           Letters, 2006, 27(8):861-874.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn import metrics</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 1, 2, 2])</span>
<span class="sd">    &gt;&gt;&gt; scores = np.array([0.1, 0.4, 0.35, 0.8])</span>
<span class="sd">    &gt;&gt;&gt; fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)</span>
<span class="sd">    &gt;&gt;&gt; fpr</span>
<span class="sd">    array([0. , 0. , 0.5, 0.5, 1. ])</span>
<span class="sd">    &gt;&gt;&gt; tpr</span>
<span class="sd">    array([0. , 0.5, 0.5, 1. , 1. ])</span>
<span class="sd">    &gt;&gt;&gt; thresholds</span>
<span class="sd">    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fps</span><span class="p">,</span> <span class="n">tps</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">_binary_clf_curve</span><span class="p">(</span>
        <span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span>
    <span class="p">)</span>

    <span class="c1"># Attempt to drop thresholds corresponding to points in between and</span>
    <span class="c1"># collinear with other points. These are always suboptimal and do not</span>
    <span class="c1"># appear on a plotted ROC curve (and thus do not affect the AUC).</span>
    <span class="c1"># Here np.diff(_, 2) is used as a &quot;second derivative&quot; to tell if there</span>
    <span class="c1"># is a corner at the point. Both fps and tps must be tested to handle</span>
    <span class="c1"># thresholds with multiple data points (which are combined in</span>
    <span class="c1"># _binary_clf_curve). This keeps all cases where the point should be kept,</span>
    <span class="c1"># but does not drop more complicated cases like fps = [1, 3, 7],</span>
    <span class="c1"># tps = [1, 2, 4]; there is no harm in keeping too many thresholds.</span>
    <span class="k">if</span> <span class="n">drop_intermediate</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">fps</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">optimal_idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_or</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">fps</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">tps</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="kc">True</span><span class="p">]</span>
        <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">fps</span> <span class="o">=</span> <span class="n">fps</span><span class="p">[</span><span class="n">optimal_idxs</span><span class="p">]</span>
        <span class="n">tps</span> <span class="o">=</span> <span class="n">tps</span><span class="p">[</span><span class="n">optimal_idxs</span><span class="p">]</span>
        <span class="n">thresholds</span> <span class="o">=</span> <span class="n">thresholds</span><span class="p">[</span><span class="n">optimal_idxs</span><span class="p">]</span>

    <span class="c1"># Add an extra threshold position</span>
    <span class="c1"># to make sure that the curve starts at (0, 0)</span>
    <span class="n">tps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">tps</span><span class="p">]</span>
    <span class="n">fps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">fps</span><span class="p">]</span>
    <span class="c1"># get dtype of `y_score` even if it is an array-like</span>
    <span class="n">thresholds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">thresholds</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">fps</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;No negative samples in y_true, false positive value should be meaningless&quot;</span><span class="p">,</span>
            <span class="n">UndefinedMetricWarning</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">fpr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">fps</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">fpr</span> <span class="o">=</span> <span class="n">fps</span> <span class="o">/</span> <span class="n">fps</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">tps</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;No positive samples in y_true, true positive value should be meaningless&quot;</span><span class="p">,</span>
            <span class="n">UndefinedMetricWarning</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">tpr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">tps</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">tpr</span> <span class="o">=</span> <span class="n">tps</span> <span class="o">/</span> <span class="n">tps</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_score&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">label_ranking_average_precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute ranking-based average precision.</span>

<span class="sd">    Label ranking average precision (LRAP) is the average over each ground</span>
<span class="sd">    truth label assigned to each sample, of the ratio of true vs. total</span>
<span class="sd">    labels with lower score.</span>

<span class="sd">    This metric is used in multilabel ranking problem, where the goal</span>
<span class="sd">    is to give better rank to the labels associated to each sample.</span>

<span class="sd">    The obtained score is always strictly greater than 0 and</span>
<span class="sd">    the best value is 1.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;label_ranking_average_precision&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : {array-like, sparse matrix} of shape (n_samples, n_labels)</span>
<span class="sd">        True binary labels in binary indicator format.</span>

<span class="sd">    y_score : array-like of shape (n_samples, n_labels)</span>
<span class="sd">        Target scores, can either be probability estimates of the positive</span>
<span class="sd">        class, confidence values, or non-thresholded measure of decisions</span>
<span class="sd">        (as returned by &quot;decision_function&quot; on some classifiers).</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">        .. versionadded:: 0.20</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : float</span>
<span class="sd">        Ranking-based average precision score.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import label_ranking_average_precision_score</span>
<span class="sd">    &gt;&gt;&gt; y_true = np.array([[1, 0, 0], [0, 0, 1]])</span>
<span class="sd">    &gt;&gt;&gt; y_score = np.array([[0.75, 0.5, 1], [1, 0.2, 0.1]])</span>
<span class="sd">    &gt;&gt;&gt; label_ranking_average_precision_score(y_true, y_score)</span>
<span class="sd">    0.416...</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">check_consistent_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">)</span>
    <span class="n">y_score</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y_score</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">y_true</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">y_score</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;y_true and y_score have different shape&quot;</span><span class="p">)</span>

    <span class="c1"># Handle badly formatted array and the degenerate case with one label</span>
    <span class="n">y_type</span> <span class="o">=</span> <span class="n">type_of_target</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;y_true&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">y_type</span> <span class="o">!=</span> <span class="s2">&quot;multilabel-indicator&quot;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="p">(</span>
        <span class="n">y_type</span> <span class="o">==</span> <span class="s2">&quot;binary&quot;</span> <span class="ow">and</span> <span class="n">y_true</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{0}</span><span class="s2"> format is not supported&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_type</span><span class="p">))</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">issparse</span><span class="p">(</span><span class="n">y_true</span><span class="p">):</span>
        <span class="n">y_true</span> <span class="o">=</span> <span class="n">csr_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>

    <span class="n">y_score</span> <span class="o">=</span> <span class="o">-</span><span class="n">y_score</span>

    <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_labels</span> <span class="o">=</span> <span class="n">y_true</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">out</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">y_true</span><span class="o">.</span><span class="n">indptr</span><span class="p">,</span> <span class="n">y_true</span><span class="o">.</span><span class="n">indptr</span><span class="p">[</span><span class="mi">1</span><span class="p">:])):</span>
        <span class="n">relevant</span> <span class="o">=</span> <span class="n">y_true</span><span class="o">.</span><span class="n">indices</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">stop</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">relevant</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">relevant</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="n">n_labels</span><span class="p">:</span>
            <span class="c1"># If all labels are relevant or unrelevant, the score is also</span>
            <span class="c1"># equal to 1. The label ranking has no meaning.</span>
            <span class="n">aux</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">scores_i</span> <span class="o">=</span> <span class="n">y_score</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">rank</span> <span class="o">=</span> <span class="n">rankdata</span><span class="p">(</span><span class="n">scores_i</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">)[</span><span class="n">relevant</span><span class="p">]</span>
            <span class="n">L</span> <span class="o">=</span> <span class="n">rankdata</span><span class="p">(</span><span class="n">scores_i</span><span class="p">[</span><span class="n">relevant</span><span class="p">],</span> <span class="s2">&quot;max&quot;</span><span class="p">)</span>
            <span class="n">aux</span> <span class="o">=</span> <span class="p">(</span><span class="n">L</span> <span class="o">/</span> <span class="n">rank</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">aux</span> <span class="o">=</span> <span class="n">aux</span> <span class="o">*</span> <span class="n">sample_weight</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">out</span> <span class="o">+=</span> <span class="n">aux</span>

    <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">/=</span> <span class="n">n_samples</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">out</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_score&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">coverage_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Coverage error measure.</span>

<span class="sd">    Compute how far we need to go through the ranked scores to cover all</span>
<span class="sd">    true labels. The best value is equal to the average number</span>
<span class="sd">    of labels in ``y_true`` per sample.</span>

<span class="sd">    Ties in ``y_scores`` are broken by giving maximal rank that would have</span>
<span class="sd">    been assigned to all tied values.</span>

<span class="sd">    Note: Our implementation&#39;s score is 1 greater than the one given in</span>
<span class="sd">    Tsoumakas et al., 2010. This extends it to handle the degenerate case</span>
<span class="sd">    in which an instance has 0 true labels.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;coverage_error&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : array-like of shape (n_samples, n_labels)</span>
<span class="sd">        True binary labels in binary indicator format.</span>

<span class="sd">    y_score : array-like of shape (n_samples, n_labels)</span>
<span class="sd">        Target scores, can either be probability estimates of the positive</span>
<span class="sd">        class, confidence values, or non-thresholded measure of decisions</span>
<span class="sd">        (as returned by &quot;decision_function&quot; on some classifiers).</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    coverage_error : float</span>
<span class="sd">        The coverage error.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Tsoumakas, G., Katakis, I., &amp; Vlahavas, I. (2010).</span>
<span class="sd">           Mining multi-label data. In Data mining and knowledge discovery</span>
<span class="sd">           handbook (pp. 667-685). Springer US.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import coverage_error</span>
<span class="sd">    &gt;&gt;&gt; y_true = [[1, 0, 0], [0, 1, 1]]</span>
<span class="sd">    &gt;&gt;&gt; y_score = [[1, 0, 0], [0, 1, 1]]</span>
<span class="sd">    &gt;&gt;&gt; coverage_error(y_true, y_score)</span>
<span class="sd">    1.5</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">y_score</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y_score</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">check_consistent_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>

    <span class="n">y_type</span> <span class="o">=</span> <span class="n">type_of_target</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;y_true&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">y_type</span> <span class="o">!=</span> <span class="s2">&quot;multilabel-indicator&quot;</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{0}</span><span class="s2"> format is not supported&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_type</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">y_true</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">y_score</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;y_true and y_score have different shape&quot;</span><span class="p">)</span>

    <span class="n">y_score_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ma</span><span class="o">.</span><span class="n">masked_array</span><span class="p">(</span><span class="n">y_score</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">y_true</span><span class="p">))</span>
    <span class="n">y_min_relevant</span> <span class="o">=</span> <span class="n">y_score_mask</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">coverage</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_score</span> <span class="o">&gt;=</span> <span class="n">y_min_relevant</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">coverage</span> <span class="o">=</span> <span class="n">coverage</span><span class="o">.</span><span class="n">filled</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">coverage</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_score&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">label_ranking_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute Ranking loss measure.</span>

<span class="sd">    Compute the average number of label pairs that are incorrectly ordered</span>
<span class="sd">    given y_score weighted by the size of the label set and the number of</span>
<span class="sd">    labels not in the label set.</span>

<span class="sd">    This is similar to the error set size, but weighted by the number of</span>
<span class="sd">    relevant and irrelevant labels. The best performance is achieved with</span>
<span class="sd">    a ranking loss of zero.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;label_ranking_loss&gt;`.</span>

<span class="sd">    .. versionadded:: 0.17</span>
<span class="sd">       A function *label_ranking_loss*</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : {array-like, sparse matrix} of shape (n_samples, n_labels)</span>
<span class="sd">        True binary labels in binary indicator format.</span>

<span class="sd">    y_score : array-like of shape (n_samples, n_labels)</span>
<span class="sd">        Target scores, can either be probability estimates of the positive</span>
<span class="sd">        class, confidence values, or non-thresholded measure of decisions</span>
<span class="sd">        (as returned by &quot;decision_function&quot; on some classifiers).</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    loss : float</span>
<span class="sd">        Average number of label pairs that are incorrectly ordered given</span>
<span class="sd">        y_score weighted by the size of the label set and the number of labels not</span>
<span class="sd">        in the label set.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Tsoumakas, G., Katakis, I., &amp; Vlahavas, I. (2010).</span>
<span class="sd">           Mining multi-label data. In Data mining and knowledge discovery</span>
<span class="sd">           handbook (pp. 667-685). Springer US.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import label_ranking_loss</span>
<span class="sd">    &gt;&gt;&gt; y_true = [[1, 0, 0], [0, 0, 1]]</span>
<span class="sd">    &gt;&gt;&gt; y_score = [[0.75, 0.5, 1], [1, 0.2, 0.1]]</span>
<span class="sd">    &gt;&gt;&gt; label_ranking_loss(y_true, y_score)</span>
<span class="sd">    0.75...</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">)</span>
    <span class="n">y_score</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y_score</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">check_consistent_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>

    <span class="n">y_type</span> <span class="o">=</span> <span class="n">type_of_target</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;y_true&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">y_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;multilabel-indicator&quot;</span><span class="p">,):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{0}</span><span class="s2"> format is not supported&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_type</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">y_true</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">y_score</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;y_true and y_score have different shape&quot;</span><span class="p">)</span>

    <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_labels</span> <span class="o">=</span> <span class="n">y_true</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">y_true</span> <span class="o">=</span> <span class="n">csr_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">y_true</span><span class="o">.</span><span class="n">indptr</span><span class="p">,</span> <span class="n">y_true</span><span class="o">.</span><span class="n">indptr</span><span class="p">[</span><span class="mi">1</span><span class="p">:])):</span>
        <span class="c1"># Sort and bin the label scores</span>
        <span class="n">unique_scores</span><span class="p">,</span> <span class="n">unique_inverse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_score</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">true_at_reversed_rank</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span>
            <span class="n">unique_inverse</span><span class="p">[</span><span class="n">y_true</span><span class="o">.</span><span class="n">indices</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">stop</span><span class="p">]],</span> <span class="n">minlength</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_scores</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">all_at_reversed_rank</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">unique_inverse</span><span class="p">,</span> <span class="n">minlength</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_scores</span><span class="p">))</span>
        <span class="n">false_at_reversed_rank</span> <span class="o">=</span> <span class="n">all_at_reversed_rank</span> <span class="o">-</span> <span class="n">true_at_reversed_rank</span>

        <span class="c1"># if the scores are ordered, it&#39;s possible to count the number of</span>
        <span class="c1"># incorrectly ordered paires in linear time by cumulatively counting</span>
        <span class="c1"># how many false labels of a given score have a score higher than the</span>
        <span class="c1"># accumulated true labels with lower score.</span>
        <span class="n">loss</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">true_at_reversed_rank</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(),</span> <span class="n">false_at_reversed_rank</span><span class="p">)</span>

    <span class="n">n_positives</span> <span class="o">=</span> <span class="n">count_nonzero</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">errstate</span><span class="p">(</span><span class="n">divide</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">invalid</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">/=</span> <span class="p">(</span><span class="n">n_labels</span> <span class="o">-</span> <span class="n">n_positives</span><span class="p">)</span> <span class="o">*</span> <span class="n">n_positives</span>

    <span class="c1"># When there is no positive or no negative labels, those values should</span>
    <span class="c1"># be consider as correct, i.e. the ranking doesn&#39;t matter.</span>
    <span class="n">loss</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">logical_or</span><span class="p">(</span><span class="n">n_positives</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="n">n_positives</span> <span class="o">==</span> <span class="n">n_labels</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_dcg_sample_scores</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">log_base</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ignore_ties</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute Discounted Cumulative Gain.</span>

<span class="sd">    Sum the true scores ranked in the order induced by the predicted scores,</span>
<span class="sd">    after applying a logarithmic discount.</span>

<span class="sd">    This ranking metric yields a high value if true labels are ranked high by</span>
<span class="sd">    ``y_score``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : ndarray of shape (n_samples, n_labels)</span>
<span class="sd">        True targets of multilabel classification, or true scores of entities</span>
<span class="sd">        to be ranked.</span>

<span class="sd">    y_score : ndarray of shape (n_samples, n_labels)</span>
<span class="sd">        Target scores, can either be probability estimates, confidence values,</span>
<span class="sd">        or non-thresholded measure of decisions (as returned by</span>
<span class="sd">        &quot;decision_function&quot; on some classifiers).</span>

<span class="sd">    k : int, default=None</span>
<span class="sd">        Only consider the highest k scores in the ranking. If `None`, use all</span>
<span class="sd">        outputs.</span>

<span class="sd">    log_base : float, default=2</span>
<span class="sd">        Base of the logarithm used for the discount. A low value means a</span>
<span class="sd">        sharper discount (top results are more important).</span>

<span class="sd">    ignore_ties : bool, default=False</span>
<span class="sd">        Assume that there are no ties in y_score (which is likely to be the</span>
<span class="sd">        case if y_score is continuous) for efficiency gains.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    discounted_cumulative_gain : ndarray of shape (n_samples,)</span>
<span class="sd">        The DCG score for each sample.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    ndcg_score : The Discounted Cumulative Gain divided by the Ideal Discounted</span>
<span class="sd">        Cumulative Gain (the DCG obtained for a perfect ranking), in order to</span>
<span class="sd">        have a score between 0 and 1.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">discount</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y_true</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">log_base</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">k</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">discount</span><span class="p">[</span><span class="n">k</span><span class="p">:]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">ignore_ties</span><span class="p">:</span>
        <span class="n">ranking</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">y_score</span><span class="p">)[:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">ranked</span> <span class="o">=</span> <span class="n">y_true</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">ranking</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">ranking</span><span class="p">]</span>
        <span class="n">cumulative_gains</span> <span class="o">=</span> <span class="n">discount</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ranked</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">discount_cumsum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">discount</span><span class="p">)</span>
        <span class="n">cumulative_gains</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">_tie_averaged_dcg</span><span class="p">(</span><span class="n">y_t</span><span class="p">,</span> <span class="n">y_s</span><span class="p">,</span> <span class="n">discount_cumsum</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">y_t</span><span class="p">,</span> <span class="n">y_s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">cumulative_gains</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">cumulative_gains</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">cumulative_gains</span>


<span class="k">def</span> <span class="nf">_tie_averaged_dcg</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">discount_cumsum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute DCG by averaging over possible permutations of ties.</span>

<span class="sd">    The gain (`y_true`) of an index falling inside a tied group (in the order</span>
<span class="sd">    induced by `y_score`) is replaced by the average gain within this group.</span>
<span class="sd">    The discounted gain for a tied group is then the average `y_true` within</span>
<span class="sd">    this group times the sum of discounts of the corresponding ranks.</span>

<span class="sd">    This amounts to averaging scores for all possible orderings of the tied</span>
<span class="sd">    groups.</span>

<span class="sd">    (note in the case of dcg@k the discount is 0 after index k)</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : ndarray</span>
<span class="sd">        The true relevance scores.</span>

<span class="sd">    y_score : ndarray</span>
<span class="sd">        Predicted scores.</span>

<span class="sd">    discount_cumsum : ndarray</span>
<span class="sd">        Precomputed cumulative sum of the discounts.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    discounted_cumulative_gain : float</span>
<span class="sd">        The discounted cumulative gain.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    McSherry, F., &amp; Najork, M. (2008, March). Computing information retrieval</span>
<span class="sd">    performance measures efficiently in the presence of tied scores. In</span>
<span class="sd">    European conference on information retrieval (pp. 414-421). Springer,</span>
<span class="sd">    Berlin, Heidelberg.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">inv</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="o">-</span><span class="n">y_score</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">ranked</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">counts</span><span class="p">))</span>
    <span class="n">np</span><span class="o">.</span><span class="n">add</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">ranked</span><span class="p">,</span> <span class="n">inv</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>
    <span class="n">ranked</span> <span class="o">/=</span> <span class="n">counts</span>
    <span class="n">groups</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">counts</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">discount_sums</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">counts</span><span class="p">))</span>
    <span class="n">discount_sums</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">discount_cumsum</span><span class="p">[</span><span class="n">groups</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">discount_sums</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">discount_cumsum</span><span class="p">[</span><span class="n">groups</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">ranked</span> <span class="o">*</span> <span class="n">discount_sums</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">_check_dcg_target_type</span><span class="p">(</span><span class="n">y_true</span><span class="p">):</span>
    <span class="n">y_type</span> <span class="o">=</span> <span class="n">type_of_target</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;y_true&quot;</span><span class="p">)</span>
    <span class="n">supported_fmt</span> <span class="o">=</span> <span class="p">(</span>
        <span class="s2">&quot;multilabel-indicator&quot;</span><span class="p">,</span>
        <span class="s2">&quot;continuous-multioutput&quot;</span><span class="p">,</span>
        <span class="s2">&quot;multiclass-multioutput&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">y_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">supported_fmt</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Only </span><span class="si">{}</span><span class="s2"> formats are supported. Got </span><span class="si">{}</span><span class="s2"> instead&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">supported_fmt</span><span class="p">,</span> <span class="n">y_type</span>
            <span class="p">)</span>
        <span class="p">)</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_score&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;k&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">Integral</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">),</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;log_base&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">Real</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;neither&quot;</span><span class="p">)],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;ignore_ties&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;boolean&quot;</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">dcg_score</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">log_base</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ignore_ties</span><span class="o">=</span><span class="kc">False</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute Discounted Cumulative Gain.</span>

<span class="sd">    Sum the true scores ranked in the order induced by the predicted scores,</span>
<span class="sd">    after applying a logarithmic discount.</span>

<span class="sd">    This ranking metric yields a high value if true labels are ranked high by</span>
<span class="sd">    ``y_score``.</span>

<span class="sd">    Usually the Normalized Discounted Cumulative Gain (NDCG, computed by</span>
<span class="sd">    ndcg_score) is preferred.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : array-like of shape (n_samples, n_labels)</span>
<span class="sd">        True targets of multilabel classification, or true scores of entities</span>
<span class="sd">        to be ranked.</span>

<span class="sd">    y_score : array-like of shape (n_samples, n_labels)</span>
<span class="sd">        Target scores, can either be probability estimates, confidence values,</span>
<span class="sd">        or non-thresholded measure of decisions (as returned by</span>
<span class="sd">        &quot;decision_function&quot; on some classifiers).</span>

<span class="sd">    k : int, default=None</span>
<span class="sd">        Only consider the highest k scores in the ranking. If None, use all</span>
<span class="sd">        outputs.</span>

<span class="sd">    log_base : float, default=2</span>
<span class="sd">        Base of the logarithm used for the discount. A low value means a</span>
<span class="sd">        sharper discount (top results are more important).</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights. If `None`, all samples are given the same weight.</span>

<span class="sd">    ignore_ties : bool, default=False</span>
<span class="sd">        Assume that there are no ties in y_score (which is likely to be the</span>
<span class="sd">        case if y_score is continuous) for efficiency gains.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    discounted_cumulative_gain : float</span>
<span class="sd">        The averaged sample DCG scores.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    ndcg_score : The Discounted Cumulative Gain divided by the Ideal Discounted</span>
<span class="sd">        Cumulative Gain (the DCG obtained for a perfect ranking), in order to</span>
<span class="sd">        have a score between 0 and 1.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    `Wikipedia entry for Discounted Cumulative Gain</span>
<span class="sd">    &lt;https://en.wikipedia.org/wiki/Discounted_cumulative_gain&gt;`_.</span>

<span class="sd">    Jarvelin, K., &amp; Kekalainen, J. (2002).</span>
<span class="sd">    Cumulated gain-based evaluation of IR techniques. ACM Transactions on</span>
<span class="sd">    Information Systems (TOIS), 20(4), 422-446.</span>

<span class="sd">    Wang, Y., Wang, L., Li, Y., He, D., Chen, W., &amp; Liu, T. Y. (2013, May).</span>
<span class="sd">    A theoretical analysis of NDCG ranking measures. In Proceedings of the 26th</span>
<span class="sd">    Annual Conference on Learning Theory (COLT 2013).</span>

<span class="sd">    McSherry, F., &amp; Najork, M. (2008, March). Computing information retrieval</span>
<span class="sd">    performance measures efficiently in the presence of tied scores. In</span>
<span class="sd">    European conference on information retrieval (pp. 414-421). Springer,</span>
<span class="sd">    Berlin, Heidelberg.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import dcg_score</span>
<span class="sd">    &gt;&gt;&gt; # we have groud-truth relevance of some answers to a query:</span>
<span class="sd">    &gt;&gt;&gt; true_relevance = np.asarray([[10, 0, 0, 1, 5]])</span>
<span class="sd">    &gt;&gt;&gt; # we predict scores for the answers</span>
<span class="sd">    &gt;&gt;&gt; scores = np.asarray([[.1, .2, .3, 4, 70]])</span>
<span class="sd">    &gt;&gt;&gt; dcg_score(true_relevance, scores)</span>
<span class="sd">    9.49...</span>
<span class="sd">    &gt;&gt;&gt; # we can set k to truncate the sum; only top k answers contribute</span>
<span class="sd">    &gt;&gt;&gt; dcg_score(true_relevance, scores, k=2)</span>
<span class="sd">    5.63...</span>
<span class="sd">    &gt;&gt;&gt; # now we have some ties in our prediction</span>
<span class="sd">    &gt;&gt;&gt; scores = np.asarray([[1, 0, 0, 0, 1]])</span>
<span class="sd">    &gt;&gt;&gt; # by default ties are averaged, so here we get the average true</span>
<span class="sd">    &gt;&gt;&gt; # relevance of our top predictions: (10 + 5) / 2 = 7.5</span>
<span class="sd">    &gt;&gt;&gt; dcg_score(true_relevance, scores, k=1)</span>
<span class="sd">    7.5</span>
<span class="sd">    &gt;&gt;&gt; # we can choose to ignore ties for faster results, but only</span>
<span class="sd">    &gt;&gt;&gt; # if we know there aren&#39;t ties in our scores, otherwise we get</span>
<span class="sd">    &gt;&gt;&gt; # wrong results:</span>
<span class="sd">    &gt;&gt;&gt; dcg_score(true_relevance,</span>
<span class="sd">    ...           scores, k=1, ignore_ties=True)</span>
<span class="sd">    5.0</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">y_score</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y_score</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">check_consistent_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>
    <span class="n">_check_dcg_target_type</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span>
        <span class="n">_dcg_sample_scores</span><span class="p">(</span>
            <span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">log_base</span><span class="o">=</span><span class="n">log_base</span><span class="p">,</span> <span class="n">ignore_ties</span><span class="o">=</span><span class="n">ignore_ties</span>
        <span class="p">),</span>
        <span class="n">weights</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">_ndcg_sample_scores</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ignore_ties</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute Normalized Discounted Cumulative Gain.</span>

<span class="sd">    Sum the true scores ranked in the order induced by the predicted scores,</span>
<span class="sd">    after applying a logarithmic discount. Then divide by the best possible</span>
<span class="sd">    score (Ideal DCG, obtained for a perfect ranking) to obtain a score between</span>
<span class="sd">    0 and 1.</span>

<span class="sd">    This ranking metric yields a high value if true labels are ranked high by</span>
<span class="sd">    ``y_score``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : ndarray of shape (n_samples, n_labels)</span>
<span class="sd">        True targets of multilabel classification, or true scores of entities</span>
<span class="sd">        to be ranked.</span>

<span class="sd">    y_score : ndarray of shape (n_samples, n_labels)</span>
<span class="sd">        Target scores, can either be probability estimates, confidence values,</span>
<span class="sd">        or non-thresholded measure of decisions (as returned by</span>
<span class="sd">        &quot;decision_function&quot; on some classifiers).</span>

<span class="sd">    k : int, default=None</span>
<span class="sd">        Only consider the highest k scores in the ranking. If None, use all</span>
<span class="sd">        outputs.</span>

<span class="sd">    ignore_ties : bool, default=False</span>
<span class="sd">        Assume that there are no ties in y_score (which is likely to be the</span>
<span class="sd">        case if y_score is continuous) for efficiency gains.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    normalized_discounted_cumulative_gain : ndarray of shape (n_samples,)</span>
<span class="sd">        The NDCG score for each sample (float in [0., 1.]).</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    dcg_score : Discounted Cumulative Gain (not normalized).</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">gain</span> <span class="o">=</span> <span class="n">_dcg_sample_scores</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">ignore_ties</span><span class="o">=</span><span class="n">ignore_ties</span><span class="p">)</span>
    <span class="c1"># Here we use the order induced by y_true so we can ignore ties since</span>
    <span class="c1"># the gain associated to tied indices is the same (permuting ties doesn&#39;t</span>
    <span class="c1"># change the value of the re-ordered y_true)</span>
    <span class="n">normalizing_gain</span> <span class="o">=</span> <span class="n">_dcg_sample_scores</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">ignore_ties</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">all_irrelevant</span> <span class="o">=</span> <span class="n">normalizing_gain</span> <span class="o">==</span> <span class="mi">0</span>
    <span class="n">gain</span><span class="p">[</span><span class="n">all_irrelevant</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">gain</span><span class="p">[</span><span class="o">~</span><span class="n">all_irrelevant</span><span class="p">]</span> <span class="o">/=</span> <span class="n">normalizing_gain</span><span class="p">[</span><span class="o">~</span><span class="n">all_irrelevant</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">gain</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_score&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;k&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">Integral</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">),</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;ignore_ties&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;boolean&quot;</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">ndcg_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ignore_ties</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute Normalized Discounted Cumulative Gain.</span>

<span class="sd">    Sum the true scores ranked in the order induced by the predicted scores,</span>
<span class="sd">    after applying a logarithmic discount. Then divide by the best possible</span>
<span class="sd">    score (Ideal DCG, obtained for a perfect ranking) to obtain a score between</span>
<span class="sd">    0 and 1.</span>

<span class="sd">    This ranking metric returns a high value if true labels are ranked high by</span>
<span class="sd">    ``y_score``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : array-like of shape (n_samples, n_labels)</span>
<span class="sd">        True targets of multilabel classification, or true scores of entities</span>
<span class="sd">        to be ranked. Negative values in `y_true` may result in an output</span>
<span class="sd">        that is not between 0 and 1.</span>

<span class="sd">    y_score : array-like of shape (n_samples, n_labels)</span>
<span class="sd">        Target scores, can either be probability estimates, confidence values,</span>
<span class="sd">        or non-thresholded measure of decisions (as returned by</span>
<span class="sd">        &quot;decision_function&quot; on some classifiers).</span>

<span class="sd">    k : int, default=None</span>
<span class="sd">        Only consider the highest k scores in the ranking. If `None`, use all</span>
<span class="sd">        outputs.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights. If `None`, all samples are given the same weight.</span>

<span class="sd">    ignore_ties : bool, default=False</span>
<span class="sd">        Assume that there are no ties in y_score (which is likely to be the</span>
<span class="sd">        case if y_score is continuous) for efficiency gains.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    normalized_discounted_cumulative_gain : float in [0., 1.]</span>
<span class="sd">        The averaged NDCG scores for all samples.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    dcg_score : Discounted Cumulative Gain (not normalized).</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    `Wikipedia entry for Discounted Cumulative Gain</span>
<span class="sd">    &lt;https://en.wikipedia.org/wiki/Discounted_cumulative_gain&gt;`_</span>

<span class="sd">    Jarvelin, K., &amp; Kekalainen, J. (2002).</span>
<span class="sd">    Cumulated gain-based evaluation of IR techniques. ACM Transactions on</span>
<span class="sd">    Information Systems (TOIS), 20(4), 422-446.</span>

<span class="sd">    Wang, Y., Wang, L., Li, Y., He, D., Chen, W., &amp; Liu, T. Y. (2013, May).</span>
<span class="sd">    A theoretical analysis of NDCG ranking measures. In Proceedings of the 26th</span>
<span class="sd">    Annual Conference on Learning Theory (COLT 2013)</span>

<span class="sd">    McSherry, F., &amp; Najork, M. (2008, March). Computing information retrieval</span>
<span class="sd">    performance measures efficiently in the presence of tied scores. In</span>
<span class="sd">    European conference on information retrieval (pp. 414-421). Springer,</span>
<span class="sd">    Berlin, Heidelberg.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import ndcg_score</span>
<span class="sd">    &gt;&gt;&gt; # we have groud-truth relevance of some answers to a query:</span>
<span class="sd">    &gt;&gt;&gt; true_relevance = np.asarray([[10, 0, 0, 1, 5]])</span>
<span class="sd">    &gt;&gt;&gt; # we predict some scores (relevance) for the answers</span>
<span class="sd">    &gt;&gt;&gt; scores = np.asarray([[.1, .2, .3, 4, 70]])</span>
<span class="sd">    &gt;&gt;&gt; ndcg_score(true_relevance, scores)</span>
<span class="sd">    0.69...</span>
<span class="sd">    &gt;&gt;&gt; scores = np.asarray([[.05, 1.1, 1., .5, .0]])</span>
<span class="sd">    &gt;&gt;&gt; ndcg_score(true_relevance, scores)</span>
<span class="sd">    0.49...</span>
<span class="sd">    &gt;&gt;&gt; # we can set k to truncate the sum; only top k answers contribute.</span>
<span class="sd">    &gt;&gt;&gt; ndcg_score(true_relevance, scores, k=4)</span>
<span class="sd">    0.35...</span>
<span class="sd">    &gt;&gt;&gt; # the normalization takes k into account so a perfect answer</span>
<span class="sd">    &gt;&gt;&gt; # would still get 1.0</span>
<span class="sd">    &gt;&gt;&gt; ndcg_score(true_relevance, true_relevance, k=4)</span>
<span class="sd">    1.0...</span>
<span class="sd">    &gt;&gt;&gt; # now we have some ties in our prediction</span>
<span class="sd">    &gt;&gt;&gt; scores = np.asarray([[1, 0, 0, 0, 1]])</span>
<span class="sd">    &gt;&gt;&gt; # by default ties are averaged, so here we get the average (normalized)</span>
<span class="sd">    &gt;&gt;&gt; # true relevance of our top predictions: (10 / 10 + 5 / 10) / 2 = .75</span>
<span class="sd">    &gt;&gt;&gt; ndcg_score(true_relevance, scores, k=1)</span>
<span class="sd">    0.75...</span>
<span class="sd">    &gt;&gt;&gt; # we can choose to ignore ties for faster results, but only</span>
<span class="sd">    &gt;&gt;&gt; # if we know there aren&#39;t ties in our scores, otherwise we get</span>
<span class="sd">    &gt;&gt;&gt; # wrong results:</span>
<span class="sd">    &gt;&gt;&gt; ndcg_score(true_relevance,</span>
<span class="sd">    ...           scores, k=1, ignore_ties=True)</span>
<span class="sd">    0.5...</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">y_score</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y_score</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">check_consistent_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">y_true</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;ndcg_score should not be used on negative y_true values.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">y_true</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">y_true</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Computing NDCG is only meaningful when there is more than 1 document. &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Got </span><span class="si">{</span><span class="n">y_true</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
        <span class="p">)</span>
    <span class="n">_check_dcg_target_type</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">gain</span> <span class="o">=</span> <span class="n">_ndcg_sample_scores</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">ignore_ties</span><span class="o">=</span><span class="n">ignore_ties</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">gain</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>


<div class="viewcode-block" id="top_k_accuracy_score"><a class="viewcode-back" href="../../../accuracy.html#accuracy.top_k_accuracy_score">[docs]</a><span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y_score&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;k&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">Integral</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)],</span>
        <span class="s2">&quot;normalize&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;boolean&quot;</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">top_k_accuracy_score</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Top-k Accuracy classification score.</span>

<span class="sd">    This metric computes the number of times where the correct label is among</span>
<span class="sd">    the top `k` labels predicted (ranked by predicted scores). Note that the</span>
<span class="sd">    multilabel case isn&#39;t covered here.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;top_k_accuracy_score&gt;`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : array-like of shape (n_samples,)</span>
<span class="sd">        True labels.</span>

<span class="sd">    y_score : array-like of shape (n_samples,) or (n_samples, n_classes)</span>
<span class="sd">        Target scores. These can be either probability estimates or</span>
<span class="sd">        non-thresholded decision values (as returned by</span>
<span class="sd">        :term:`decision_function` on some classifiers).</span>
<span class="sd">        The binary case expects scores with shape (n_samples,) while the</span>
<span class="sd">        multiclass case expects scores with shape (n_samples, n_classes).</span>
<span class="sd">        In the multiclass case, the order of the class scores must</span>
<span class="sd">        correspond to the order of ``labels``, if provided, or else to</span>
<span class="sd">        the numerical or lexicographical order of the labels in ``y_true``.</span>
<span class="sd">        If ``y_true`` does not contain all the labels, ``labels`` must be</span>
<span class="sd">        provided.</span>

<span class="sd">    k : int, default=2</span>
<span class="sd">        Number of most likely outcomes considered to find the correct label.</span>

<span class="sd">    normalize : bool, default=True</span>
<span class="sd">        If `True`, return the fraction of correctly classified samples.</span>
<span class="sd">        Otherwise, return the number of correctly classified samples.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Sample weights. If `None`, all samples are given the same weight.</span>

<span class="sd">    labels : array-like of shape (n_classes,), default=None</span>
<span class="sd">        Multiclass only. List of labels that index the classes in ``y_score``.</span>
<span class="sd">        If ``None``, the numerical or lexicographical order of the labels in</span>
<span class="sd">        ``y_true`` is used. If ``y_true`` does not contain all the labels,</span>
<span class="sd">        ``labels`` must be provided.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : float</span>
<span class="sd">        The top-k accuracy score. The best performance is 1 with</span>
<span class="sd">        `normalize == True` and the number of samples with</span>
<span class="sd">        `normalize == False`.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    accuracy_score : Compute the accuracy score. By default, the function will</span>
<span class="sd">        return the fraction of correct predictions divided by the total number</span>
<span class="sd">        of predictions.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    In cases where two or more labels are assigned equal predicted scores,</span>
<span class="sd">    the labels with the highest indices will be chosen first. This might</span>
<span class="sd">    impact the result if the correct label falls after the threshold because</span>
<span class="sd">    of that.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import top_k_accuracy_score</span>
<span class="sd">    &gt;&gt;&gt; y_true = np.array([0, 1, 2, 2])</span>
<span class="sd">    &gt;&gt;&gt; y_score = np.array([[0.5, 0.2, 0.2],  # 0 is in top 2</span>
<span class="sd">    ...                     [0.3, 0.4, 0.2],  # 1 is in top 2</span>
<span class="sd">    ...                     [0.2, 0.4, 0.3],  # 2 is in top 2</span>
<span class="sd">    ...                     [0.7, 0.2, 0.1]]) # 2 isn&#39;t in top 2</span>
<span class="sd">    &gt;&gt;&gt; top_k_accuracy_score(y_true, y_score, k=2)</span>
<span class="sd">    0.75</span>
<span class="sd">    &gt;&gt;&gt; # Not normalizing gives the number of &quot;correctly&quot; classified samples</span>
<span class="sd">    &gt;&gt;&gt; top_k_accuracy_score(y_true, y_score, k=2, normalize=False)</span>
<span class="sd">    3</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">y_type</span> <span class="o">=</span> <span class="n">type_of_target</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;y_true&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">y_type</span> <span class="o">==</span> <span class="s2">&quot;binary&quot;</span> <span class="ow">and</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">y_type</span> <span class="o">=</span> <span class="s2">&quot;multiclass&quot;</span>
    <span class="k">if</span> <span class="n">y_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">}:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;y type must be &#39;binary&#39; or &#39;multiclass&#39;, got &#39;</span><span class="si">{</span><span class="n">y_type</span><span class="si">}</span><span class="s2">&#39; instead.&quot;</span>
        <span class="p">)</span>
    <span class="n">y_score</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y_score</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">y_type</span> <span class="o">==</span> <span class="s2">&quot;binary&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">y_score</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">y_score</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;`y_true` is binary while y_score is 2d with&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="n">y_score</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> classes. If `y_true` does not contain all the&quot;</span>
                <span class="s2">&quot; labels, `labels` must be provided.&quot;</span>
            <span class="p">)</span>
        <span class="n">y_score</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span>

    <span class="n">check_consistent_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>
    <span class="n">y_score_n_classes</span> <span class="o">=</span> <span class="n">y_score</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">y_score</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="k">else</span> <span class="mi">2</span>

    <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">classes</span> <span class="o">=</span> <span class="n">_unique</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
        <span class="n">n_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">n_classes</span> <span class="o">!=</span> <span class="n">y_score_n_classes</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Number of classes in &#39;y_true&#39; (</span><span class="si">{</span><span class="n">n_classes</span><span class="si">}</span><span class="s2">) not equal &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;to the number of classes in &#39;y_score&#39; (</span><span class="si">{</span><span class="n">y_score_n_classes</span><span class="si">}</span><span class="s2">).&quot;</span>
                <span class="s2">&quot;You can provide a list of all known classes by assigning it &quot;</span>
                <span class="s2">&quot;to the `labels` parameter.&quot;</span>
            <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">classes</span> <span class="o">=</span> <span class="n">_unique</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">n_labels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">n_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">n_classes</span> <span class="o">!=</span> <span class="n">n_labels</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Parameter &#39;labels&#39; must be unique.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">classes</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Parameter &#39;labels&#39; must be ordered.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">n_classes</span> <span class="o">!=</span> <span class="n">y_score_n_classes</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Number of given labels (</span><span class="si">{</span><span class="n">n_classes</span><span class="si">}</span><span class="s2">) not equal to the &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;number of classes in &#39;y_score&#39; (</span><span class="si">{</span><span class="n">y_score_n_classes</span><span class="si">}</span><span class="s2">).&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">setdiff1d</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">classes</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;&#39;y_true&#39; contains labels not in parameter &#39;labels&#39;.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">k</span> <span class="o">&gt;=</span> <span class="n">n_classes</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&#39;k&#39; (</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">) greater than or equal to &#39;n_classes&#39; (</span><span class="si">{</span><span class="n">n_classes</span><span class="si">}</span><span class="s2">) &quot;</span>
                <span class="s2">&quot;will result in a perfect score and is therefore meaningless.&quot;</span>
            <span class="p">),</span>
            <span class="n">UndefinedMetricWarning</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">y_true_encoded</span> <span class="o">=</span> <span class="n">_encode</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">uniques</span><span class="o">=</span><span class="n">classes</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">y_type</span> <span class="o">==</span> <span class="s2">&quot;binary&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="k">if</span> <span class="n">y_score</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">y_score</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">0</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_score</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
            <span class="n">hits</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">==</span> <span class="n">y_true_encoded</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">hits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">y_score</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">bool_</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">y_type</span> <span class="o">==</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">:</span>
        <span class="n">sorted_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">y_score</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;mergesort&quot;</span><span class="p">)[:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">hits</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_true_encoded</span> <span class="o">==</span> <span class="n">sorted_pred</span><span class="p">[:,</span> <span class="p">:</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">hits</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">hits</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">hits</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, MindsDB.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>